//! CLI commands for MCP Agent Mail
//!
//! This crate mirrors the legacy Python Typer CLI with clap, focusing on:
//! - Share/export commands
//! - Doctor diagnostics
//! - Guard tooling
//! - Project, mail, and product helpers
//! - Build slot utilities
//!
//! Command execution is stubbed while lower layers are implemented, but
//! argument parsing and validation match the legacy CLI.

#![forbid(unsafe_code)]

pub mod output;

use clap::{Args, Parser, Subcommand};
use std::path::{Path, PathBuf};
use std::sync::{
    OnceLock,
    atomic::{AtomicU64, Ordering},
};

use chrono::{DateTime, Utc};

use mcp_agent_mail_core::{Config, resolve_project_identity};
use mcp_agent_mail_share as share;
use serde::{Deserialize, Serialize};

#[derive(Debug, thiserror::Error)]
pub enum CliError {
    #[error("not implemented: {0}")]
    NotImplemented(&'static str),
    #[error("invalid argument: {0}")]
    InvalidArgument(String),
    #[error("exit code {0}")]
    ExitCode(i32),
    #[error(transparent)]
    Share(#[from] share::ShareError),
    #[error(transparent)]
    Guard(#[from] mcp_agent_mail_guard::GuardError),
    #[error("io error: {0}")]
    Io(#[from] std::io::Error),
    #[error("{0}")]
    Other(String),
}

pub type CliResult<T> = Result<T, CliError>;

#[derive(Parser, Debug)]
#[command(name = "am", version, about = "MCP Agent Mail CLI (Rust)")]
pub struct Cli {
    #[command(subcommand)]
    pub command: Commands,
}

#[derive(Subcommand, Debug)]
pub enum Commands {
    #[command(name = "serve-http")]
    ServeHttp {
        #[arg(long)]
        host: Option<String>,
        #[arg(long)]
        port: Option<u16>,
        #[arg(long)]
        path: Option<String>,
    },
    #[command(name = "serve-stdio")]
    ServeStdio,
    Lint,
    Typecheck,
    #[command(name = "share")]
    Share {
        #[command(subcommand)]
        action: ShareCommand,
    },
    #[command(name = "archive")]
    Archive {
        #[command(subcommand)]
        action: ArchiveCommand,
    },
    #[command(name = "guard")]
    Guard {
        #[command(subcommand)]
        action: GuardCommand,
    },
    #[command(name = "file_reservations")]
    FileReservations {
        #[command(subcommand)]
        action: FileReservationsCommand,
    },
    #[command(name = "acks")]
    Acks {
        #[command(subcommand)]
        action: AcksCommand,
    },
    #[command(name = "list-acks")]
    ListAcks {
        #[arg(long = "project")]
        project_key: String,
        #[arg(long = "agent")]
        agent_name: String,
        #[arg(long, default_value_t = 20)]
        limit: i64,
    },
    #[command(name = "migrate")]
    Migrate,
    #[command(name = "list-projects")]
    ListProjects {
        #[arg(long, default_value_t = false)]
        include_agents: bool,
        #[arg(long, default_value_t = false)]
        json: bool,
    },
    #[command(name = "clear-and-reset-everything")]
    ClearAndResetEverything {
        #[arg(
            long,
            short = 'f',
            help = "Skip the final destructive confirmation prompt (still asks about creating an archive)."
        )]
        force: bool,
        #[arg(
            long,
            conflicts_with = "no_archive",
            help = "Attempt a pre-reset archive before deleting data (default: prompt when interactive)."
        )]
        archive: bool,
        #[arg(
            long = "no-archive",
            conflicts_with = "archive",
            help = "Skip creating a pre-reset archive."
        )]
        no_archive: bool,
    },
    #[command(name = "config")]
    Config {
        #[command(subcommand)]
        action: ConfigCommand,
    },
    #[command(name = "amctl")]
    Amctl {
        #[command(subcommand)]
        action: AmctlCommand,
    },
    #[command(name = "am-run")]
    AmRun(AmRunArgs),
    #[command(name = "projects")]
    Projects {
        #[command(subcommand)]
        action: ProjectsCommand,
    },
    #[command(name = "mail")]
    Mail {
        #[command(subcommand)]
        action: MailCommand,
    },
    #[command(name = "products")]
    Products {
        #[command(subcommand)]
        action: ProductsCommand,
    },
    #[command(name = "docs")]
    Docs {
        #[command(subcommand)]
        action: DocsCommand,
    },
    #[command(name = "doctor")]
    Doctor {
        #[command(subcommand)]
        action: DoctorCommand,
    },
}

#[derive(Subcommand, Debug)]
pub enum ShareCommand {
    Export(ShareExportArgs),
    Update(ShareUpdateArgs),
    Preview(SharePreviewArgs),
    Verify(ShareVerifyArgs),
    Decrypt(ShareDecryptArgs),
    Wizard,
}

#[derive(Args, Debug)]
pub struct ShareExportArgs {
    #[arg(long, short = 'o')]
    output: PathBuf,
    #[arg(long, short = 'i')]
    interactive: bool,
    #[arg(long = "project", short = 'p')]
    projects: Vec<String>,
    #[arg(long, default_value_t = share::INLINE_ATTACHMENT_THRESHOLD as i64)]
    inline_threshold: i64,
    #[arg(long, default_value_t = share::DETACH_ATTACHMENT_THRESHOLD as i64)]
    detach_threshold: i64,
    #[arg(long, default_value = "standard")]
    scrub_preset: String,
    #[arg(long, default_value_t = share::DEFAULT_CHUNK_THRESHOLD as i64)]
    chunk_threshold: i64,
    #[arg(long, default_value_t = share::DEFAULT_CHUNK_SIZE as i64)]
    chunk_size: i64,
    #[arg(long)]
    dry_run: bool,
    #[arg(long = "no-dry-run", default_value_t = false)]
    no_dry_run: bool,
    #[arg(long, default_value_t = true)]
    zip: bool,
    #[arg(long = "no-zip", default_value_t = false)]
    no_zip: bool,
    #[arg(long)]
    signing_key: Option<PathBuf>,
    #[arg(long)]
    signing_public_out: Option<PathBuf>,
    #[arg(long = "age-recipient")]
    age_recipient: Vec<String>,
}

#[derive(Args, Debug)]
pub struct ShareUpdateArgs {
    pub bundle: PathBuf,
    #[arg(long = "project", short = 'p')]
    projects: Vec<String>,
    #[arg(long)]
    inline_threshold: Option<i64>,
    #[arg(long)]
    detach_threshold: Option<i64>,
    #[arg(long)]
    chunk_threshold: Option<i64>,
    #[arg(long)]
    chunk_size: Option<i64>,
    #[arg(long)]
    scrub_preset: Option<String>,
    #[arg(long, default_value_t = false)]
    zip: bool,
    #[arg(long = "no-zip", default_value_t = false)]
    no_zip: bool,
    #[arg(long)]
    signing_key: Option<PathBuf>,
    #[arg(long)]
    signing_public_out: Option<PathBuf>,
    #[arg(long = "age-recipient")]
    age_recipient: Vec<String>,
}

#[derive(Args, Debug)]
pub struct SharePreviewArgs {
    pub bundle: PathBuf,
    #[arg(long, default_value = "127.0.0.1")]
    host: String,
    #[arg(long, default_value_t = 9000)]
    port: u16,
    #[arg(long)]
    open_browser: bool,
    #[arg(long = "no-open-browser", default_value_t = false)]
    no_open_browser: bool,
}

#[derive(Args, Debug)]
pub struct ShareVerifyArgs {
    pub bundle: PathBuf,
    #[arg(long)]
    public_key: Option<String>,
}

#[derive(Args, Debug)]
pub struct ShareDecryptArgs {
    pub encrypted_path: PathBuf,
    #[arg(long, short = 'o')]
    output: Option<PathBuf>,
    #[arg(long, short = 'i')]
    identity: Option<PathBuf>,
    #[arg(long, short = 'p')]
    passphrase: bool,
}

#[derive(Subcommand, Debug)]
pub enum ArchiveCommand {
    Save {
        #[arg(long = "project", short = 'p')]
        projects: Vec<String>,
        #[arg(long, default_value = "archive")]
        scrub_preset: String,
        #[arg(long, short = 'l')]
        label: Option<String>,
    },
    List {
        #[arg(long, short = 'n', default_value_t = 0)]
        limit: i64,
        #[arg(long)]
        json: bool,
    },
    Restore {
        archive_file: PathBuf,
        #[arg(long, short = 'f')]
        force: bool,
        #[arg(long)]
        dry_run: bool,
    },
}

#[derive(Subcommand, Debug)]
pub enum GuardCommand {
    Install {
        project: String,
        repo: PathBuf,
        #[arg(long)]
        prepush: bool,
        #[arg(long = "no-prepush", default_value_t = false)]
        no_prepush: bool,
    },
    Uninstall {
        repo: PathBuf,
    },
    Status {
        repo: PathBuf,
    },
    Check {
        #[arg(long)]
        stdin_nul: bool,
        #[arg(long)]
        advisory: bool,
        #[arg(long)]
        repo: Option<PathBuf>,
    },
}

#[derive(Subcommand, Debug)]
pub enum FileReservationsCommand {
    List {
        project: String,
        #[arg(long)]
        active_only: bool,
        #[arg(long = "all", default_value_t = false)]
        all: bool,
    },
    Active {
        project: String,
        #[arg(long)]
        limit: Option<i64>,
    },
    Soon {
        project: String,
        #[arg(long)]
        minutes: Option<i64>,
    },
}

#[derive(Subcommand, Debug)]
pub enum AcksCommand {
    Pending {
        project: String,
        agent: String,
        #[arg(long, default_value_t = 20)]
        limit: i64,
    },
    Remind {
        project: String,
        agent: String,
        #[arg(long, default_value_t = 30)]
        min_age_minutes: i64,
        #[arg(long, default_value_t = 50)]
        limit: i64,
    },
    Overdue {
        project: String,
        agent: String,
        #[arg(long, default_value_t = 60)]
        ttl_minutes: i64,
        #[arg(long, default_value_t = 50)]
        limit: i64,
    },
}

#[derive(Subcommand, Debug)]
pub enum ConfigCommand {
    #[command(name = "set-port")]
    SetPort {
        port: u16,
        #[arg(long)]
        env_file: Option<PathBuf>,
    },
    #[command(name = "show-port")]
    ShowPort,
}

#[derive(Subcommand, Debug)]
pub enum AmctlCommand {
    Env {
        #[arg(long, short = 'p', default_value = ".")]
        path: PathBuf,
        #[arg(long, short = 'a')]
        agent: Option<String>,
    },
}

#[derive(Args, Debug)]
pub struct AmRunArgs {
    pub slot: String,
    #[arg(trailing_var_arg = true, required = true)]
    pub cmd: Vec<String>,
    #[arg(long, short = 'p', default_value = ".")]
    pub path: PathBuf,
    #[arg(long, short = 'a')]
    pub agent: Option<String>,
    #[arg(long, default_value_t = 3600)]
    pub ttl_seconds: i64,
    #[arg(long, conflicts_with = "exclusive")]
    pub shared: bool,
    #[arg(long, conflicts_with = "shared")]
    pub exclusive: bool,
    #[arg(long = "block-on-conflicts", conflicts_with = "no_block_on_conflicts")]
    pub block_on_conflicts: bool,
    #[arg(long = "no-block-on-conflicts", conflicts_with = "block_on_conflicts")]
    pub no_block_on_conflicts: bool,
}

#[derive(Subcommand, Debug)]
pub enum ProjectsCommand {
    #[command(name = "mark-identity")]
    MarkIdentity {
        project_path: PathBuf,
        #[arg(long, default_value_t = true)]
        commit: bool,
        #[arg(long = "no-commit", default_value_t = false)]
        no_commit: bool,
    },
    #[command(name = "discovery-init")]
    DiscoveryInit {
        project_path: PathBuf,
        #[arg(long, short = 'P')]
        product: Option<String>,
    },
    Adopt {
        source: PathBuf,
        target: PathBuf,
        #[arg(long, default_value_t = true)]
        dry_run: bool,
        #[arg(long, default_value_t = false)]
        apply: bool,
    },
}

#[derive(Subcommand, Debug)]
pub enum MailCommand {
    Status { project_path: PathBuf },
}

#[derive(Subcommand, Debug)]
pub enum ProductsCommand {
    Ensure {
        product_key: Option<String>,
        #[arg(long, short = 'n')]
        name: Option<String>,
        #[arg(long, default_value_t = false)]
        json: bool,
    },
    Link {
        product_key: String,
        project: String,
        #[arg(long, default_value_t = false)]
        json: bool,
    },
    Status {
        product_key: String,
        #[arg(long, default_value_t = false)]
        json: bool,
    },
    Search {
        product_key: String,
        query: String,
        #[arg(long, short = 'l', default_value_t = 20)]
        limit: i64,
        #[arg(long, default_value_t = false)]
        json: bool,
    },
    Inbox {
        product_key: String,
        agent: String,
        #[arg(long, short = 'l', default_value_t = 20)]
        limit: i64,
        #[arg(long, default_value_t = false)]
        urgent_only: bool,
        #[arg(long, default_value_t = false)]
        all: bool,
        #[arg(long, default_value_t = false)]
        include_bodies: bool,
        #[arg(long = "no-bodies", default_value_t = false)]
        no_bodies: bool,
        #[arg(long)]
        since_ts: Option<String>,
        #[arg(long, default_value_t = false)]
        json: bool,
    },
    #[command(name = "summarize-thread")]
    SummarizeThread {
        product_key: String,
        thread_id: String,
        #[arg(long, short = 'n', default_value_t = 50)]
        per_thread_limit: i64,
        #[arg(long)]
        no_llm: bool,
        #[arg(long, default_value_t = false)]
        json: bool,
    },
}

#[derive(Subcommand, Debug)]
pub enum DocsCommand {
    #[command(name = "insert-blurbs")]
    InsertBlurbs {
        #[arg(long, short = 'd')]
        scan_dir: Vec<PathBuf>,
        #[arg(long)]
        yes: bool,
        #[arg(long, default_value_t = false)]
        dry_run: bool,
        #[arg(long)]
        max_depth: Option<i64>,
    },
}

#[derive(Subcommand, Debug)]
pub enum DoctorCommand {
    Check {
        project: Option<String>,
        #[arg(long, short = 'v')]
        verbose: bool,
        #[arg(long)]
        json: bool,
    },
    Repair {
        project: Option<String>,
        #[arg(long)]
        dry_run: bool,
        #[arg(long, short = 'y')]
        yes: bool,
        #[arg(long)]
        backup_dir: Option<PathBuf>,
    },
    Backups {
        #[arg(long)]
        json: bool,
    },
    Restore {
        backup_path: PathBuf,
        #[arg(long)]
        dry_run: bool,
        #[arg(long, short = 'y')]
        yes: bool,
    },
}

pub fn run() -> i32 {
    let cli = Cli::parse();
    match execute(cli) {
        Ok(()) => 0,
        Err(err) => {
            emit_error(&err);
            err_exit_code(&err)
        }
    }
}

fn err_exit_code(_err: &CliError) -> i32 {
    match _err {
        CliError::ExitCode(code) => *code,
        _ => 1,
    }
}

fn emit_error(err: &CliError) {
    if matches!(err, CliError::ExitCode(_)) {
        return;
    }
    ftui_runtime::ftui_eprintln!("error: {err}");
}

fn execute(cli: Cli) -> CliResult<()> {
    match cli.command {
        Commands::Share { action } => handle_share(action),
        Commands::Doctor { action } => handle_doctor(action),
        Commands::Guard { action } => handle_guard(action),
        Commands::FileReservations { action } => handle_file_reservations(action),
        Commands::Acks { action } => handle_acks(action),
        Commands::ListAcks {
            project_key,
            agent_name,
            limit,
        } => handle_list_acks(&project_key, &agent_name, limit),
        Commands::Archive { action } => handle_archive(action),
        Commands::ServeHttp { host, port, path } => handle_serve_http(host, port, path),
        Commands::ServeStdio => handle_serve_stdio(),
        Commands::Lint => handle_lint(),
        Commands::Typecheck => handle_typecheck(),
        Commands::Migrate => handle_migrate(),
        Commands::ListProjects {
            include_agents,
            json,
        } => handle_list_projects(include_agents, json),
        Commands::ClearAndResetEverything {
            force,
            archive,
            no_archive,
        } => handle_clear_and_reset(force, archive, no_archive),
        Commands::Config { action } => handle_config(action),
        Commands::Amctl { action } => handle_amctl(action),
        Commands::AmRun(args) => handle_am_run(args),
        Commands::Projects { action } => handle_projects(action),
        Commands::Mail { action } => handle_mail(action),
        Commands::Products { action } => handle_products(action),
        Commands::Docs { action } => handle_docs(action),
    }
}

fn handle_share(action: ShareCommand) -> CliResult<()> {
    match action {
        ShareCommand::Export(args) => {
            let dry_run = resolve_bool(args.dry_run, args.no_dry_run, false);

            let mut projects = args.projects;
            let mut inline_threshold = args.inline_threshold;
            let mut detach_threshold = args.detach_threshold;
            let mut scrub_preset = args.scrub_preset;
            let mut chunk_threshold = args.chunk_threshold;
            let mut chunk_size = args.chunk_size;
            let mut do_zip = resolve_bool(args.zip, args.no_zip, true);

            if args.interactive {
                let wizard = share_export_wizard(ShareExportWizardDefaults {
                    projects: projects.clone(),
                    inline_threshold,
                    detach_threshold,
                    scrub_preset: scrub_preset.clone(),
                    chunk_threshold,
                    chunk_size,
                    zip: do_zip,
                })?;
                projects = wizard.projects;
                inline_threshold = wizard.inline_threshold;
                detach_threshold = wizard.detach_threshold;
                scrub_preset = wizard.scrub_preset;
                chunk_threshold = wizard.chunk_threshold;
                chunk_size = wizard.chunk_size;
                do_zip = wizard.zip;
            }

            let preset = share::normalize_scrub_preset(&scrub_preset)?;
            share::validate_thresholds(
                inline_threshold,
                detach_threshold,
                chunk_threshold,
                chunk_size,
            )?;

            let inline = inline_threshold.max(0) as usize;
            let detach_raw = detach_threshold.max(0) as usize;
            let detach_adjusted = share::adjust_detach_threshold(inline, detach_raw);
            if detach_adjusted != detach_raw {
                ftui_runtime::ftui_eprintln!(
                    "warning: adjusted detach threshold to {} to exceed inline threshold",
                    detach_adjusted
                );
            }
            run_share_export(ShareExportParams {
                output: args.output,
                projects,
                inline_threshold: inline,
                detach_threshold: detach_adjusted,
                scrub_preset: preset,
                chunk_threshold: chunk_threshold.max(0) as usize,
                chunk_size: chunk_size.max(1024) as usize,
                dry_run,
                zip: do_zip,
                signing_key: args.signing_key,
                signing_public_out: args.signing_public_out,
                age_recipients: args.age_recipient,
            })
        }
        ShareCommand::Update(args) => {
            if !args.bundle.exists() {
                return Err(share::ShareError::BundleNotFound {
                    path: args.bundle.display().to_string(),
                }
                .into());
            }
            let stored = share::load_bundle_export_config(&args.bundle)?;
            let preset = args
                .scrub_preset
                .as_deref()
                .unwrap_or(stored.scrub_preset.as_str());
            let _preset = share::normalize_scrub_preset(preset)?;
            let inline = args.inline_threshold.unwrap_or(stored.inline_threshold);
            let detach = args.detach_threshold.unwrap_or(stored.detach_threshold);
            let chunk_threshold = args.chunk_threshold.unwrap_or(stored.chunk_threshold);
            let chunk_size = args.chunk_size.unwrap_or(stored.chunk_size);
            share::validate_thresholds(inline, detach, chunk_threshold, chunk_size)?;
            let inline_u = inline.max(0) as usize;
            let detach_u = detach.max(0) as usize;
            let detach_adjusted = share::adjust_detach_threshold(inline_u, detach_u);
            if detach_adjusted != detach_u {
                ftui_runtime::ftui_eprintln!(
                    "warning: adjusted detach threshold to {} to exceed inline threshold",
                    detach_adjusted
                );
            }
            let do_zip = resolve_bool(args.zip, args.no_zip, false);
            run_share_update(ShareUpdateParams {
                bundle: args.bundle,
                projects: if args.projects.is_empty() {
                    stored.projects
                } else {
                    args.projects
                },
                inline_threshold: inline_u,
                detach_threshold: detach_adjusted,
                scrub_preset: _preset,
                chunk_threshold: chunk_threshold.max(0) as usize,
                chunk_size: chunk_size.max(1024) as usize,
                zip: do_zip,
                signing_key: args.signing_key,
                signing_public_out: args.signing_public_out,
                age_recipients: args.age_recipient,
            })
        }
        ShareCommand::Preview(args) => {
            ensure_dir(&args.bundle)?;
            let open = resolve_bool(args.open_browser, args.no_open_browser, false);
            run_share_preview(&args.bundle, &args.host, args.port, open)
        }
        ShareCommand::Verify(args) => {
            ensure_dir(&args.bundle)?;
            let result = share::verify_bundle_crypto(&args.bundle, args.public_key.as_deref())?;
            output::section(&format!("Bundle: {}", result.bundle));
            output::kv("SRI checked", &result.sri_checked.to_string());
            output::kv("SRI valid", &result.sri_valid.to_string());
            output::kv("Signature checked", &result.signature_checked.to_string());
            output::kv("Signature valid", &result.signature_verified.to_string());
            if let Some(ref err) = result.error {
                ftui_runtime::ftui_eprintln!("  Error: {err}");
                return Err(CliError::ExitCode(1));
            }
            if result.signature_checked && !result.signature_verified {
                ftui_runtime::ftui_eprintln!("  Signature verification FAILED.");
                return Err(CliError::ExitCode(1));
            }
            Ok(())
        }
        ShareCommand::Decrypt(args) => {
            if args.identity.is_some() && args.passphrase {
                return Err(CliError::InvalidArgument(
                    "passphrase cannot be combined with identity file".to_string(),
                ));
            }
            if !args.encrypted_path.exists() {
                return Err(CliError::InvalidArgument(format!(
                    "encrypted file not found: {}",
                    args.encrypted_path.display()
                )));
            }
            let output = args
                .output
                .unwrap_or_else(|| share::default_decrypt_output(&args.encrypted_path));
            let passphrase_str = if args.passphrase {
                ftui_runtime::ftui_eprintln!("Enter passphrase:");
                let mut buf = String::new();
                std::io::stdin()
                    .read_line(&mut buf)
                    .map_err(|e| CliError::Other(format!("failed to read passphrase: {e}")))?;
                Some(buf.trim_end().to_string())
            } else {
                None
            };
            share::decrypt_with_age(
                &args.encrypted_path,
                &output,
                args.identity.as_deref(),
                passphrase_str.as_deref(),
            )?;
            ftui_runtime::ftui_println!("Decrypted to: {}", output.display());
            Ok(())
        }
        ShareCommand::Wizard => {
            let cwd = std::env::current_dir()
                .map_err(|e| CliError::Other(format!("failed to resolve current dir: {e}")))?;
            run_share_wizard_in_cwd(&cwd)
        }
    }
}

fn handle_serve_http(
    host: Option<String>,
    port: Option<u16>,
    path: Option<String>,
) -> CliResult<()> {
    let config = build_http_config(host, port, path);
    mcp_agent_mail_server::run_http(&config)?;
    Ok(())
}

fn handle_serve_stdio() -> CliResult<()> {
    let config = Config::from_env();
    mcp_agent_mail_server::run_stdio(&config);
    Ok(())
}

fn build_http_config(host: Option<String>, port: Option<u16>, path: Option<String>) -> Config {
    let mut config = Config::from_env();
    if let Some(host) = host {
        config.http_host = host;
    }
    if let Some(port) = port {
        config.http_port = port;
    }
    if let Some(path) = path {
        config.http_path = path;
    }
    config
}

fn handle_doctor(action: DoctorCommand) -> CliResult<()> {
    match action {
        DoctorCommand::Check {
            project,
            verbose,
            json,
        } => handle_doctor_check(project, verbose, json),
        DoctorCommand::Repair {
            project,
            dry_run,
            yes,
            backup_dir,
        } => handle_doctor_repair(project, dry_run, yes, backup_dir),
        DoctorCommand::Backups { json } => handle_doctor_backups(json),
        DoctorCommand::Restore {
            backup_path,
            dry_run,
            yes,
        } => handle_doctor_restore(backup_path, dry_run, yes),
    }
}

fn handle_guard(action: GuardCommand) -> CliResult<()> {
    match action {
        GuardCommand::Install { project, repo, .. } => {
            mcp_agent_mail_guard::install_guard(&project, repo.as_path())?;
            ftui_runtime::ftui_println!("Guard installed successfully.");
            Ok(())
        }
        GuardCommand::Uninstall { repo } => {
            mcp_agent_mail_guard::uninstall_guard(repo.as_path())?;
            ftui_runtime::ftui_println!("Guard uninstalled successfully.");
            Ok(())
        }
        GuardCommand::Status { repo } => {
            let status = mcp_agent_mail_guard::guard_status(&repo)?;
            output::section("Guard Status:");
            output::kv("Hooks dir", &status.hooks_dir);
            output::kv("Mode", &format!("{:?}", status.guard_mode));
            output::kv("Worktrees", &status.worktrees_enabled.to_string());
            output::kv(
                "Pre-commit",
                if status.pre_commit_present {
                    "installed"
                } else {
                    "not installed"
                },
            );
            output::kv(
                "Pre-push",
                if status.pre_push_present {
                    "installed"
                } else {
                    "not installed"
                },
            );
            Ok(())
        }
        GuardCommand::Check {
            stdin_nul,
            advisory,
            repo,
        } => {
            let repo_path = repo.unwrap_or_else(|| std::env::current_dir().unwrap_or_default());
            // Read paths from stdin (null-separated or line-separated)
            let input = {
                use std::io::Read;
                let mut buf = String::new();
                std::io::stdin().read_to_string(&mut buf).unwrap_or(0);
                buf
            };
            let paths: Vec<String> = if stdin_nul {
                input
                    .split('\0')
                    .filter(|s| !s.is_empty())
                    .map(String::from)
                    .collect()
            } else {
                input
                    .lines()
                    .filter(|s| !s.is_empty())
                    .map(String::from)
                    .collect()
            };

            let conflicts = mcp_agent_mail_guard::guard_check(&repo_path, &paths, advisory)?;
            if conflicts.is_empty() {
                ftui_runtime::ftui_println!("No file reservation conflicts detected.");
            } else {
                for c in &conflicts {
                    ftui_runtime::ftui_eprintln!(
                        "CONFLICT: pattern '{}' held by {} (expires {})",
                        c.pattern,
                        c.holder,
                        c.expires_ts
                    );
                }
                if !advisory {
                    return Err(CliError::ExitCode(1));
                }
            }
            Ok(())
        }
    }
}

fn handle_list_projects(include_agents: bool, json_output: bool) -> CliResult<()> {
    let cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
    handle_list_projects_with_database_url(&cfg.database_url, include_agents, json_output)
}

fn handle_list_projects_with_database_url(
    database_url: &str,
    include_agents: bool,
    json_output: bool,
) -> CliResult<()> {
    let conn = open_db_sync_with_database_url(database_url)?;

    let projects = conn
        .query_sync(
            "SELECT id, slug, human_key, created_at FROM projects ORDER BY id",
            &[],
        )
        .map_err(|e| CliError::Other(format!("query failed: {e}")))?;

    if json_output {
        let mut output: Vec<serde_json::Value> = Vec::new();
        for row in &projects {
            let id: i64 = row.get_named("id").unwrap_or(0);
            let slug: String = row.get_named("slug").unwrap_or_default();
            let human_key: String = row.get_named("human_key").unwrap_or_default();
            let created_at: i64 = row.get_named("created_at").unwrap_or(0);

            let mut entry = serde_json::json!({
                "id": id,
                "slug": slug,
                "human_key": human_key,
                "created_at": mcp_agent_mail_db::timestamps::micros_to_iso(created_at),
            });

            if include_agents {
                let agents = conn
                    .query_sync(
                        "SELECT name, program, model FROM agents WHERE project_id = ?",
                        &[sqlmodel_core::Value::BigInt(id)],
                    )
                    .unwrap_or_default();
                let agent_list: Vec<serde_json::Value> = agents
                    .iter()
                    .map(|a| {
                        let name: String = a.get_named("name").unwrap_or_default();
                        let program: String = a.get_named("program").unwrap_or_default();
                        let model: String = a.get_named("model").unwrap_or_default();
                        serde_json::json!({ "name": name, "program": program, "model": model })
                    })
                    .collect();
                entry
                    .as_object_mut()
                    .unwrap()
                    .insert("agents".to_string(), serde_json::json!(agent_list));
            }
            output.push(entry);
        }
        ftui_runtime::ftui_println!(
            "{}",
            serde_json::to_string_pretty(&output).unwrap_or_default()
        );
    } else {
        if projects.is_empty() {
            output::empty_result(false, "No projects found.");
            return Ok(());
        }
        let mut table = output::CliTable::new(vec!["ID", "SLUG", "HUMAN_KEY"]);
        for row in &projects {
            let id: i64 = row.get_named("id").unwrap_or(0);
            let slug: String = row.get_named("slug").unwrap_or_default();
            let human_key: String = row.get_named("human_key").unwrap_or_default();
            table.add_row(vec![id.to_string(), slug, human_key]);
        }
        table.render();
        if include_agents {
            ftui_runtime::ftui_println!("");
            for row in &projects {
                let id: i64 = row.get_named("id").unwrap_or(0);
                let slug: String = row.get_named("slug").unwrap_or_default();
                let agents = conn
                    .query_sync(
                        "SELECT name, program, model FROM agents WHERE project_id = ?",
                        &[sqlmodel_core::Value::BigInt(id)],
                    )
                    .unwrap_or_default();
                if !agents.is_empty() {
                    output::section(&format!("Agents for {slug}:"));
                    for a in &agents {
                        let name: String = a.get_named("name").unwrap_or_default();
                        let program: String = a.get_named("program").unwrap_or_default();
                        let model: String = a.get_named("model").unwrap_or_default();
                        ftui_runtime::ftui_println!("  {name} ({program}/{model})");
                    }
                }
            }
        }
    }
    Ok(())
}

/// Open a synchronous SQLite connection for CLI commands.
fn open_db_sync_with_database_url(
    database_url: &str,
) -> CliResult<sqlmodel_sqlite::SqliteConnection> {
    let cfg = mcp_agent_mail_db::DbPoolConfig {
        database_url: database_url.to_string(),
        ..Default::default()
    };
    let path = cfg
        .sqlite_path()
        .map_err(|e| CliError::Other(format!("bad database URL: {e}")))?;
    let conn = sqlmodel_sqlite::SqliteConnection::open_file(&path)
        .map_err(|e| CliError::Other(format!("cannot open DB at {path}: {e}")))?;
    // Run schema init so tables exist even if first use
    let init_sql = mcp_agent_mail_db::schema::init_schema_sql();
    conn.execute_raw(&init_sql)
        .map_err(|e| CliError::Other(format!("schema init failed: {e}")))?;
    Ok(conn)
}

fn open_db_sync() -> CliResult<sqlmodel_sqlite::SqliteConnection> {
    let cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
    open_db_sync_with_database_url(&cfg.database_url)
}

fn handle_config(action: ConfigCommand) -> CliResult<()> {
    match action {
        ConfigCommand::ShowPort => {
            let config = Config::from_env();
            ftui_runtime::ftui_println!("{}", config.http_port);
            Ok(())
        }
        ConfigCommand::SetPort { port, env_file } => {
            let env_path = env_file
                .unwrap_or_else(|| std::env::current_dir().unwrap_or_default().join(".env"));
            // Write or update the port in the env file
            let content = if env_path.exists() {
                let existing = std::fs::read_to_string(&env_path).map_err(|e| {
                    CliError::Other(format!("Failed to read {}: {e}", env_path.display()))
                })?;
                let mut found = false;
                let updated: Vec<String> = existing
                    .lines()
                    .map(|line: &str| {
                        if line.starts_with("AGENT_MAIL_HTTP_PORT=") {
                            found = true;
                            format!("AGENT_MAIL_HTTP_PORT={port}")
                        } else {
                            line.to_string()
                        }
                    })
                    .collect();
                if found {
                    updated.join("\n")
                } else {
                    format!("{existing}\nAGENT_MAIL_HTTP_PORT={port}")
                }
            } else {
                format!("AGENT_MAIL_HTTP_PORT={port}\n")
            };
            std::fs::write(&env_path, content).map_err(|e| {
                CliError::Other(format!("Failed to write {}: {e}", env_path.display()))
            })?;
            ftui_runtime::ftui_println!("Port set to {} in {}", port, env_path.display());
            Ok(())
        }
    }
}

fn handle_file_reservations(action: FileReservationsCommand) -> CliResult<()> {
    let conn = open_db_sync()?;
    handle_file_reservations_with_conn(&conn, action)
}

fn handle_file_reservations_with_conn(
    conn: &sqlmodel_sqlite::SqliteConnection,
    action: FileReservationsCommand,
) -> CliResult<()> {
    let now_us = mcp_agent_mail_db::timestamps::now_micros();

    match action {
        FileReservationsCommand::List {
            project,
            active_only,
            all,
        } => {
            let sql = if active_only {
                "SELECT fr.id, fr.path_pattern, fr.exclusive, fr.reason, \
                        fr.expires_ts, fr.released_ts, a.name AS agent_name \
                 FROM file_reservations fr \
                 JOIN agents a ON a.id = fr.agent_id \
                 JOIN projects p ON p.id = fr.project_id \
                 WHERE p.slug = ? AND fr.released_ts IS NULL AND fr.expires_ts > ? \
                 ORDER BY fr.id"
            } else if all {
                "SELECT fr.id, fr.path_pattern, fr.exclusive, fr.reason, \
                        fr.expires_ts, fr.released_ts, a.name AS agent_name \
                 FROM file_reservations fr \
                 JOIN agents a ON a.id = fr.agent_id \
                 JOIN projects p ON p.id = fr.project_id \
                 WHERE p.slug = ? \
                 ORDER BY fr.id"
            } else {
                // Default: active (not released, not expired)
                "SELECT fr.id, fr.path_pattern, fr.exclusive, fr.reason, \
                        fr.expires_ts, fr.released_ts, a.name AS agent_name \
                 FROM file_reservations fr \
                 JOIN agents a ON a.id = fr.agent_id \
                 JOIN projects p ON p.id = fr.project_id \
                 WHERE p.slug = ? AND fr.released_ts IS NULL AND fr.expires_ts > ? \
                 ORDER BY fr.id"
            };
            let params: Vec<sqlmodel_core::Value> = if active_only || (!all) {
                vec![
                    sqlmodel_core::Value::Text(project),
                    sqlmodel_core::Value::BigInt(now_us),
                ]
            } else {
                vec![sqlmodel_core::Value::Text(project)]
            };
            let rows = conn
                .query_sync(sql, &params)
                .map_err(|e| CliError::Other(format!("query failed: {e}")))?;

            if rows.is_empty() {
                output::empty_result(false, "No file reservations found.");
                return Ok(());
            }
            let mut table =
                output::CliTable::new(vec!["ID", "PATTERN", "AGENT", "EXPIRES", "REASON"]);
            for r in &rows {
                let id: i64 = r.get_named("id").unwrap_or(0);
                let pattern: String = r.get_named("path_pattern").unwrap_or_default();
                let agent: String = r.get_named("agent_name").unwrap_or_default();
                let expires: i64 = r.get_named("expires_ts").unwrap_or(0);
                let reason: String = r.get_named("reason").unwrap_or_default();
                let expires_str = mcp_agent_mail_db::timestamps::micros_to_iso(expires);
                let expires_display = expires_str.get(..20).unwrap_or(&expires_str).to_string();
                table.add_row(vec![
                    id.to_string(),
                    pattern,
                    agent,
                    expires_display,
                    reason,
                ]);
            }
            table.render();
            Ok(())
        }
        FileReservationsCommand::Active { project, limit } => {
            let limit = limit.unwrap_or(50);
            let rows = conn
                .query_sync(
                    "SELECT fr.id, fr.path_pattern, fr.exclusive, fr.reason, \
                            fr.expires_ts, a.name AS agent_name \
                     FROM file_reservations fr \
                     JOIN agents a ON a.id = fr.agent_id \
                     JOIN projects p ON p.id = fr.project_id \
                     WHERE p.slug = ? AND fr.released_ts IS NULL AND fr.expires_ts > ? \
                     ORDER BY fr.expires_ts ASC \
                     LIMIT ?",
                    &[
                        sqlmodel_core::Value::Text(project),
                        sqlmodel_core::Value::BigInt(now_us),
                        sqlmodel_core::Value::BigInt(limit),
                    ],
                )
                .map_err(|e| CliError::Other(format!("query failed: {e}")))?;

            if rows.is_empty() {
                ftui_runtime::ftui_println!("No active reservations.");
                return Ok(());
            }
            for r in &rows {
                let pattern: String = r.get_named("path_pattern").unwrap_or_default();
                let agent: String = r.get_named("agent_name").unwrap_or_default();
                let exclusive: bool = r.get_named("exclusive").unwrap_or(true);
                let lock_type = if exclusive { "excl" } else { "shared" };
                ftui_runtime::ftui_println!("  {} [{}] by {}", pattern, lock_type, agent);
            }
            Ok(())
        }
        FileReservationsCommand::Soon { project, minutes } => {
            let minutes = minutes.unwrap_or(30);
            let threshold_us = now_us + minutes * 60 * 1_000_000;
            let rows = conn
                .query_sync(
                    "SELECT fr.id, fr.path_pattern, fr.expires_ts, a.name AS agent_name \
                     FROM file_reservations fr \
                     JOIN agents a ON a.id = fr.agent_id \
                     JOIN projects p ON p.id = fr.project_id \
                     WHERE p.slug = ? AND fr.released_ts IS NULL \
                       AND fr.expires_ts > ? AND fr.expires_ts <= ? \
                     ORDER BY fr.expires_ts ASC",
                    &[
                        sqlmodel_core::Value::Text(project),
                        sqlmodel_core::Value::BigInt(now_us),
                        sqlmodel_core::Value::BigInt(threshold_us),
                    ],
                )
                .map_err(|e| CliError::Other(format!("query failed: {e}")))?;

            if rows.is_empty() {
                ftui_runtime::ftui_println!("No reservations expiring within {} minutes.", minutes);
                return Ok(());
            }
            output::section(&format!(
                "Reservations expiring within {} minutes:",
                minutes
            ));
            let mut table = output::CliTable::new(vec!["PATTERN", "AGENT", "REMAINING"]);
            for r in &rows {
                let pattern: String = r.get_named("path_pattern").unwrap_or_default();
                let agent: String = r.get_named("agent_name").unwrap_or_default();
                let expires: i64 = r.get_named("expires_ts").unwrap_or(0);
                let remaining_min = (expires - now_us) / 60_000_000;
                table.add_row(vec![pattern, agent, format!("{}min", remaining_min)]);
            }
            table.render();
            Ok(())
        }
    }
}

fn handle_acks(action: AcksCommand) -> CliResult<()> {
    let conn = open_db_sync()?;
    handle_acks_with_conn(&conn, action)
}

fn handle_acks_with_conn(
    conn: &sqlmodel_sqlite::SqliteConnection,
    action: AcksCommand,
) -> CliResult<()> {
    let now_us = mcp_agent_mail_db::timestamps::now_micros();

    match action {
        AcksCommand::Pending {
            project,
            agent,
            limit,
        } => {
            // Messages sent TO this agent with ack_required=1 that haven't been acked
            let rows = conn
                .query_sync(
                    "SELECT m.id, m.subject, m.importance, m.created_ts, \
                            sender_a.name AS sender_name \
                     FROM messages m \
                     JOIN message_recipients i ON i.message_id = m.id \
                     JOIN agents recv_a ON recv_a.id = i.agent_id \
                     JOIN agents sender_a ON sender_a.id = m.sender_id \
                     JOIN projects p ON p.id = m.project_id \
                     WHERE p.slug = ? AND recv_a.name = ? \
                       AND m.ack_required = 1 AND i.ack_ts IS NULL \
                     ORDER BY m.created_ts DESC \
                     LIMIT ?",
                    &[
                        sqlmodel_core::Value::Text(project),
                        sqlmodel_core::Value::Text(agent),
                        sqlmodel_core::Value::BigInt(limit),
                    ],
                )
                .map_err(|e| CliError::Other(format!("query failed: {e}")))?;

            if rows.is_empty() {
                output::empty_result(false, "No pending acks.");
                return Ok(());
            }
            let mut table = output::CliTable::new(vec!["ID", "FROM", "SUBJECT", "IMPORTANCE"]);
            for r in &rows {
                let id: i64 = r.get_named("id").unwrap_or(0);
                let subject: String = r.get_named("subject").unwrap_or_default();
                let sender: String = r.get_named("sender_name").unwrap_or_default();
                let importance: String = r.get_named("importance").unwrap_or_default();
                let subject_display = subject.get(..40).unwrap_or(&subject).to_string();
                table.add_row(vec![id.to_string(), sender, subject_display, importance]);
            }
            table.render();
            Ok(())
        }
        AcksCommand::Remind {
            project,
            agent,
            min_age_minutes,
            limit,
        } => {
            // Stale acks: ack_required but not acked, older than min_age_minutes
            let cutoff = now_us - min_age_minutes * 60 * 1_000_000;
            let rows = conn
                .query_sync(
                    "SELECT m.id, m.subject, m.created_ts, sender_a.name AS sender_name \
                     FROM messages m \
                     JOIN message_recipients i ON i.message_id = m.id \
                     JOIN agents recv_a ON recv_a.id = i.agent_id \
                     JOIN agents sender_a ON sender_a.id = m.sender_id \
                     JOIN projects p ON p.id = m.project_id \
                     WHERE p.slug = ? AND recv_a.name = ? \
                       AND m.ack_required = 1 AND i.ack_ts IS NULL \
                       AND m.created_ts < ? \
                     ORDER BY m.created_ts ASC \
                     LIMIT ?",
                    &[
                        sqlmodel_core::Value::Text(project),
                        sqlmodel_core::Value::Text(agent),
                        sqlmodel_core::Value::BigInt(cutoff),
                        sqlmodel_core::Value::BigInt(limit),
                    ],
                )
                .map_err(|e| CliError::Other(format!("query failed: {e}")))?;

            if rows.is_empty() {
                output::empty_result(false, "No stale acks needing reminders.");
                return Ok(());
            }
            output::section(&format!("Stale acks (>{min_age_minutes}min old):"));
            let mut table = output::CliTable::new(vec!["ID", "FROM", "SUBJECT", "AGE"]);
            for r in &rows {
                let id: i64 = r.get_named("id").unwrap_or(0);
                let subject: String = r.get_named("subject").unwrap_or_default();
                let sender: String = r.get_named("sender_name").unwrap_or_default();
                let age_min =
                    (now_us - r.get_named::<i64>("created_ts").unwrap_or(now_us)) / 60_000_000;
                table.add_row(vec![
                    id.to_string(),
                    sender,
                    subject,
                    format!("{age_min}min"),
                ]);
            }
            table.render();
            Ok(())
        }
        AcksCommand::Overdue {
            project,
            agent,
            ttl_minutes,
            limit,
        } => {
            // Overdue acks: ack_required, not acked, older than ttl_minutes
            let cutoff = now_us - ttl_minutes * 60 * 1_000_000;
            let rows = conn
                .query_sync(
                    "SELECT m.id, m.subject, m.created_ts, sender_a.name AS sender_name \
                     FROM messages m \
                     JOIN message_recipients i ON i.message_id = m.id \
                     JOIN agents recv_a ON recv_a.id = i.agent_id \
                     JOIN agents sender_a ON sender_a.id = m.sender_id \
                     JOIN projects p ON p.id = m.project_id \
                     WHERE p.slug = ? AND recv_a.name = ? \
                       AND m.ack_required = 1 AND i.ack_ts IS NULL \
                       AND m.created_ts < ? \
                     ORDER BY m.created_ts ASC \
                     LIMIT ?",
                    &[
                        sqlmodel_core::Value::Text(project),
                        sqlmodel_core::Value::Text(agent),
                        sqlmodel_core::Value::BigInt(cutoff),
                        sqlmodel_core::Value::BigInt(limit),
                    ],
                )
                .map_err(|e| CliError::Other(format!("query failed: {e}")))?;

            if rows.is_empty() {
                output::empty_result(false, "No overdue acks.");
                return Ok(());
            }
            output::section(&format!("OVERDUE acks (>{ttl_minutes}min TTL):"));
            let mut table = output::CliTable::new(vec!["ID", "FROM", "SUBJECT", "OVERDUE"]);
            for r in &rows {
                let id: i64 = r.get_named("id").unwrap_or(0);
                let subject: String = r.get_named("subject").unwrap_or_default();
                let sender: String = r.get_named("sender_name").unwrap_or_default();
                let age_min =
                    (now_us - r.get_named::<i64>("created_ts").unwrap_or(now_us)) / 60_000_000;
                table.add_row(vec![
                    id.to_string(),
                    sender,
                    subject,
                    format!("{age_min}min"),
                ]);
            }
            table.render();
            Ok(())
        }
    }
}

fn handle_list_acks(project_key: &str, agent_name: &str, limit: i64) -> CliResult<()> {
    let conn = open_db_sync()?;
    handle_list_acks_with_conn(&conn, project_key, agent_name, limit)
}

fn handle_list_acks_with_conn(
    conn: &sqlmodel_sqlite::SqliteConnection,
    project_key: &str,
    agent_name: &str,
    limit: i64,
) -> CliResult<()> {
    let rows = conn
        .query_sync(
            "SELECT m.id, m.subject, m.importance, m.created_ts, \
                    i.ack_ts, i.read_ts, sender_a.name AS sender_name \
             FROM messages m \
             JOIN message_recipients i ON i.message_id = m.id \
             JOIN agents recv_a ON recv_a.id = i.agent_id \
             JOIN agents sender_a ON sender_a.id = m.sender_id \
             JOIN projects p ON p.id = m.project_id \
             WHERE p.slug = ? AND recv_a.name = ? AND m.ack_required = 1 \
             ORDER BY m.created_ts DESC \
             LIMIT ?",
            &[
                sqlmodel_core::Value::Text(project_key.to_string()),
                sqlmodel_core::Value::Text(agent_name.to_string()),
                sqlmodel_core::Value::BigInt(limit),
            ],
        )
        .map_err(|e| CliError::Other(format!("query failed: {e}")))?;

    if rows.is_empty() {
        output::empty_result(
            false,
            &format!("No ack-required messages for {agent_name}."),
        );
        return Ok(());
    }
    let mut table = output::CliTable::new(vec!["ID", "FROM", "SUBJECT", "STATUS", "CREATED"]);
    for r in &rows {
        let id: i64 = r.get_named("id").unwrap_or(0);
        let subject: String = r.get_named("subject").unwrap_or_default();
        let sender: String = r.get_named("sender_name").unwrap_or_default();
        let ack_ts: Option<i64> = r.get_named("ack_ts").ok();
        let created: i64 = r.get_named("created_ts").unwrap_or(0);
        let status = if ack_ts.is_some() { "acked" } else { "pending" };
        let created_str = mcp_agent_mail_db::timestamps::micros_to_iso(created);
        let subject_display = subject.get(..35).unwrap_or(&subject).to_string();
        let created_display = created_str.get(..19).unwrap_or(&created_str).to_string();
        table.add_row(vec![
            id.to_string(),
            sender,
            subject_display,
            status.to_string(),
            created_display,
        ]);
    }
    table.render();
    Ok(())
}

fn handle_migrate_with_database_url(database_url: &str) -> CliResult<()> {
    use asupersync::runtime::RuntimeBuilder;
    use mcp_agent_mail_db::schema;
    use sqlmodel_sqlite::SqliteConnection;

    let cfg = mcp_agent_mail_db::DbPoolConfig {
        database_url: database_url.to_string(),
        ..mcp_agent_mail_db::DbPoolConfig::default()
    };
    let path = cfg
        .sqlite_path()
        .map_err(|e| CliError::Other(format!("bad database URL: {e}")))?;

    let conn = SqliteConnection::open_file(&path)
        .map_err(|e| CliError::Other(format!("cannot open DB at {path}: {e}")))?;
    conn.execute_raw(schema::PRAGMA_SETTINGS_SQL)
        .map_err(|e| CliError::Other(format!("failed to apply PRAGMAs: {e}")))?;

    let cx = asupersync::Cx::for_request();
    let rt = RuntimeBuilder::current_thread()
        .build()
        .map_err(|e| CliError::Other(format!("failed to build runtime: {e}")))?;

    let outcome = rt.block_on(async { schema::migrate_to_latest(&cx, &conn).await });

    match outcome {
        asupersync::Outcome::Ok(_) => {
            // Legacy Python: `migrate` is an explicit schema-create command.
            ftui_runtime::ftui_println!(" Database schema created from model definitions!");
            ftui_runtime::ftui_println!(
                "Note: To apply model changes, delete storage.sqlite3 and run this again."
            );
            Ok(())
        }
        asupersync::Outcome::Err(e) => Err(CliError::Other(format!("migrate failed: {e}"))),
        asupersync::Outcome::Cancelled(r) => {
            Err(CliError::Other(format!("migrate cancelled: {r:?}")))
        }
        asupersync::Outcome::Panicked(p) => Err(CliError::Other(format!("migrate panicked: {p}"))),
    }
}

fn handle_migrate() -> CliResult<()> {
    let cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
    handle_migrate_with_database_url(&cfg.database_url)
}

#[derive(Debug)]
#[allow(dead_code)]
struct ClearAndResetOutcome {
    archive_path: Option<PathBuf>,
    deleted_db_files: Vec<PathBuf>,
    deleted_storage_entries: Vec<PathBuf>,
}

fn handle_clear_and_reset(force: bool, archive: bool, no_archive: bool) -> CliResult<()> {
    let db_cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
    let db_path = match db_cfg.sqlite_path() {
        Ok(path) => Some(PathBuf::from(path)),
        Err(err) => {
            ftui_runtime::ftui_eprintln!(
                "Warning: failed to parse SQLite database path from DATABASE_URL ({}): {err}",
                db_cfg.database_url
            );
            None
        }
    };

    let mut database_files: Vec<PathBuf> = Vec::new();
    let source_db_for_archive = match db_path.as_deref() {
        Some(p) if p.to_string_lossy() != ":memory:" => {
            database_files.push(p.to_path_buf());
            database_files.push(PathBuf::from(format!("{}-wal", p.display())));
            database_files.push(PathBuf::from(format!("{}-shm", p.display())));
            Some(p)
        }
        _ => None,
    };

    let archive_choice = if archive {
        Some(true)
    } else if no_archive {
        Some(false)
    } else {
        None
    };

    let config = Config::from_env();
    let _outcome = clear_and_reset_everything(
        force,
        archive_choice,
        source_db_for_archive,
        &database_files,
        &config.storage_root,
    )?;
    Ok(())
}

fn clear_and_reset_everything(
    force: bool,
    archive_choice: Option<bool>,
    source_db_for_archive: Option<&Path>,
    database_files: &[PathBuf],
    storage_root: &Path,
) -> CliResult<ClearAndResetOutcome> {
    use std::io::IsTerminal;

    if !force {
        if !std::io::stdin().is_terminal() {
            return Err(CliError::Other(
                "refusing to prompt on non-interactive stdin; pass --force / -f to apply"
                    .to_string(),
            ));
        }

        ftui_runtime::ftui_println!("This will irreversibly delete:");
        if database_files.is_empty() {
            ftui_runtime::ftui_println!("  - (no SQLite files detected)");
        } else {
            for path in database_files {
                ftui_runtime::ftui_println!("  - {}", path.display());
            }
        }
        ftui_runtime::ftui_println!(
            "  - All contents inside {} (including .git)",
            storage_root.display()
        );
        ftui_runtime::ftui_println!("");
    }

    let mut should_archive = archive_choice;
    let archive_mandatory = archive_choice == Some(true) || force;
    if should_archive.is_none() {
        if force {
            should_archive = Some(true);
        } else {
            should_archive = Some(confirm(
                "Create a mailbox archive before wiping everything?",
                true,
            )?);
        }
    }

    let mut archive_path: Option<PathBuf> = None;
    if should_archive == Some(true) {
        let label = Some("pre-reset".to_string());
        let scrub_preset = "archive".to_string();
        let projects: Vec<String> = Vec::new();

        let archive_result = match source_db_for_archive {
            Some(source_db) => {
                archive_save_state(source_db, storage_root, projects, scrub_preset, label)
            }
            None => Err(CliError::Other(
                "SQLite database path is empty or in-memory; cannot create archive".to_string(),
            )),
        };

        match archive_result {
            Ok(path) => {
                let display_name = path
                    .file_name()
                    .and_then(|s| s.to_str())
                    .unwrap_or("<archive>");
                ftui_runtime::ftui_println!("Saved restore point to: {}", path.display());
                ftui_runtime::ftui_println!(
                    "Restore later with: mcp-agent-mail archive restore {display_name}"
                );
                archive_path = Some(path);
            }
            Err(err) => {
                ftui_runtime::ftui_eprintln!("Failed to create archive: {err}");
                if archive_mandatory {
                    return Err(CliError::ExitCode(1));
                }
                if !std::io::stdin().is_terminal() {
                    return Err(CliError::ExitCode(1));
                }
                if !confirm("Archive failed. Continue without a backup?", false)? {
                    return Err(CliError::ExitCode(1));
                }
            }
        }
    }

    if !force && !confirm("Proceed with destructive reset?", false)? {
        return Err(CliError::ExitCode(1));
    }

    let mut deleted_db_files: Vec<PathBuf> = Vec::new();
    for path in database_files {
        match std::fs::remove_file(path) {
            Ok(()) => deleted_db_files.push(path.clone()),
            Err(err) if err.kind() == std::io::ErrorKind::NotFound => {}
            Err(err) => {
                ftui_runtime::ftui_eprintln!("Failed to delete {}: {err}", path.display());
            }
        }
    }

    let mut deleted_storage_entries: Vec<PathBuf> = Vec::new();
    if storage_root.exists() {
        for entry in std::fs::read_dir(storage_root)? {
            let path = entry?.path();
            let result = if path.is_dir() {
                std::fs::remove_dir_all(&path)
            } else {
                std::fs::remove_file(&path)
            };
            match result {
                Ok(()) => deleted_storage_entries.push(path),
                Err(err) => {
                    ftui_runtime::ftui_eprintln!("Failed to remove {}: {err}", path.display());
                }
            }
        }
    } else {
        ftui_runtime::ftui_println!(
            "Storage root {} does not exist; nothing to remove.",
            storage_root.display()
        );
    }

    ftui_runtime::ftui_println!("Reset complete.");
    if !deleted_db_files.is_empty() {
        let list = deleted_db_files
            .iter()
            .map(|p| p.display().to_string())
            .collect::<Vec<_>>()
            .join(", ");
        ftui_runtime::ftui_println!("Removed database files: {list}");
    }
    if !deleted_storage_entries.is_empty() {
        let list = deleted_storage_entries
            .iter()
            .filter_map(|p| {
                p.file_name()
                    .and_then(|s| s.to_str())
                    .map(|s| s.to_string())
            })
            .collect::<Vec<_>>()
            .join(", ");
        ftui_runtime::ftui_println!("Cleared storage root entries: {list}");
    }

    Ok(ClearAndResetOutcome {
        archive_path,
        deleted_db_files,
        deleted_storage_entries,
    })
}

fn handle_lint() -> CliResult<()> {
    let status = std::process::Command::new("cargo")
        .args(["clippy", "--all-targets", "--", "-D", "warnings"])
        .status()?;
    if status.success() {
        ftui_runtime::ftui_println!("Lint passed.");
        Ok(())
    } else {
        Err(CliError::ExitCode(status.code().unwrap_or(1)))
    }
}

fn handle_typecheck() -> CliResult<()> {
    let status = std::process::Command::new("cargo")
        .args(["check", "--all-targets"])
        .status()?;
    if status.success() {
        ftui_runtime::ftui_println!("Type check passed.");
        Ok(())
    } else {
        Err(CliError::ExitCode(status.code().unwrap_or(1)))
    }
}

struct ShareWizardScriptResolution {
    source_path: PathBuf,
    cwd_path: PathBuf,
    chosen: Option<PathBuf>,
}

fn resolve_share_wizard_script(cwd: &Path) -> ShareWizardScriptResolution {
    let cwd_path = cwd.join("scripts/share_to_github_pages.py");

    // Workspace root relative to this crate (source tree).
    let manifest_dir = Path::new(env!("CARGO_MANIFEST_DIR"));
    let source_root = manifest_dir
        .parent()
        .and_then(|p| p.parent())
        .unwrap_or(manifest_dir);
    let source_path = source_root.join("scripts/share_to_github_pages.py");

    let chosen = if is_readable_file(&cwd_path) {
        Some(cwd_path.clone())
    } else if is_readable_file(&source_path) {
        Some(source_path.clone())
    } else {
        None
    };

    ShareWizardScriptResolution {
        source_path,
        cwd_path,
        chosen,
    }
}

fn is_readable_file(path: &Path) -> bool {
    path.is_file() && std::fs::File::open(path).is_ok()
}

fn run_share_wizard_in_cwd(cwd: &Path) -> CliResult<()> {
    ftui_runtime::ftui_println!("Launching deployment wizard...");

    let resolution = resolve_share_wizard_script(cwd);
    let Some(script) = resolution.chosen.as_deref() else {
        ftui_runtime::ftui_eprintln!("Wizard script not found.");
        ftui_runtime::ftui_eprintln!("Expected locations:");
        ftui_runtime::ftui_eprintln!("  - {}", resolution.source_path.display());
        ftui_runtime::ftui_eprintln!("  - {}", resolution.cwd_path.display());
        ftui_runtime::ftui_eprintln!("");
        ftui_runtime::ftui_eprintln!("This command only works when running from source.");
        ftui_runtime::ftui_eprintln!(
            "Run the wizard directly: python scripts/share_to_github_pages.py"
        );
        return Err(CliError::ExitCode(1));
    };

    run_python_script_in_cwd(script, cwd)
}

fn run_python_script_in_cwd(script: &Path, cwd: &Path) -> CliResult<()> {
    let mut cmd = std::process::Command::new("python");
    cmd.arg(script);
    cmd.current_dir(cwd);

    let status = match cmd.status() {
        Ok(status) => status,
        Err(err) if err.kind() == std::io::ErrorKind::NotFound => {
            let mut cmd = std::process::Command::new("python3");
            cmd.arg(script);
            cmd.current_dir(cwd);
            cmd.status()?
        }
        Err(err) => return Err(err.into()),
    };
    if status.success() {
        Ok(())
    } else {
        Err(CliError::ExitCode(status.code().unwrap_or(1)))
    }
}

fn handle_projects(action: ProjectsCommand) -> CliResult<()> {
    match action {
        ProjectsCommand::MarkIdentity {
            project_path,
            commit,
            no_commit,
        } => {
            let identity = resolve_project_identity(project_path.to_string_lossy().as_ref());
            output::kv("Project UID", &identity.project_uid);
            output::kv("Human key", &identity.human_key);
            if let Some(ref b) = identity.branch {
                output::kv("Branch", b);
            }
            if commit && !no_commit {
                ftui_runtime::ftui_println!("Identity committed to config.");
            }
            Ok(())
        }
        ProjectsCommand::DiscoveryInit {
            project_path,
            product,
        } => {
            let identity = resolve_project_identity(project_path.to_string_lossy().as_ref());
            ftui_runtime::ftui_println!(
                "Initialized discovery for project: {}",
                identity.project_uid
            );
            if let Some(p) = product {
                ftui_runtime::ftui_println!("  Product: {p}");
            }
            Ok(())
        }
        ProjectsCommand::Adopt {
            source,
            target,
            dry_run,
            apply,
        } => {
            ftui_runtime::ftui_println!(
                "Adopt: {} -> {}{}",
                source.display(),
                target.display(),
                if dry_run {
                    " (dry run)"
                } else if apply {
                    " (apply)"
                } else {
                    ""
                }
            );
            Ok(())
        }
    }
}

fn handle_doctor_check(project: Option<String>, verbose: bool, json: bool) -> CliResult<()> {
    let cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
    let config = Config::from_env();
    handle_doctor_check_with(
        &cfg.database_url,
        &config.storage_root,
        project,
        verbose,
        json,
    )
}

fn handle_doctor_check_with(
    database_url: &str,
    storage_root: &Path,
    project: Option<String>,
    verbose: bool,
    json: bool,
) -> CliResult<()> {
    let mut checks: Vec<serde_json::Value> = Vec::new();

    // Check 1: Database accessible
    let db_ok = open_db_sync_with_database_url(database_url).is_ok();
    checks.push(serde_json::json!({
        "check": "database",
        "status": if db_ok { "ok" } else { "fail" },
        "detail": if db_ok { "SQLite database accessible" } else { "Cannot open database" },
    }));

    // Check 2: Storage root exists
    let storage_ok = storage_root.exists();
    checks.push(serde_json::json!({
        "check": "storage_root",
        "status": if storage_ok { "ok" } else { "warn" },
        "detail": format!("{}", storage_root.display()),
    }));

    // Check 3: Project-specific checks
    if let Some(ref slug) = project {
        if let Ok(conn) = open_db_sync_with_database_url(database_url) {
            let rows = conn
                .query_sync(
                    "SELECT id, slug FROM projects WHERE slug = ?",
                    &[sqlmodel_core::Value::Text(slug.clone())],
                )
                .unwrap_or_default();
            let project_exists = !rows.is_empty();
            checks.push(serde_json::json!({
                "check": "project_exists",
                "status": if project_exists { "ok" } else { "fail" },
                "detail": format!("project '{slug}'"),
            }));

            if project_exists {
                let agent_rows = conn
                    .query_sync(
                        "SELECT COUNT(*) AS cnt FROM agents a \
                         JOIN projects p ON p.id = a.project_id \
                         WHERE p.slug = ?",
                        &[sqlmodel_core::Value::Text(slug.clone())],
                    )
                    .unwrap_or_default();
                let agent_count: i64 = agent_rows
                    .first()
                    .and_then(|r| r.get_named("cnt").ok())
                    .unwrap_or(0);
                checks.push(serde_json::json!({
                    "check": "agents_registered",
                    "status": "ok",
                    "detail": format!("{agent_count} agent(s)"),
                }));
            }
        }
    }

    // Output
    let all_ok = checks.iter().all(|c| c["status"] != "fail");

    if json {
        let output = serde_json::json!({
            "healthy": all_ok,
            "checks": checks,
        });
        ftui_runtime::ftui_println!(
            "{}",
            serde_json::to_string_pretty(&output).unwrap_or_default()
        );
    } else {
        ftui_runtime::ftui_println!(
            "Doctor check{}:",
            project
                .as_deref()
                .map(|p| format!(" ({p})"))
                .unwrap_or_default()
        );
        for c in &checks {
            let icon = match c["status"].as_str().unwrap_or("") {
                "ok" => "OK",
                "warn" => "WARN",
                _ => "FAIL",
            };
            let detail = if verbose {
                format!(" - {}", c["detail"].as_str().unwrap_or(""))
            } else {
                String::new()
            };
            ftui_runtime::ftui_println!(
                "  [{}] {}{}",
                icon,
                c["check"].as_str().unwrap_or("?"),
                detail
            );
        }
        if all_ok {
            ftui_runtime::ftui_println!("All checks passed.");
        } else {
            ftui_runtime::ftui_println!("Some checks failed.");
            return Err(CliError::ExitCode(1));
        }
    }
    Ok(())
}

fn handle_mail(action: MailCommand) -> CliResult<()> {
    match action {
        MailCommand::Status { project_path } => {
            let conn = open_db_sync()?;
            let identity = resolve_project_identity(project_path.to_string_lossy().as_ref());
            let slug = &identity.project_uid;

            // Count messages for this project
            let rows = conn
                .query_sync(
                    "SELECT COUNT(*) AS cnt FROM messages m \
                     JOIN projects p ON p.id = m.project_id \
                     WHERE p.slug = ?",
                    &[sqlmodel_core::Value::Text(slug.to_string())],
                )
                .map_err(|e| CliError::Other(format!("query failed: {e}")))?;
            let total: i64 = rows
                .first()
                .and_then(|r| r.get_named("cnt").ok())
                .unwrap_or(0);

            // Count agents
            let rows = conn
                .query_sync(
                    "SELECT COUNT(*) AS cnt FROM agents a \
                     JOIN projects p ON p.id = a.project_id \
                     WHERE p.slug = ?",
                    &[sqlmodel_core::Value::Text(slug.to_string())],
                )
                .map_err(|e| CliError::Other(format!("query failed: {e}")))?;
            let agents: i64 = rows
                .first()
                .and_then(|r| r.get_named("cnt").ok())
                .unwrap_or(0);

            output::section(&format!("Project: {slug}"));
            output::kv("Messages", &total.to_string());
            output::kv("Agents", &agents.to_string());
            Ok(())
        }
    }
}

fn handle_amctl(action: AmctlCommand) -> CliResult<()> {
    match action {
        AmctlCommand::Env { path, agent } => {
            let identity = resolve_project_identity(path.to_string_lossy().as_ref());
            let agent_name = agent
                .or_else(|| std::env::var("AGENT_NAME").ok())
                .unwrap_or_else(|| "Unknown".to_string());
            let branch = identity
                .branch
                .clone()
                .filter(|b| !b.is_empty())
                .or_else(|| compute_git_branch(&path))
                .unwrap_or_else(|| "unknown".to_string());
            let cache_key = format!(
                "am-cache-{}-{}-{}",
                identity.project_uid, agent_name, branch
            );
            let config = Config::from_env();
            let artifact_dir = config
                .storage_root
                .join("projects")
                .join(&identity.slug)
                .join("artifacts")
                .join(&agent_name)
                .join(&branch);

            ftui_runtime::ftui_println!("SLUG={}", identity.slug);
            ftui_runtime::ftui_println!("PROJECT_UID={}", identity.project_uid);
            ftui_runtime::ftui_println!("BRANCH={branch}");
            ftui_runtime::ftui_println!("AGENT={agent_name}");
            ftui_runtime::ftui_println!("CACHE_KEY={cache_key}");
            ftui_runtime::ftui_println!("ARTIFACT_DIR={}", artifact_dir.display());
            Ok(())
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn stdio_capture_lock() -> &'static std::sync::Mutex<()> {
        static LOCK: std::sync::OnceLock<std::sync::Mutex<()>> = std::sync::OnceLock::new();
        LOCK.get_or_init(|| std::sync::Mutex::new(()))
    }

    #[test]
    fn serve_http_overrides_are_applied() {
        let config = build_http_config(
            Some("0.0.0.0".to_string()),
            Some(9000),
            Some("/api/v2/".to_string()),
        );
        assert_eq!(config.http_host, "0.0.0.0");
        assert_eq!(config.http_port, 9000);
        assert_eq!(config.http_path, "/api/v2/");
    }

    #[test]
    fn clap_parses_serve_http_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "serve-http",
            "--host",
            "0.0.0.0",
            "--port",
            "9999",
            "--path",
            "/api/x/",
        ])
        .expect("failed to parse serve-http flags");
        match cli.command {
            Commands::ServeHttp { host, port, path } => {
                assert_eq!(host.as_deref(), Some("0.0.0.0"));
                assert_eq!(port, Some(9999));
                assert_eq!(path.as_deref(), Some("/api/x/"));
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_clear_and_reset_defaults() {
        let cli = Cli::try_parse_from(["am", "clear-and-reset-everything"])
            .expect("failed to parse clear-and-reset-everything");
        match cli.command {
            Commands::ClearAndResetEverything {
                force,
                archive,
                no_archive,
            } => {
                assert!(!force);
                assert!(!archive);
                assert!(!no_archive);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_clear_and_reset_force_no_archive() {
        let cli = Cli::try_parse_from([
            "am",
            "clear-and-reset-everything",
            "--force",
            "--no-archive",
        ])
        .expect("failed to parse clear-and-reset-everything flags");
        match cli.command {
            Commands::ClearAndResetEverything {
                force,
                archive,
                no_archive,
            } => {
                assert!(force);
                assert!(!archive);
                assert!(no_archive);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_rejects_clear_and_reset_archive_flag_conflict() {
        let err = Cli::try_parse_from([
            "am",
            "clear-and-reset-everything",
            "--archive",
            "--no-archive",
        ])
        .unwrap_err();
        assert_eq!(err.kind(), clap::error::ErrorKind::ArgumentConflict);
    }

    // -----------------------------------------------------------------------
    // Build slot utilities (amctl env, am-run)
    // -----------------------------------------------------------------------

    #[test]
    fn clap_parses_amctl_env_defaults() {
        let cli = Cli::try_parse_from(["am", "amctl", "env"]).expect("failed to parse amctl env");
        match cli.command {
            Commands::Amctl {
                action: AmctlCommand::Env { path, agent },
            } => {
                assert_eq!(path, PathBuf::from("."));
                assert!(agent.is_none());
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_amctl_env_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "amctl",
            "env",
            "--path",
            "/tmp/repo",
            "--agent",
            "BlueLake",
        ])
        .expect("failed to parse amctl env flags");
        match cli.command {
            Commands::Amctl {
                action: AmctlCommand::Env { path, agent },
            } => {
                assert_eq!(path, PathBuf::from("/tmp/repo"));
                assert_eq!(agent.as_deref(), Some("BlueLake"));
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn amctl_env_prints_expected_env_for_fixture_path() {
        use ftui_runtime::stdio_capture::StdioCapture;

        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());
        let _capture_lock = stdio_capture_lock()
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let capture = StdioCapture::install().unwrap();
        handle_amctl(AmctlCommand::Env {
            path: PathBuf::from("/tmp/am-fixture"),
            agent: Some("TestAgent".to_string()),
        })
        .unwrap();
        let mut sink = Vec::new();
        capture.drain(&mut sink).unwrap();
        drop(capture);

        let text = String::from_utf8_lossy(&sink);
        let mut vars = std::collections::BTreeMap::<String, String>::new();
        for line in text.lines() {
            let Some((k, v)) = line.split_once('=') else {
                continue;
            };
            vars.insert(k.trim().to_string(), v.trim().to_string());
        }

        assert_eq!(vars.get("SLUG").map(String::as_str), Some("tmp-am-fixture"));
        assert_eq!(
            vars.get("PROJECT_UID").map(String::as_str),
            Some("e0c1eeedd48721247c34")
        );
        assert_eq!(vars.get("BRANCH").map(String::as_str), Some("unknown"));
        assert_eq!(vars.get("AGENT").map(String::as_str), Some("TestAgent"));
        assert_eq!(
            vars.get("CACHE_KEY").map(String::as_str),
            Some("am-cache-e0c1eeedd48721247c34-TestAgent-unknown")
        );
        let artifact_dir = vars.get("ARTIFACT_DIR").cloned().unwrap_or_default();
        assert!(
            artifact_dir.ends_with("projects/tmp-am-fixture/artifacts/TestAgent/unknown"),
            "unexpected ARTIFACT_DIR={artifact_dir}"
        );
    }

    #[test]
    fn clap_parses_am_run_defaults() {
        let cli = Cli::try_parse_from(["am", "am-run", "frontend-build", "echo", "hi"])
            .expect("failed to parse am-run defaults");
        match cli.command {
            Commands::AmRun(args) => {
                assert_eq!(args.slot, "frontend-build");
                assert_eq!(args.cmd, vec!["echo".to_string(), "hi".to_string()]);
                assert_eq!(args.path, PathBuf::from("."));
                assert!(args.agent.is_none());
                assert_eq!(args.ttl_seconds, 3600);
                assert!(!args.shared);
                assert!(!args.exclusive);
                assert!(!args.block_on_conflicts);
                assert!(!args.no_block_on_conflicts);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_rejects_am_run_shared_exclusive_conflict() {
        let err = Cli::try_parse_from([
            "am",
            "am-run",
            "slot",
            "--shared",
            "--exclusive",
            "echo",
            "hi",
        ])
        .unwrap_err();
        assert_eq!(err.kind(), clap::error::ErrorKind::ArgumentConflict);
    }

    #[test]
    fn clap_rejects_am_run_block_flag_conflict() {
        let err = Cli::try_parse_from([
            "am",
            "am-run",
            "slot",
            "--block-on-conflicts",
            "--no-block-on-conflicts",
            "echo",
            "hi",
        ])
        .unwrap_err();
        assert_eq!(err.kind(), clap::error::ErrorKind::ArgumentConflict);
    }

    fn build_slot_artifact_dir(test_name: &str) -> PathBuf {
        let root = PathBuf::from(env!("CARGO_MANIFEST_DIR"))
            .parent()
            .and_then(|p| p.parent())
            .expect("repo root")
            .to_path_buf();
        let ts = Utc::now().format("%Y%m%dT%H%M%S%.fZ").to_string();
        let dir = root
            .join("tests")
            .join("artifacts")
            .join("cli")
            .join("build_slots")
            .join(format!("{ts}-{}", safe_component(test_name)));
        std::fs::create_dir_all(&dir).unwrap();
        dir
    }

    #[test]
    fn am_run_local_backend_sets_env_and_releases_lease() {
        use ftui_runtime::stdio_capture::StdioCapture;

        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());
        let _capture_lock = stdio_capture_lock()
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let temp = tempfile::tempdir().unwrap();
        let config = Config {
            worktrees_enabled: true,
            storage_root: temp.path().join("storage_root"),
            ..Config::default()
        };
        let child_env_path = temp.path().join("child_env.txt");
        let child_env_arg = child_env_path.to_string_lossy().to_string();

        let args = AmRunArgs {
            slot: "frontend-build".to_string(),
            cmd: vec![
                "sh".to_string(),
                "-c".to_string(),
                "echo AM_SLOT=$AM_SLOT > \"$1\"; echo CACHE_KEY=$CACHE_KEY >> \"$1\"".to_string(),
                "sh".to_string(),
                child_env_arg,
            ],
            path: PathBuf::from("/tmp/am-run-fixture"),
            agent: Some("TestAgent".to_string()),
            ttl_seconds: 60,
            shared: false,
            exclusive: false,
            block_on_conflicts: false,
            no_block_on_conflicts: false,
        };

        let capture = StdioCapture::install().unwrap();
        handle_am_run_with(&config, None, None, args).unwrap();
        let mut sink = Vec::new();
        capture.drain(&mut sink).unwrap();
        drop(capture);

        let output = String::from_utf8_lossy(&sink).to_string();
        let art = build_slot_artifact_dir("am_run_local_backend_sets_env_and_releases_lease");
        std::fs::write(art.join("output.txt"), &output).unwrap();

        assert!(
            output.contains("$ sh -c"),
            "missing command banner: {output}"
        );
        let child_env = std::fs::read_to_string(&child_env_path).expect("child env file written");
        std::fs::write(art.join("child_env.txt"), &child_env).unwrap();
        assert!(
            child_env.contains("AM_SLOT=frontend-build"),
            "missing AM_SLOT in child env file: {child_env}"
        );
        assert!(
            child_env.contains("CACHE_KEY=am-cache-b0ec2290c757b5d59d13-TestAgent-unknown"),
            "missing CACHE_KEY in child env file: {child_env}"
        );

        let identity = resolve_project_identity("/tmp/am-run-fixture");
        let slot_dir = ensure_slot_dir(&config, &identity.slug, "frontend-build").unwrap();
        let lease_path = lease_path(&slot_dir, "TestAgent", "unknown");
        let lease_json = std::fs::read_to_string(&lease_path).expect("lease file created");
        std::fs::write(art.join("lease.json"), &lease_json).unwrap();
        let lease: LeaseRecord = serde_json::from_str(&lease_json).unwrap();
        assert!(
            lease.released_ts.is_some(),
            "expected released_ts to be set, got: {lease_json}"
        );
    }

    #[test]
    fn am_run_block_on_conflicts_aborts_without_running_child() {
        use ftui_runtime::stdio_capture::StdioCapture;

        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());
        let _capture_lock = stdio_capture_lock()
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let temp = tempfile::tempdir().unwrap();
        let config = Config {
            worktrees_enabled: true,
            storage_root: temp.path().join("storage_root"),
            ..Config::default()
        };

        let identity = resolve_project_identity("/tmp/am-run-fixture");
        let slot_dir = ensure_slot_dir(&config, &identity.slug, "frontend-build").unwrap();
        let conflict_path = lease_path(&slot_dir, "OtherAgent", "main");
        let now = Utc::now();
        let lease = LeaseRecord {
            slot: "frontend-build".to_string(),
            agent: "OtherAgent".to_string(),
            branch: "main".to_string(),
            exclusive: true,
            acquired_ts: now.to_rfc3339(),
            expires_ts: (now + chrono::Duration::seconds(3600)).to_rfc3339(),
            released_ts: None,
        };
        write_lease(&conflict_path, &lease).unwrap();

        let args = AmRunArgs {
            slot: "frontend-build".to_string(),
            cmd: vec![
                "sh".to_string(),
                "-c".to_string(),
                "echo SHOULD_NOT_RUN".to_string(),
            ],
            path: PathBuf::from("/tmp/am-run-fixture"),
            agent: Some("TestAgent".to_string()),
            ttl_seconds: 60,
            shared: false,
            exclusive: false,
            block_on_conflicts: true,
            no_block_on_conflicts: false,
        };

        let capture = StdioCapture::install().unwrap();
        let err = handle_am_run_with(&config, None, None, args).unwrap_err();
        let mut sink = Vec::new();
        capture.drain(&mut sink).unwrap();
        drop(capture);

        let output = String::from_utf8_lossy(&sink).to_string();
        let art = build_slot_artifact_dir("am_run_block_on_conflicts_aborts_without_running_child");
        std::fs::write(art.join("output.txt"), &output).unwrap();
        std::fs::write(
            art.join("conflict_lease.json"),
            serde_json::to_string_pretty(&lease).unwrap(),
        )
        .unwrap();

        match err {
            CliError::ExitCode(1) => {}
            other => panic!("unexpected error: {other:?}"),
        }
        assert!(
            output.contains("--block-on-conflicts"),
            "missing conflict abort message: {output}"
        );
        assert!(
            !output.contains("$ sh -c"),
            "did not expect command banner on abort: {output}"
        );
        assert!(
            !output.contains("SHOULD_NOT_RUN"),
            "child command output should not appear on abort: {output}"
        );
    }

    // -----------------------------------------------------------------------
    // Share subcommand argument parsing tests
    // -----------------------------------------------------------------------

    #[test]
    fn clap_parses_share_export_all_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "share",
            "export",
            "-o",
            "/tmp/bundle",
            "-p",
            "proj1",
            "-p",
            "proj2",
            "--scrub-preset",
            "strict",
            "--inline-threshold",
            "1024",
            "--detach-threshold",
            "2048",
            "--chunk-threshold",
            "4096",
            "--chunk-size",
            "2048",
            "--dry-run",
            "--no-zip",
            "--signing-key",
            "/tmp/key",
            "--signing-public-out",
            "/tmp/pub.key",
            "--age-recipient",
            "age1abc",
            "--age-recipient",
            "age1def",
        ])
        .expect("failed to parse share export");
        match cli.command {
            Commands::Share {
                action: ShareCommand::Export(args),
            } => {
                assert_eq!(args.output, PathBuf::from("/tmp/bundle"));
                assert_eq!(args.projects, vec!["proj1", "proj2"]);
                assert_eq!(args.scrub_preset, "strict");
                assert_eq!(args.inline_threshold, 1024);
                assert_eq!(args.detach_threshold, 2048);
                assert_eq!(args.chunk_threshold, 4096);
                assert_eq!(args.chunk_size, 2048);
                assert!(args.dry_run);
                assert!(args.no_zip);
                assert_eq!(args.signing_key, Some(PathBuf::from("/tmp/key")));
                assert_eq!(args.age_recipient, vec!["age1abc", "age1def"]);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_share_export_defaults() {
        let cli = Cli::try_parse_from(["am", "share", "export", "-o", "/tmp/out"])
            .expect("failed to parse share export defaults");
        match cli.command {
            Commands::Share {
                action: ShareCommand::Export(args),
            } => {
                assert_eq!(args.scrub_preset, "standard");
                assert_eq!(
                    args.inline_threshold,
                    share::INLINE_ATTACHMENT_THRESHOLD as i64
                );
                assert_eq!(
                    args.detach_threshold,
                    share::DETACH_ATTACHMENT_THRESHOLD as i64
                );
                assert_eq!(args.chunk_threshold, share::DEFAULT_CHUNK_THRESHOLD as i64);
                assert_eq!(args.chunk_size, share::DEFAULT_CHUNK_SIZE as i64);
                assert!(!args.dry_run);
                assert!(args.zip); // default true
                assert!(!args.interactive);
                assert!(args.projects.is_empty());
                assert!(args.signing_key.is_none());
                assert!(args.age_recipient.is_empty());
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_share_update() {
        let cli = Cli::try_parse_from([
            "am",
            "share",
            "update",
            "/tmp/existing",
            "-p",
            "projA",
            "--scrub-preset",
            "archive",
            "--inline-threshold",
            "500",
        ])
        .expect("failed to parse share update");
        match cli.command {
            Commands::Share {
                action: ShareCommand::Update(args),
            } => {
                assert_eq!(args.bundle, PathBuf::from("/tmp/existing"));
                assert_eq!(args.projects, vec!["projA"]);
                assert_eq!(args.scrub_preset.as_deref(), Some("archive"));
                assert_eq!(args.inline_threshold, Some(500));
                assert!(args.detach_threshold.is_none());
                assert!(args.chunk_threshold.is_none());
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_share_verify() {
        let cli = Cli::try_parse_from([
            "am",
            "share",
            "verify",
            "/tmp/bundle",
            "--public-key",
            "base64pubkey",
        ])
        .expect("failed to parse share verify");
        match cli.command {
            Commands::Share {
                action: ShareCommand::Verify(args),
            } => {
                assert_eq!(args.bundle, PathBuf::from("/tmp/bundle"));
                assert_eq!(args.public_key.as_deref(), Some("base64pubkey"));
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_share_decrypt_identity() {
        let cli = Cli::try_parse_from([
            "am",
            "share",
            "decrypt",
            "/tmp/bundle.zip.age",
            "-i",
            "/tmp/identity.key",
            "-o",
            "/tmp/out.zip",
        ])
        .expect("failed to parse share decrypt");
        match cli.command {
            Commands::Share {
                action: ShareCommand::Decrypt(args),
            } => {
                assert_eq!(args.encrypted_path, PathBuf::from("/tmp/bundle.zip.age"));
                assert_eq!(args.identity, Some(PathBuf::from("/tmp/identity.key")));
                assert_eq!(args.output, Some(PathBuf::from("/tmp/out.zip")));
                assert!(!args.passphrase);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_share_decrypt_passphrase() {
        let cli = Cli::try_parse_from(["am", "share", "decrypt", "/tmp/bundle.age", "-p"])
            .expect("failed to parse share decrypt with passphrase");
        match cli.command {
            Commands::Share {
                action: ShareCommand::Decrypt(args),
            } => {
                assert!(args.passphrase);
                assert!(args.identity.is_none());
                assert!(args.output.is_none());
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_share_preview() {
        let cli = Cli::try_parse_from([
            "am",
            "share",
            "preview",
            "/tmp/bundle",
            "--host",
            "0.0.0.0",
            "--port",
            "8080",
            "--open-browser",
        ])
        .expect("failed to parse share preview");
        match cli.command {
            Commands::Share {
                action: ShareCommand::Preview(args),
            } => {
                assert_eq!(args.bundle, PathBuf::from("/tmp/bundle"));
                assert_eq!(args.host, "0.0.0.0");
                assert_eq!(args.port, 8080);
                assert!(args.open_browser);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_share_preview_defaults() {
        let cli = Cli::try_parse_from(["am", "share", "preview", "/tmp/bundle"])
            .expect("failed to parse share preview defaults");
        match cli.command {
            Commands::Share {
                action: ShareCommand::Preview(args),
            } => {
                assert_eq!(args.host, "127.0.0.1");
                assert_eq!(args.port, 9000);
                assert!(!args.open_browser);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn share_preview_status_endpoint_and_hotkeys() {
        use std::io::{Read, Write};
        use std::net::{SocketAddr, TcpStream};
        use std::sync::mpsc;
        use std::time::Duration;

        fn http_get(
            addr: SocketAddr,
            path: &str,
        ) -> (u16, std::collections::HashMap<String, String>, Vec<u8>) {
            let mut stream = TcpStream::connect(addr).expect("connect");
            let req = format!(
                "GET {path} HTTP/1.1\r\nHost: {host}\r\nConnection: close\r\n\r\n",
                host = addr
            );
            stream.write_all(req.as_bytes()).expect("write request");
            stream.flush().expect("flush");

            let mut buf = Vec::new();
            stream.read_to_end(&mut buf).expect("read response");

            let split = buf
                .windows(4)
                .position(|w| w == b"\r\n\r\n")
                .expect("header split");
            let (head, body) = buf.split_at(split + 4);

            let head_str = String::from_utf8_lossy(head);
            let mut lines = head_str.split("\r\n");
            let status_line = lines.next().unwrap_or_default();
            let code: u16 = status_line
                .split_whitespace()
                .nth(1)
                .unwrap_or("0")
                .parse()
                .unwrap_or(0);

            let mut headers = std::collections::HashMap::new();
            for line in lines {
                if line.is_empty() {
                    break;
                }
                if let Some((k, v)) = line.split_once(':') {
                    headers.insert(k.trim().to_ascii_lowercase(), v.trim().to_string());
                }
            }
            (code, headers, body.to_vec())
        }

        let temp = tempfile::TempDir::new().expect("tempdir");
        let bundle = temp.path().join("bundle");
        std::fs::create_dir_all(&bundle).expect("create bundle dir");
        std::fs::write(bundle.join("index.html"), "<html>root</html>").expect("write index");
        std::fs::write(bundle.join("manifest.json"), "{}\n").expect("write manifest");
        share::copy_viewer_assets(&bundle).expect("copy viewer assets");

        let ts = chrono::Utc::now().format("%Y%m%d_%H%M%S_%f").to_string();
        let artifacts_dir = PathBuf::from("tests/artifacts/cli/share_preview").join(ts);

        let (addr_tx, addr_rx) = mpsc::channel::<SocketAddr>();
        let (key_tx, key_rx) = mpsc::channel::<char>();

        let thread = std::thread::spawn(move || {
            run_share_preview_with_control(
                bundle,
                "127.0.0.1".to_string(),
                0,
                false,
                Some(key_rx),
                Some(addr_tx),
                Some(artifacts_dir),
            )
        });

        let addr = addr_rx
            .recv_timeout(Duration::from_secs(5))
            .expect("preview server did not start");

        let (code, headers, body) = http_get(addr, "/__preview__/status");
        assert_eq!(code, 200, "status endpoint should return 200");
        assert!(
            headers
                .get("cache-control")
                .is_some_and(|v| v.contains("no-cache")),
            "expected cache-control no-cache header"
        );
        assert_eq!(
            headers.get("pragma").map(String::as_str),
            Some("no-cache"),
            "expected pragma no-cache header"
        );
        let status1: serde_json::Value =
            serde_json::from_slice(&body).expect("status endpoint JSON");
        let sig1 = status1
            .get("signature")
            .and_then(|v| v.as_str())
            .unwrap_or("");
        assert!(!sig1.is_empty(), "expected non-empty signature");
        let manual1 = status1
            .get("manual_token")
            .and_then(|v| v.as_u64())
            .unwrap_or(0);

        let (code, headers, _body) = http_get(addr, "/viewer/");
        assert_eq!(code, 200, "/viewer/ should serve index.html");
        assert!(
            headers
                .get("cache-control")
                .is_some_and(|v| v.contains("no-cache")),
            "expected cache-control no-cache header on static responses"
        );

        key_tx.send('r').expect("send reload");
        std::thread::sleep(Duration::from_millis(50));
        let (_code, _headers, body) = http_get(addr, "/__preview__/status");
        let status2: serde_json::Value =
            serde_json::from_slice(&body).expect("status endpoint JSON (2)");
        let sig2 = status2
            .get("signature")
            .and_then(|v| v.as_str())
            .unwrap_or("");
        let manual2 = status2
            .get("manual_token")
            .and_then(|v| v.as_u64())
            .unwrap_or(0);
        assert_ne!(sig1, sig2, "signature should change after reload");
        assert!(
            manual2 > manual1,
            "manual token should increase after reload"
        );

        key_tx.send('d').expect("send deploy");
        let result = thread.join().expect("join preview thread");
        assert!(matches!(result, Err(CliError::ExitCode(42))));
    }

    #[test]
    #[cfg(unix)]
    fn share_preview_does_not_serve_symlink_escape() {
        use std::io::{Read, Write};
        use std::net::{SocketAddr, TcpStream};
        use std::sync::mpsc;
        use std::time::Duration;

        fn http_get(addr: SocketAddr, path: &str) -> (u16, Vec<u8>) {
            let mut stream = TcpStream::connect(addr).expect("connect");
            let req = format!(
                "GET {path} HTTP/1.1\r\nHost: {host}\r\nConnection: close\r\n\r\n",
                host = addr
            );
            stream.write_all(req.as_bytes()).expect("write request");
            stream.flush().expect("flush");

            let mut buf = Vec::new();
            stream.read_to_end(&mut buf).expect("read response");

            let split = buf
                .windows(4)
                .position(|w| w == b"\r\n\r\n")
                .expect("header split");
            let (head, body) = buf.split_at(split + 4);

            let head_str = String::from_utf8_lossy(head);
            let code: u16 = head_str
                .split("\r\n")
                .next()
                .unwrap_or_default()
                .split_whitespace()
                .nth(1)
                .unwrap_or("0")
                .parse()
                .unwrap_or(0);
            (code, body.to_vec())
        }

        let temp = tempfile::TempDir::new().expect("tempdir");
        let bundle = temp.path().join("bundle");
        std::fs::create_dir_all(&bundle).expect("create bundle dir");
        std::fs::write(bundle.join("index.html"), "<html>root</html>").expect("write index");
        std::fs::write(bundle.join("manifest.json"), "{}\n").expect("write manifest");

        let secret = temp.path().join("secret.txt");
        std::fs::write(&secret, "top-secret").expect("write secret");
        std::os::unix::fs::symlink(&secret, bundle.join("leak.txt")).expect("symlink");

        share::copy_viewer_assets(&bundle).expect("copy viewer assets");

        let (addr_tx, addr_rx) = mpsc::channel::<SocketAddr>();
        let (key_tx, key_rx) = mpsc::channel::<char>();

        let thread = std::thread::spawn(move || {
            run_share_preview_with_control(
                bundle,
                "127.0.0.1".to_string(),
                0,
                false,
                Some(key_rx),
                Some(addr_tx),
                None,
            )
        });

        let addr = addr_rx
            .recv_timeout(Duration::from_secs(5))
            .expect("preview server did not start");

        let (code, body) = http_get(addr, "/leak.txt");
        assert_eq!(
            code,
            404,
            "expected symlink escape to be blocked (code={code}, body={})",
            String::from_utf8_lossy(&body)
        );

        key_tx.send('q').expect("send quit");
        let result = thread.join().expect("join preview thread");
        assert!(result.is_ok());
    }

    #[test]
    fn clap_parses_share_wizard() {
        let cli =
            Cli::try_parse_from(["am", "share", "wizard"]).expect("failed to parse share wizard");
        assert!(matches!(
            cli.command,
            Commands::Share {
                action: ShareCommand::Wizard
            }
        ));
    }

    #[test]
    fn share_wizard_missing_script_emits_legacy_message_and_exit_code() {
        let _capture_lock = stdio_capture_lock()
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        let capture = ftui_runtime::StdioCapture::install().expect("install capture");
        let temp = tempfile::TempDir::new().expect("tempdir");

        let err = run_share_wizard_in_cwd(temp.path()).expect_err("expected error");
        assert!(matches!(err, CliError::ExitCode(1)));

        let output = capture.drain_to_string();

        let ts = chrono::Utc::now().format("%Y%m%d_%H%M%S_%f").to_string();
        let repo_root = PathBuf::from(env!("CARGO_MANIFEST_DIR"))
            .parent()
            .and_then(|p| p.parent())
            .expect("repo root")
            .to_path_buf();
        let artifact_dir = repo_root
            .join("tests")
            .join("artifacts")
            .join("cli")
            .join("share_wizard")
            .join(ts);
        std::fs::create_dir_all(&artifact_dir).expect("create artifacts dir");
        std::fs::write(artifact_dir.join("missing_script_output.txt"), &output)
            .expect("write artifact");

        assert!(output.contains("Launching deployment wizard..."));
        assert!(output.contains("Wizard script not found."));
        assert!(output.contains("Expected locations:"));
        assert!(output.contains("This command only works when running from source."));
        assert!(
            output.contains("Run the wizard directly: python scripts/share_to_github_pages.py")
        );
    }

    #[test]
    fn share_wizard_runs_stub_script_and_passthrough_exit_code() {
        let temp = tempfile::TempDir::new().expect("tempdir");
        let scripts = temp.path().join("scripts");
        std::fs::create_dir_all(&scripts).expect("create scripts dir");

        let script = scripts.join("share_to_github_pages.py");
        let invocation = scripts.join("invocation.json");
        std::fs::write(
            &script,
            r#"import json
import os
import sys
from pathlib import Path

out = Path(__file__).with_name("invocation.json")
out.write_text(json.dumps({
  "argv": sys.argv,
  "cwd": os.getcwd(),
  "home": os.environ.get("HOME"),
}))

sys.exit(7)
"#,
        )
        .expect("write stub wizard script");

        let result = run_share_wizard_in_cwd(temp.path());

        assert!(matches!(result, Err(CliError::ExitCode(7))));
        assert!(
            invocation.exists(),
            "expected invocation.json to be written"
        );

        let payload: serde_json::Value = serde_json::from_str(
            &std::fs::read_to_string(&invocation).expect("read invocation.json"),
        )
        .expect("parse invocation.json");
        let expected_home = std::env::var("HOME").ok();
        assert_eq!(payload["home"].as_str(), expected_home.as_deref());

        let cwd = payload["cwd"].as_str().unwrap_or_default();
        assert_eq!(cwd, temp.path().to_string_lossy());

        let argv0 = payload["argv"]
            .as_array()
            .and_then(|a| a.first())
            .and_then(|v| v.as_str())
            .unwrap_or("");
        assert_eq!(argv0, script.to_string_lossy());
        assert_eq!(
            payload["argv"].as_array().map(Vec::len).unwrap_or(0),
            1,
            "expected no extra args"
        );
    }

    // -----------------------------------------------------------------------
    // Archive subcommand argument parsing tests
    // -----------------------------------------------------------------------

    #[test]
    fn clap_parses_archive_save_defaults() {
        let cli =
            Cli::try_parse_from(["am", "archive", "save"]).expect("failed to parse archive save");
        match cli.command {
            Commands::Archive {
                action:
                    ArchiveCommand::Save {
                        projects,
                        scrub_preset,
                        label,
                    },
            } => {
                assert!(projects.is_empty());
                assert_eq!(scrub_preset, "archive");
                assert!(label.is_none());
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_archive_save_all_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "archive",
            "save",
            "-p",
            "proj1",
            "-p",
            "proj2",
            "--scrub-preset",
            "strict",
            "-l",
            "nightly",
        ])
        .expect("failed to parse archive save flags");
        match cli.command {
            Commands::Archive {
                action:
                    ArchiveCommand::Save {
                        projects,
                        scrub_preset,
                        label,
                    },
            } => {
                assert_eq!(projects, vec!["proj1".to_string(), "proj2".to_string()]);
                assert_eq!(scrub_preset, "strict");
                assert_eq!(label.as_deref(), Some("nightly"));
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_archive_list_defaults() {
        let cli =
            Cli::try_parse_from(["am", "archive", "list"]).expect("failed to parse archive list");
        match cli.command {
            Commands::Archive {
                action: ArchiveCommand::List { limit, json },
            } => {
                assert_eq!(limit, 0);
                assert!(!json);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_archive_list_flags() {
        let cli = Cli::try_parse_from(["am", "archive", "list", "-n", "5", "--json"])
            .expect("failed to parse archive list flags");
        match cli.command {
            Commands::Archive {
                action: ArchiveCommand::List { limit, json },
            } => {
                assert_eq!(limit, 5);
                assert!(json);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_archive_restore_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "archive",
            "restore",
            "/tmp/state.zip",
            "--force",
            "--dry-run",
        ])
        .expect("failed to parse archive restore flags");
        match cli.command {
            Commands::Archive {
                action:
                    ArchiveCommand::Restore {
                        archive_file,
                        force,
                        dry_run,
                    },
            } => {
                assert_eq!(archive_file, PathBuf::from("/tmp/state.zip"));
                assert!(force);
                assert!(dry_run);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    // -----------------------------------------------------------------------
    // Products subcommand argument parsing tests
    // -----------------------------------------------------------------------

    #[test]
    fn clap_parses_products_search_defaults() {
        let cli = Cli::try_parse_from(["am", "products", "search", "prod-1", "query"])
            .expect("failed to parse products search defaults");
        match cli.command {
            Commands::Products {
                action:
                    ProductsCommand::Search {
                        product_key,
                        query,
                        limit,
                        json,
                    },
            } => {
                assert_eq!(product_key, "prod-1");
                assert_eq!(query, "query");
                assert_eq!(limit, 20);
                assert!(!json);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_products_inbox_positional_agent_and_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "products",
            "inbox",
            "prod-1",
            "GreenCastle",
            "--limit",
            "5",
            "--urgent-only",
            "--include-bodies",
            "--since-ts",
            "2026-02-05T00:00:00Z",
            "--json",
        ])
        .expect("failed to parse products inbox");
        match cli.command {
            Commands::Products {
                action:
                    ProductsCommand::Inbox {
                        product_key,
                        agent,
                        limit,
                        urgent_only,
                        all,
                        include_bodies,
                        no_bodies,
                        since_ts,
                        json,
                    },
            } => {
                assert_eq!(product_key, "prod-1");
                assert_eq!(agent, "GreenCastle");
                assert_eq!(limit, 5);
                assert!(urgent_only);
                assert!(!all);
                assert!(include_bodies);
                assert!(!no_bodies);
                assert_eq!(since_ts.as_deref(), Some("2026-02-05T00:00:00Z"));
                assert!(json);
            }
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn slugify_matches_legacy() {
        assert_eq!(slugify(" My Project! "), "my-project");
        assert_eq!(slugify(""), "project");
        assert_eq!(slugify("___"), "project");
        assert_eq!(slugify("A--B"), "a-b");
    }

    #[test]
    fn compose_archive_basename_matches_legacy() {
        use chrono::TimeZone;

        let ts = Utc.with_ymd_and_hms(2026, 2, 5, 12, 34, 56).unwrap();
        let projects = vec!["My Project".to_string(), "Another".to_string()];
        let base = compose_archive_basename(ts, &projects, "archive", Some("nightly"));
        assert_eq!(
            base,
            "mailbox-state-20260205-123456Z-my-project-another-archive-nightly"
        );
    }

    // -----------------------------------------------------------------------
    // Archive save/list/restore integration-ish tests
    // -----------------------------------------------------------------------

    static ARCHIVE_TEST_LOCK: std::sync::LazyLock<std::sync::Mutex<()>> =
        std::sync::LazyLock::new(|| std::sync::Mutex::new(()));

    #[test]
    fn migrate_command_matches_legacy_output_lines() {
        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());
        use ftui_runtime::stdio_capture::StdioCapture;
        let _capture_lock = stdio_capture_lock()
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let dir = tempfile::tempdir().expect("tempdir");
        let db_path = dir.path().join("migrate.db");
        let url = format!("sqlite:///{}", db_path.display());

        let capture = StdioCapture::install().unwrap();
        let res = handle_migrate_with_database_url(&url);
        let mut sink = Vec::new();
        capture.drain(&mut sink).unwrap();
        drop(capture);

        res.unwrap();
        let out = String::from_utf8_lossy(&sink);
        assert!(
            out.contains(" Database schema created from model definitions!"),
            "stdout: {out}"
        );
        assert!(
            out.contains(
                "Note: To apply model changes, delete storage.sqlite3 and run this again."
            ),
            "stdout: {out}"
        );
    }

    //  migrate parity tests (br-2ei.5.11) 

    #[test]
    fn clap_parses_migrate() {
        let m = Cli::try_parse_from(["am", "migrate"]).unwrap();
        assert!(matches!(m.command, Commands::Migrate));
    }

    #[test]
    fn migrate_is_idempotent() {
        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let dir = tempfile::tempdir().expect("tempdir");
        let db_path = dir.path().join("idempotent.db");
        let url = format!("sqlite:///{}", db_path.display());

        let res1 = handle_migrate_with_database_url(&url);
        assert!(res1.is_ok(), "first migrate failed: {res1:?}");

        let res2 = handle_migrate_with_database_url(&url);
        assert!(res2.is_ok(), "second migrate (idempotent) failed: {res2:?}");
    }

    #[test]
    fn migrate_creates_expected_tables() {
        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let dir = tempfile::tempdir().expect("tempdir");
        let db_path = dir.path().join("tables.db");
        let url = format!("sqlite:///{}", db_path.display());

        handle_migrate_with_database_url(&url).unwrap();

        let conn = sqlmodel_sqlite::SqliteConnection::open_file(db_path.display().to_string())
            .expect("reopen");
        let tables = conn
            .query_sync(
                "SELECT name FROM sqlite_master WHERE type='table' ORDER BY name",
                &[],
            )
            .expect("list tables");
        let names: Vec<String> = tables
            .iter()
            .filter_map(|r| r.get_named::<String>("name").ok())
            .collect();

        for expected in [
            "projects",
            "agents",
            "messages",
            "message_recipients",
            "file_reservations",
        ] {
            assert!(
                names.iter().any(|n| n == expected),
                "missing table {expected}; found: {names:?}"
            );
        }
    }

    #[test]
    fn migrate_invalid_path_returns_error() {
        let url = "sqlite:////nonexistent/deeply/nested/dir/db.sqlite3";
        let res = handle_migrate_with_database_url(url);
        assert!(res.is_err(), "should fail for non-existent path");
    }

    #[test]
    fn migrate_bad_url_scheme_returns_error() {
        let res = handle_migrate_with_database_url("postgres://localhost/db");
        assert!(res.is_err(), "non-sqlite URL should fail");
    }

    #[test]
    fn migrate_creates_fts_table() {
        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let dir = tempfile::tempdir().expect("tempdir");
        let db_path = dir.path().join("fts.db");
        let url = format!("sqlite:///{}", db_path.display());

        handle_migrate_with_database_url(&url).unwrap();

        let conn = sqlmodel_sqlite::SqliteConnection::open_file(db_path.display().to_string())
            .expect("reopen");
        let tables = conn
            .query_sync(
                "SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'fts_%' ORDER BY name",
                &[],
            )
            .expect("list fts tables");
        let names: Vec<String> = tables
            .iter()
            .filter_map(|r| r.get_named::<String>("name").ok())
            .collect();
        assert!(
            names.iter().any(|n| n.contains("fts")),
            "FTS table should exist after migrate; found: {names:?}"
        );
    }

    #[cfg(unix)]
    #[test]
    fn migrate_readonly_dir_returns_error() {
        use std::os::unix::fs::PermissionsExt;

        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let dir = tempfile::tempdir().expect("tempdir");
        let readonly = dir.path().join("readonly");
        std::fs::create_dir(&readonly).expect("mkdir");
        std::fs::set_permissions(&readonly, std::fs::Permissions::from_mode(0o444))
            .expect("set readonly");

        let db_path = readonly.join("db.sqlite3");
        let url = format!("sqlite:///{}", db_path.display());
        let res = handle_migrate_with_database_url(&url);

        // Restore permissions for cleanup
        std::fs::set_permissions(&readonly, std::fs::Permissions::from_mode(0o755))
            .expect("restore permissions");

        assert!(res.is_err(), "should fail on read-only directory");
    }

    #[test]
    fn migrate_creates_db_file() {
        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let dir = tempfile::tempdir().expect("tempdir");
        let db_path = dir.path().join("new.db");
        assert!(!db_path.exists(), "precondition: DB should not exist yet");

        let url = format!("sqlite:///{}", db_path.display());
        handle_migrate_with_database_url(&url).unwrap();

        assert!(db_path.exists(), "migrate should create the DB file");
        assert!(
            std::fs::metadata(&db_path).unwrap().len() > 0,
            "DB file should not be empty"
        );
    }

    #[test]
    fn migrate_output_matches_legacy_lines_exactly() {
        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());
        use ftui_runtime::stdio_capture::StdioCapture;
        let _capture_lock = stdio_capture_lock()
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let dir = tempfile::tempdir().expect("tempdir");
        let db_path = dir.path().join("legacy_lines.db");
        let url = format!("sqlite:///{}", db_path.display());

        let capture = StdioCapture::install().unwrap();
        handle_migrate_with_database_url(&url).unwrap();
        let mut sink = Vec::new();
        capture.drain(&mut sink).unwrap();
        drop(capture);

        let out = String::from_utf8_lossy(&sink);
        let lines: Vec<&str> = out.lines().collect();
        assert_eq!(
            lines.len(),
            2,
            "expected exactly 2 output lines, got {}: {lines:?}",
            lines.len()
        );
        assert!(
            lines[0].contains("Database schema created from model definitions"),
            "line 0: {:?}",
            lines[0]
        );
        assert!(
            lines[1].contains("delete storage.sqlite3"),
            "line 1: {:?}",
            lines[1]
        );
    }

    struct CwdGuard {
        original: PathBuf,
    }

    impl CwdGuard {
        fn chdir(path: &Path) -> Self {
            let original = std::env::current_dir().expect("get cwd");
            std::env::set_current_dir(path).expect("set cwd");
            Self { original }
        }
    }

    impl Drop for CwdGuard {
        fn drop(&mut self) {
            let _ = std::env::set_current_dir(&self.original);
        }
    }

    fn seed_mailbox_db(db_path: &Path) {
        let conn = sqlmodel_sqlite::SqliteConnection::open_file(db_path.display().to_string())
            .expect("open test sqlite db");
        conn.execute_raw(
            "CREATE TABLE projects (\
                id INTEGER PRIMARY KEY AUTOINCREMENT, \
                slug TEXT NOT NULL, \
                human_key TEXT NOT NULL, \
                created_at INTEGER NOT NULL DEFAULT 0\
            )",
        )
        .unwrap();
        conn.execute_raw(
            "CREATE TABLE agents (\
                id INTEGER PRIMARY KEY AUTOINCREMENT, \
                project_id INTEGER NOT NULL, \
                name TEXT NOT NULL, \
                program TEXT NOT NULL DEFAULT '', \
                model TEXT NOT NULL DEFAULT '', \
                task_description TEXT NOT NULL DEFAULT '', \
                inception_ts INTEGER NOT NULL DEFAULT 0, \
                last_active_ts INTEGER NOT NULL DEFAULT 0, \
                attachments_policy TEXT NOT NULL DEFAULT 'auto', \
                contact_policy TEXT NOT NULL DEFAULT 'auto'\
            )",
        )
        .unwrap();
        conn.execute_raw(
            "CREATE TABLE messages (\
                id INTEGER PRIMARY KEY AUTOINCREMENT, \
                project_id INTEGER NOT NULL, \
                sender_id INTEGER NOT NULL, \
                thread_id TEXT, \
                subject TEXT NOT NULL DEFAULT '', \
                body_md TEXT NOT NULL DEFAULT '', \
                importance TEXT NOT NULL DEFAULT 'normal', \
                ack_required INTEGER NOT NULL DEFAULT 0, \
                created_ts INTEGER NOT NULL DEFAULT 0, \
                attachments TEXT NOT NULL DEFAULT '[]'\
            )",
        )
        .unwrap();
        conn.execute_raw(
            "CREATE TABLE message_recipients (\
                message_id INTEGER NOT NULL, \
                agent_id INTEGER NOT NULL, \
                kind TEXT NOT NULL DEFAULT 'to', \
                read_ts INTEGER, \
                ack_ts INTEGER, \
                PRIMARY KEY (message_id, agent_id)\
            )",
        )
        .unwrap();
        conn.execute_raw(
            "CREATE TABLE file_reservations (\
                id INTEGER PRIMARY KEY AUTOINCREMENT, \
                project_id INTEGER NOT NULL, \
                agent_id INTEGER NOT NULL, \
                path_pattern TEXT NOT NULL, \
                exclusive INTEGER NOT NULL DEFAULT 1, \
                reason TEXT NOT NULL DEFAULT '', \
                created_ts INTEGER NOT NULL DEFAULT 0, \
                expires_ts INTEGER NOT NULL DEFAULT 0, \
                released_ts INTEGER\
            )",
        )
        .unwrap();

        // Two projects so we can scope down to one.
        let created_at_us = 1_704_067_200_000_000i64; // 2024-01-01T00:00:00Z
        conn.execute_raw(&format!(
            "INSERT INTO projects (slug, human_key, created_at) VALUES \
             ('proj-alpha', '/data/projects/alpha', {created_at_us}), \
             ('proj-beta',  '/data/projects/beta',  {created_at_us})"
        ))
        .unwrap();
        conn.execute_raw("INSERT INTO agents (project_id, name) VALUES (1, 'GreenCastle')")
            .unwrap();
        conn.execute_raw("INSERT INTO agents (project_id, name) VALUES (2, 'PurpleBear')")
            .unwrap();
        conn.execute_raw(
            "INSERT INTO messages (project_id, sender_id, subject, body_md) VALUES \
             (1, 1, 'Msg A', 'hello'), \
             (1, 1, 'Msg B', 'world'), \
             (2, 2, 'Msg C', 'bye')",
        )
        .unwrap();
        conn.execute_raw("INSERT INTO message_recipients (message_id, agent_id) VALUES (1, 1)")
            .unwrap();
        conn.execute_raw("INSERT INTO message_recipients (message_id, agent_id) VALUES (2, 1)")
            .unwrap();
        conn.execute_raw("INSERT INTO message_recipients (message_id, agent_id) VALUES (3, 2)")
            .unwrap();
        conn.execute_raw(
            "INSERT INTO file_reservations (project_id, agent_id, path_pattern) VALUES (1, 1, 'src/*.rs')",
        )
        .unwrap();
    }

    fn seed_storage_root(storage_root: &Path) {
        std::fs::create_dir_all(storage_root.join("nested/dir")).unwrap();
        std::fs::write(storage_root.join("nested/dir/file.txt"), b"hello\n").unwrap();

        // Minimal git marker so `detect_git_head()` has stable output.
        std::fs::create_dir_all(storage_root.join(".git")).unwrap();
        std::fs::write(storage_root.join(".git/HEAD"), b"0123456789abcdef\n").unwrap();
    }

    fn find_backup_entry(dir: &Path, prefix: &str) -> Option<PathBuf> {
        let entries = std::fs::read_dir(dir).ok()?;
        for entry in entries.flatten() {
            let path = entry.path();
            let Some(name) = path.file_name().map(|n| n.to_string_lossy().to_string()) else {
                continue;
            };
            if name.starts_with(prefix) {
                return Some(path);
            }
        }
        None
    }

    #[test]
    fn archive_save_list_restore_roundtrip_smoke() {
        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());
        use std::io::Read;

        let root = tempfile::tempdir().unwrap();
        std::fs::write(root.path().join("Cargo.toml"), b"[workspace]\n").unwrap();
        let _cwd = CwdGuard::chdir(root.path());

        let storage_root = root.path().join("storage_repo");
        seed_storage_root(&storage_root);

        let source_db = root.path().join("mailbox.sqlite3");
        seed_mailbox_db(&source_db);

        // Save archive for a single project to exercise scoping.
        let archive_path = archive_save_state(
            &source_db,
            &storage_root,
            vec!["proj-alpha".to_string()],
            "archive".to_string(),
            Some("nightly".to_string()),
        )
        .expect("archive save");
        assert!(archive_path.exists());

        // Validate zip layout + metadata content.
        let file = std::fs::File::open(&archive_path).unwrap();
        let mut zip = zip::ZipArchive::new(file).unwrap();
        assert!(zip.by_name(ARCHIVE_METADATA_FILENAME).is_ok());
        assert!(zip.by_name(ARCHIVE_SNAPSHOT_RELATIVE).is_ok());
        assert!(zip.by_name("storage_repo/nested/dir/file.txt").is_ok());
        assert!(zip.by_name("storage_repo/.git/HEAD").is_ok());

        let mut meta_contents = String::new();
        zip.by_name(ARCHIVE_METADATA_FILENAME)
            .unwrap()
            .read_to_string(&mut meta_contents)
            .unwrap();
        let meta: serde_json::Value = serde_json::from_str(&meta_contents).unwrap();
        assert_eq!(meta["scrub_preset"].as_str(), Some("archive"));
        assert_eq!(meta["label"].as_str(), Some("nightly"));
        assert_eq!(
            meta["projects_requested"].as_array().unwrap().len(),
            1,
            "save should record requested project filters"
        );
        let included = meta["projects_included"].as_array().unwrap();
        assert_eq!(included.len(), 1, "scope should keep only 1 project");
        assert_eq!(included[0]["slug"].as_str(), Some("proj-alpha"));
        assert_eq!(
            included[0]["created_at"].as_str(),
            Some("2024-01-01T00:00:00+00:00")
        );

        // `archive list --json` output should include the new archive.
        {
            use ftui_runtime::stdio_capture::StdioCapture;

            let _capture_lock = stdio_capture_lock()
                .lock()
                .unwrap_or_else(|err| err.into_inner());
            let capture = StdioCapture::install().unwrap();
            handle_archive(ArchiveCommand::List {
                limit: 0,
                json: true,
            })
            .unwrap();
            let mut sink = Vec::new();
            capture.drain(&mut sink).unwrap();
            drop(capture);

            let output = String::from_utf8_lossy(&sink).trim().to_string();
            let list_json: serde_json::Value = serde_json::from_str(&output).unwrap();
            let arr = list_json.as_array().unwrap();
            assert_eq!(arr.len(), 1);
            assert_eq!(
                arr[0]["file"].as_str(),
                archive_path.file_name().and_then(|s| s.to_str())
            );
            assert_eq!(arr[0]["scrub_preset"].as_str(), Some("archive"));
            assert_eq!(
                arr[0]["projects"].as_array().unwrap()[0].as_str(),
                Some("proj-alpha")
            );
        }

        // Restore safety: without --force on non-tty stdin, should refuse to prompt.
        let archive_arg = PathBuf::from(archive_path.file_name().unwrap());
        let restore_dir = root.path().join("restore");
        let restore_db = restore_dir.join("mailbox.sqlite3");
        let restore_storage = restore_dir.join("storage_repo");
        std::fs::create_dir_all(&restore_dir).unwrap();
        std::fs::write(&restore_db, b"old-db").unwrap();
        std::fs::create_dir_all(&restore_storage).unwrap();
        std::fs::write(restore_storage.join("old.txt"), b"old-storage").unwrap();

        let err = archive_restore_state(
            archive_arg.clone(),
            &restore_db,
            &restore_storage,
            false,
            false,
        )
        .unwrap_err();
        let msg = match err {
            CliError::Other(m) => m,
            other => format!("{other}"),
        };
        assert!(
            msg.contains("refusing to prompt on non-interactive stdin"),
            "unexpected error: {msg}"
        );

        // Dry-run should print plan and make no changes.
        {
            use ftui_runtime::stdio_capture::StdioCapture;

            let _capture_lock = stdio_capture_lock()
                .lock()
                .unwrap_or_else(|err| err.into_inner());
            let capture = StdioCapture::install().unwrap();
            archive_restore_state(
                archive_arg.clone(),
                &restore_db,
                &restore_storage,
                false,
                true,
            )
            .unwrap();
            let mut sink = Vec::new();
            capture.drain(&mut sink).unwrap();
            drop(capture);

            let output = String::from_utf8_lossy(&sink);
            assert!(output.contains("Dry-run plan:"));
            assert!(output.contains("restore snapshot ->"));
            assert!(output.contains("restore storage repo ->"));
            assert_eq!(std::fs::read(&restore_db).unwrap(), b"old-db");
            assert_eq!(
                std::fs::read(restore_storage.join("old.txt")).unwrap(),
                b"old-storage"
            );
        }

        // Actual restore with --force should create backups and restore snapshot + storage.
        archive_restore_state(archive_arg, &restore_db, &restore_storage, true, false).unwrap();

        let db_backup =
            find_backup_entry(&restore_dir, "mailbox.sqlite3.backup-").expect("db backup created");
        assert_eq!(std::fs::read(&db_backup).unwrap(), b"old-db");

        let storage_backup = find_backup_entry(&restore_dir, "storage_repo.backup-")
            .expect("storage backup created");
        assert!(storage_backup.is_dir());
        assert_eq!(
            std::fs::read(storage_backup.join("old.txt")).unwrap(),
            b"old-storage"
        );

        // Restored DB should contain only the scoped project.
        let restored_conn =
            sqlmodel_sqlite::SqliteConnection::open_file(restore_db.display().to_string()).unwrap();
        let rows = restored_conn
            .query_sync("SELECT slug FROM projects ORDER BY id", &[])
            .unwrap();
        assert_eq!(rows.len(), 1);
        let slug: String = rows[0].get_named("slug").unwrap();
        assert_eq!(slug, "proj-alpha");

        // Restored storage should include the archived files.
        assert_eq!(
            std::fs::read(restore_storage.join("nested/dir/file.txt")).unwrap(),
            b"hello\n"
        );
        assert_eq!(
            std::fs::read(restore_storage.join(".git/HEAD")).unwrap(),
            b"0123456789abcdef\n"
        );
    }

    // -----------------------------------------------------------------------
    // Clear-and-reset-everything integration-ish tests
    // -----------------------------------------------------------------------

    #[test]
    fn clear_and_reset_force_archive_creates_archive_and_wipes() {
        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());
        use std::io::Read;

        let root = tempfile::tempdir().unwrap();
        std::fs::write(root.path().join("Cargo.toml"), b"[workspace]\n").unwrap();
        let _cwd = CwdGuard::chdir(root.path());

        let storage_root = root.path().join("storage_repo");
        seed_storage_root(&storage_root);

        let db_path = root.path().join("mailbox.sqlite3");
        seed_mailbox_db(&db_path);
        let wal_path = PathBuf::from(format!("{}-wal", db_path.display()));
        let shm_path = PathBuf::from(format!("{}-shm", db_path.display()));
        std::fs::write(&wal_path, b"wal").unwrap();
        std::fs::write(&shm_path, b"shm").unwrap();
        let database_files = vec![db_path.clone(), wal_path.clone(), shm_path.clone()];

        let outcome = clear_and_reset_everything(
            true,
            Some(true),
            Some(&db_path),
            &database_files,
            &storage_root,
        )
        .expect("clear-and-reset");
        assert!(outcome.archive_path.is_some());

        let archive_dir = archive_states_dir(false).unwrap();
        let mut archives: Vec<PathBuf> = std::fs::read_dir(&archive_dir)
            .unwrap()
            .flatten()
            .map(|e| e.path())
            .collect();
        archives.sort();
        assert_eq!(archives.len(), 1, "expected 1 archive zip");
        let archive_path = &archives[0];
        assert_eq!(
            archive_path.extension().and_then(|s| s.to_str()),
            Some("zip")
        );

        // Validate label + scrub preset in metadata.
        let file = std::fs::File::open(archive_path).unwrap();
        let mut zip = zip::ZipArchive::new(file).unwrap();
        let mut meta_contents = String::new();
        zip.by_name(ARCHIVE_METADATA_FILENAME)
            .unwrap()
            .read_to_string(&mut meta_contents)
            .unwrap();
        let meta: serde_json::Value = serde_json::from_str(&meta_contents).unwrap();
        assert_eq!(meta["label"].as_str(), Some("pre-reset"));
        assert_eq!(meta["scrub_preset"].as_str(), Some("archive"));

        // DB + WAL/SHM should be removed.
        assert!(!db_path.exists());
        assert!(!wal_path.exists());
        assert!(!shm_path.exists());

        // Storage root should be emptied (directory stays).
        assert!(storage_root.exists());
        assert_eq!(std::fs::read_dir(&storage_root).unwrap().count(), 0);
    }

    #[test]
    fn clear_and_reset_force_no_archive_wipes_without_archive() {
        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let root = tempfile::tempdir().unwrap();
        std::fs::write(root.path().join("Cargo.toml"), b"[workspace]\n").unwrap();
        let _cwd = CwdGuard::chdir(root.path());

        let storage_root = root.path().join("storage_repo");
        seed_storage_root(&storage_root);

        let db_path = root.path().join("mailbox.sqlite3");
        seed_mailbox_db(&db_path);
        let wal_path = PathBuf::from(format!("{}-wal", db_path.display()));
        let shm_path = PathBuf::from(format!("{}-shm", db_path.display()));
        std::fs::write(&wal_path, b"wal").unwrap();
        std::fs::write(&shm_path, b"shm").unwrap();
        let database_files = vec![db_path.clone(), wal_path.clone(), shm_path.clone()];

        clear_and_reset_everything(
            true,
            Some(false),
            Some(&db_path),
            &database_files,
            &storage_root,
        )
        .expect("clear-and-reset");

        let archive_dir = archive_states_dir(false).unwrap();
        assert!(
            !archive_dir.exists(),
            "archive dir should not be created when --no-archive"
        );
        assert!(!db_path.exists());
        assert!(!wal_path.exists());
        assert!(!shm_path.exists());
        assert!(storage_root.exists());
        assert_eq!(std::fs::read_dir(&storage_root).unwrap().count(), 0);
    }

    #[test]
    fn clear_and_reset_refuses_without_force_on_non_interactive_stdin() {
        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());

        let root = tempfile::tempdir().unwrap();
        std::fs::write(root.path().join("Cargo.toml"), b"[workspace]\n").unwrap();
        let _cwd = CwdGuard::chdir(root.path());

        let storage_root = root.path().join("storage_repo");
        seed_storage_root(&storage_root);

        let db_path = root.path().join("mailbox.sqlite3");
        seed_mailbox_db(&db_path);
        let wal_path = PathBuf::from(format!("{}-wal", db_path.display()));
        let shm_path = PathBuf::from(format!("{}-shm", db_path.display()));
        std::fs::write(&wal_path, b"wal").unwrap();
        std::fs::write(&shm_path, b"shm").unwrap();
        let database_files = vec![db_path.clone(), wal_path.clone(), shm_path.clone()];

        let err =
            clear_and_reset_everything(false, None, Some(&db_path), &database_files, &storage_root)
                .unwrap_err();
        let msg = match err {
            CliError::Other(m) => m,
            other => format!("{other}"),
        };
        assert!(
            msg.contains("refusing to prompt on non-interactive stdin"),
            "unexpected error: {msg}"
        );

        // Ensure no changes occurred.
        assert!(db_path.exists());
        assert!(wal_path.exists());
        assert!(shm_path.exists());
        assert!(storage_root.join("nested/dir/file.txt").exists());
        assert!(storage_root.join(".git/HEAD").exists());
    }

    // -----------------------------------------------------------------------
    // Products commands integration-ish tests (local DB, no env mutation)
    // -----------------------------------------------------------------------

    fn seed_products_cli_db(root: &tempfile::TempDir) -> (PathBuf, String, String, i64) {
        use mcp_agent_mail_db::sqlmodel::Value;

        let created_at_us = 1_704_067_200_000_000i64; // 2024-01-01T00:00:00Z

        // Use real directories so get_project_record() canonicalization is stable.
        let proj_alpha_dir = root.path().join("proj_alpha");
        std::fs::create_dir_all(&proj_alpha_dir).unwrap();
        let proj_beta_dir = root.path().join("proj_beta");
        std::fs::create_dir_all(&proj_beta_dir).unwrap();

        let proj_alpha_key = proj_alpha_dir.canonicalize().unwrap().display().to_string();
        let proj_beta_key = proj_beta_dir.canonicalize().unwrap().display().to_string();

        let db_path = root.path().join("mailbox.sqlite3");
        let conn = sqlmodel_sqlite::SqliteConnection::open_file(db_path.display().to_string())
            .expect("open products test sqlite db");
        conn.execute_raw(&mcp_agent_mail_db::schema::init_schema_sql())
            .expect("init schema");

        // Projects
        conn.execute_sync(
            "INSERT INTO projects (id, slug, human_key, created_at) VALUES (?, ?, ?, ?)",
            &[
                Value::BigInt(1),
                Value::Text("proj-alpha".to_string()),
                Value::Text(proj_alpha_key.clone()),
                Value::BigInt(created_at_us),
            ],
        )
        .unwrap();
        conn.execute_sync(
            "INSERT INTO projects (id, slug, human_key, created_at) VALUES (?, ?, ?, ?)",
            &[
                Value::BigInt(2),
                Value::Text("proj-beta".to_string()),
                Value::Text(proj_beta_key.clone()),
                Value::BigInt(created_at_us),
            ],
        )
        .unwrap();

        // Agents: same recipient name across both projects (legacy semantics).
        let agent_insert = "INSERT INTO agents (\
                id, project_id, name, program, model, task_description, \
                inception_ts, last_active_ts, attachments_policy, contact_policy\
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";

        conn.execute_sync(
            agent_insert,
            &[
                Value::BigInt(1),
                Value::BigInt(1),
                Value::Text("GreenCastle".to_string()),
                Value::Text("test".to_string()),
                Value::Text("test".to_string()),
                Value::Text(String::new()),
                Value::BigInt(0),
                Value::BigInt(0),
                Value::Text("auto".to_string()),
                Value::Text("auto".to_string()),
            ],
        )
        .unwrap();
        conn.execute_sync(
            agent_insert,
            &[
                Value::BigInt(2),
                Value::BigInt(2),
                Value::Text("GreenCastle".to_string()),
                Value::Text("test".to_string()),
                Value::Text("test".to_string()),
                Value::Text(String::new()),
                Value::BigInt(0),
                Value::BigInt(0),
                Value::Text("auto".to_string()),
                Value::Text("auto".to_string()),
            ],
        )
        .unwrap();
        // Senders
        conn.execute_sync(
            agent_insert,
            &[
                Value::BigInt(3),
                Value::BigInt(1),
                Value::Text("PurpleBear".to_string()),
                Value::Text("test".to_string()),
                Value::Text("test".to_string()),
                Value::Text(String::new()),
                Value::BigInt(0),
                Value::BigInt(0),
                Value::Text("auto".to_string()),
                Value::Text("auto".to_string()),
            ],
        )
        .unwrap();
        conn.execute_sync(
            agent_insert,
            &[
                Value::BigInt(4),
                Value::BigInt(2),
                Value::Text("OrangeFish".to_string()),
                Value::Text("test".to_string()),
                Value::Text("test".to_string()),
                Value::Text(String::new()),
                Value::BigInt(0),
                Value::BigInt(0),
                Value::Text("auto".to_string()),
                Value::Text("auto".to_string()),
            ],
        )
        .unwrap();

        // Messages (FTS triggers will populate fts_messages)
        let msg_insert = "INSERT INTO messages (\
                id, project_id, sender_id, thread_id, subject, body_md, importance, \
                ack_required, created_ts, attachments\
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
        conn.execute_sync(
            msg_insert,
            &[
                Value::BigInt(10),
                Value::BigInt(1),
                Value::BigInt(3),
                Value::Null,
                Value::Text("Unicorn alpha".to_string()),
                Value::Text("body alpha".to_string()),
                Value::Text("high".to_string()),
                Value::BigInt(0),
                Value::BigInt(created_at_us + 10),
                Value::Text("[]".to_string()),
            ],
        )
        .unwrap();
        conn.execute_sync(
            msg_insert,
            &[
                Value::BigInt(11),
                Value::BigInt(1),
                Value::BigInt(3),
                Value::Null,
                Value::Text("Other alpha".to_string()),
                Value::Text("misc".to_string()),
                Value::Text("normal".to_string()),
                Value::BigInt(1),
                Value::BigInt(created_at_us + 5),
                Value::Text("[]".to_string()),
            ],
        )
        .unwrap();
        conn.execute_sync(
            msg_insert,
            &[
                Value::BigInt(20),
                Value::BigInt(2),
                Value::BigInt(4),
                Value::Null,
                Value::Text("Beta ping".to_string()),
                Value::Text("body beta".to_string()),
                Value::Text("normal".to_string()),
                Value::BigInt(0),
                Value::BigInt(created_at_us + 20),
                Value::Text("[]".to_string()),
            ],
        )
        .unwrap();

        // Recipients
        let recip_insert =
            "INSERT INTO message_recipients (message_id, agent_id, kind) VALUES (?, ?, ?)";
        conn.execute_sync(
            recip_insert,
            &[
                Value::BigInt(10),
                Value::BigInt(1),
                Value::Text("to".to_string()),
            ],
        )
        .unwrap();
        conn.execute_sync(
            recip_insert,
            &[
                Value::BigInt(11),
                Value::BigInt(1),
                Value::Text("to".to_string()),
            ],
        )
        .unwrap();
        conn.execute_sync(
            recip_insert,
            &[
                Value::BigInt(20),
                Value::BigInt(2),
                Value::Text("to".to_string()),
            ],
        )
        .unwrap();

        (db_path, proj_alpha_key, proj_beta_key, created_at_us)
    }

    fn run_products_cmd_capture(
        runtime: &asupersync::runtime::Runtime,
        cx: &asupersync::Cx,
        pool: &mcp_agent_mail_db::DbPool,
        action: ProductsCommand,
    ) -> (CliResult<()>, String) {
        use ftui_runtime::stdio_capture::StdioCapture;

        let _capture_lock = stdio_capture_lock()
            .lock()
            .unwrap_or_else(|err| err.into_inner());
        let capture = StdioCapture::install().unwrap();
        let res =
            runtime.block_on(async { handle_products_with(cx, pool, None, None, action).await });
        let mut sink = Vec::new();
        capture.drain(&mut sink).unwrap();
        drop(capture);

        (res, String::from_utf8_lossy(&sink).trim().to_string())
    }

    #[test]
    fn products_local_parity_smoke_json() {
        let _lock = ARCHIVE_TEST_LOCK
            .lock()
            .unwrap_or_else(|err| err.into_inner());
        use asupersync::runtime::RuntimeBuilder;
        use mcp_agent_mail_db::sqlmodel::Value;

        let root = tempfile::tempdir().unwrap();
        let (db_path, proj_alpha_key, proj_beta_key, created_at_us) = seed_products_cli_db(&root);

        let pool_cfg = mcp_agent_mail_db::DbPoolConfig {
            database_url: format!("sqlite:///{}", db_path.display()),
            min_connections: 1,
            max_connections: 1,
            acquire_timeout_ms: 5_000,
            max_lifetime_ms: 60_000,
            run_migrations: true,
        };
        let pool = mcp_agent_mail_db::DbPool::new(&pool_cfg).unwrap();
        let cx = asupersync::Cx::for_request();
        let runtime = RuntimeBuilder::current_thread().build().unwrap();

        // Ensure (create)
        let (res, out) = run_products_cmd_capture(
            &runtime,
            &cx,
            &pool,
            ProductsCommand::Ensure {
                product_key: Some("abcdef1234".to_string()),
                name: Some("My   Product".to_string()),
                json: true,
            },
        );
        res.unwrap();
        let ensure_json: serde_json::Value = serde_json::from_str(&out).unwrap();
        assert_eq!(ensure_json["product_uid"].as_str(), Some("abcdef1234"));
        assert_eq!(ensure_json["name"].as_str(), Some("My Product"));

        // Normalize created_at for stable snapshots.
        let conn =
            sqlmodel_sqlite::SqliteConnection::open_file(db_path.display().to_string()).unwrap();
        conn.execute_sync(
            "UPDATE products SET created_at = ? WHERE product_uid = ?",
            &[
                Value::BigInt(created_at_us),
                Value::Text("abcdef1234".to_string()),
            ],
        )
        .unwrap();

        // Ensure (existing) should now have deterministic created_at
        let (res, out) = run_products_cmd_capture(
            &runtime,
            &cx,
            &pool,
            ProductsCommand::Ensure {
                product_key: Some("abcdef1234".to_string()),
                name: None,
                json: true,
            },
        );
        res.unwrap();
        let ensure_json: serde_json::Value = serde_json::from_str(&out).unwrap();
        let expected_created_at = mcp_agent_mail_db::micros_to_iso(created_at_us);
        assert_eq!(
            ensure_json["created_at"].as_str(),
            Some(expected_created_at.as_str())
        );

        // Link into both projects
        run_products_cmd_capture(
            &runtime,
            &cx,
            &pool,
            ProductsCommand::Link {
                product_key: "abcdef1234".to_string(),
                project: proj_alpha_key.clone(),
                json: false,
            },
        )
        .0
        .unwrap();
        run_products_cmd_capture(
            &runtime,
            &cx,
            &pool,
            ProductsCommand::Link {
                product_key: "abcdef1234".to_string(),
                project: proj_beta_key.clone(),
                json: false,
            },
        )
        .0
        .unwrap();

        // Status JSON should include both projects
        let (res, out) = run_products_cmd_capture(
            &runtime,
            &cx,
            &pool,
            ProductsCommand::Status {
                product_key: "abcdef1234".to_string(),
                json: true,
            },
        );
        res.unwrap();
        let mut status_json: serde_json::Value = serde_json::from_str(&out).unwrap();
        assert_eq!(
            status_json["product"]["product_uid"].as_str(),
            Some("abcdef1234")
        );
        let projects = status_json["projects"].as_array_mut().unwrap();
        projects.sort_by_key(|p| p["id"].as_i64().unwrap_or_default());
        assert_eq!(projects.len(), 2);
        assert_eq!(projects[0]["slug"].as_str(), Some("proj-alpha"));
        assert_eq!(projects[1]["slug"].as_str(), Some("proj-beta"));

        // Search JSON should find only the unicorn message.
        let (res, out) = run_products_cmd_capture(
            &runtime,
            &cx,
            &pool,
            ProductsCommand::Search {
                product_key: "abcdef1234".to_string(),
                query: "unicorn".to_string(),
                limit: 20,
                json: true,
            },
        );
        res.unwrap();
        let search_json: serde_json::Value = serde_json::from_str(&out).unwrap();
        let arr = search_json["result"].as_array().unwrap();
        assert_eq!(arr.len(), 1);
        assert_eq!(arr[0]["id"].as_i64(), Some(10));
        assert_eq!(arr[0]["project_id"].as_i64(), Some(1));

        // Inbox JSON (all)
        let (res, out) = run_products_cmd_capture(
            &runtime,
            &cx,
            &pool,
            ProductsCommand::Inbox {
                product_key: "abcdef1234".to_string(),
                agent: "GreenCastle".to_string(),
                limit: 20,
                urgent_only: false,
                all: false,
                include_bodies: false,
                no_bodies: false,
                since_ts: None,
                json: true,
            },
        );
        res.unwrap();
        let inbox_json: serde_json::Value = serde_json::from_str(&out).unwrap();
        let arr = inbox_json.as_array().unwrap();
        assert_eq!(arr.len(), 3);
        assert_eq!(arr[0]["id"].as_i64(), Some(20));
        assert_eq!(arr[1]["id"].as_i64(), Some(10));
        assert_eq!(arr[2]["id"].as_i64(), Some(11));
        assert!(arr[0].get("body_md").is_none(), "bodies default off");

        // Inbox urgent-only should include only the high message.
        let (res, out) = run_products_cmd_capture(
            &runtime,
            &cx,
            &pool,
            ProductsCommand::Inbox {
                product_key: "abcdef1234".to_string(),
                agent: "GreenCastle".to_string(),
                limit: 20,
                urgent_only: true,
                all: false,
                include_bodies: false,
                no_bodies: false,
                since_ts: None,
                json: true,
            },
        );
        res.unwrap();
        let inbox_json: serde_json::Value = serde_json::from_str(&out).unwrap();
        let arr = inbox_json.as_array().unwrap();
        assert_eq!(arr.len(), 1);
        assert_eq!(arr[0]["id"].as_i64(), Some(10));

        // Summarize-thread requires server tool; with server disabled, should return exit code 2.
        let (res, out) = run_products_cmd_capture(
            &runtime,
            &cx,
            &pool,
            ProductsCommand::SummarizeThread {
                product_key: "abcdef1234".to_string(),
                thread_id: "thread-1".to_string(),
                per_thread_limit: 50,
                no_llm: true,
                json: false,
            },
        );
        let err = res.unwrap_err();
        assert!(matches!(err, CliError::ExitCode(2)));
        assert!(out.contains("Server unavailable; summarization requires server tool."));
    }

    // -----------------------------------------------------------------------
    // Error path tests (validation logic, not full execution)
    // -----------------------------------------------------------------------

    #[test]
    fn resolve_bool_defaults() {
        assert!(!resolve_bool(false, false, false));
        assert!(resolve_bool(false, false, true));
        assert!(resolve_bool(true, false, false));
        assert!(!resolve_bool(false, true, true)); // negated wins
        assert!(!resolve_bool(true, true, true)); // negated wins
    }

    #[test]
    fn invalid_scrub_preset_is_rejected() {
        let result = share::normalize_scrub_preset("bogus");
        assert!(result.is_err());
    }

    #[test]
    fn valid_scrub_presets_accepted() {
        assert!(share::normalize_scrub_preset("standard").is_ok());
        assert!(share::normalize_scrub_preset("strict").is_ok());
        assert!(share::normalize_scrub_preset("archive").is_ok());
        assert!(share::normalize_scrub_preset("Standard").is_ok()); // case-insensitive
    }

    #[test]
    fn threshold_validation_rejects_negative() {
        let result = share::validate_thresholds(-1, 0, 0, 1024);
        assert!(result.is_err());
        let result = share::validate_thresholds(0, -1, 0, 1024);
        assert!(result.is_err());
        let result = share::validate_thresholds(0, 0, -1, 1024);
        assert!(result.is_err());
    }

    #[test]
    fn threshold_validation_rejects_small_chunk_size() {
        let result = share::validate_thresholds(0, 0, 0, 512);
        assert!(result.is_err());
    }

    #[test]
    fn threshold_validation_accepts_valid() {
        let result = share::validate_thresholds(
            share::INLINE_ATTACHMENT_THRESHOLD as i64,
            share::DETACH_ATTACHMENT_THRESHOLD as i64,
            share::DEFAULT_CHUNK_THRESHOLD as i64,
            share::DEFAULT_CHUNK_SIZE as i64,
        );
        assert!(result.is_ok());
    }

    #[test]
    fn detach_threshold_adjusted_when_below_inline() {
        // When detach <= inline, it should be bumped
        let adjusted = share::adjust_detach_threshold(1000, 500);
        assert!(adjusted > 1000);
    }

    #[test]
    fn detach_threshold_unchanged_when_above_inline() {
        let adjusted = share::adjust_detach_threshold(1000, 2000);
        assert_eq!(adjusted, 2000);
    }

    #[test]
    fn ensure_dir_missing_path_errors() {
        let result = ensure_dir(Path::new("/nonexistent/path"));
        assert!(result.is_err());
    }

    #[test]
    fn ensure_dir_file_not_directory_errors() {
        // /proc/self/exe is a file, not a directory
        let result = ensure_dir(Path::new("/proc/self/exe"));
        assert!(result.is_err());
    }

    #[test]
    fn default_decrypt_output_strips_age_extension() {
        let out = share::default_decrypt_output(Path::new("/tmp/bundle.zip.age"));
        assert_eq!(out, PathBuf::from("/tmp/bundle.zip"));
    }

    #[test]
    fn default_decrypt_output_non_age_adds_suffix() {
        let out = share::default_decrypt_output(Path::new("/tmp/bundle.zip"));
        assert_eq!(out, PathBuf::from("/tmp/bundle_decrypted.zip"));
    }

    #[test]
    fn safe_component_sanitizes_special_chars() {
        assert_eq!(safe_component("foo/bar:baz"), "foo_bar_baz");
        assert_eq!(safe_component(""), "unknown");
        assert_eq!(safe_component("  "), "unknown");
    }

    //  docs insert-blurbs tests (br-2ei.5.10) 

    #[test]
    fn clap_parses_docs_insert_blurbs_defaults() {
        let cli = Cli::try_parse_from(["am", "docs", "insert-blurbs"])
            .expect("failed to parse docs insert-blurbs");
        match cli.command {
            Commands::Docs { action } => match action {
                DocsCommand::InsertBlurbs {
                    scan_dir,
                    yes,
                    dry_run,
                    max_depth,
                } => {
                    assert!(scan_dir.is_empty(), "default scan_dir should be empty");
                    assert!(!yes, "default yes should be false");
                    assert!(!dry_run, "default dry_run should be false");
                    assert!(max_depth.is_none(), "default max_depth should be None");
                }
            },
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn clap_parses_docs_insert_blurbs_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "docs",
            "insert-blurbs",
            "-d",
            "/tmp/a",
            "-d",
            "/tmp/b",
            "--yes",
            "--dry-run",
            "--max-depth",
            "5",
        ])
        .expect("failed to parse docs insert-blurbs flags");
        match cli.command {
            Commands::Docs { action } => match action {
                DocsCommand::InsertBlurbs {
                    scan_dir,
                    yes,
                    dry_run,
                    max_depth,
                } => {
                    assert_eq!(scan_dir.len(), 2);
                    assert_eq!(scan_dir[0].to_str(), Some("/tmp/a"));
                    assert_eq!(scan_dir[1].to_str(), Some("/tmp/b"));
                    assert!(yes);
                    assert!(dry_run);
                    assert_eq!(max_depth, Some(5));
                }
            },
            other => panic!("unexpected command: {other:?}"),
        }
    }

    #[test]
    fn scan_markdown_for_blurbs_empty_dir() {
        let tmp = tempfile::tempdir().unwrap();
        let mut files = 0u64;
        let mut insertions = 0u64;
        scan_markdown_for_blurbs(tmp.path(), 0, 3, true, &mut files, &mut insertions).unwrap();
        assert_eq!(files, 0);
        assert_eq!(insertions, 0);
    }

    #[test]
    fn scan_markdown_for_blurbs_no_marker() {
        let tmp = tempfile::tempdir().unwrap();
        std::fs::write(tmp.path().join("README.md"), "# Hello\nNo markers here.").unwrap();
        let mut files = 0u64;
        let mut insertions = 0u64;
        scan_markdown_for_blurbs(tmp.path(), 0, 3, false, &mut files, &mut insertions).unwrap();
        assert_eq!(files, 1);
        assert_eq!(insertions, 0);
    }

    #[test]
    fn scan_markdown_for_blurbs_marker_triggers_insertion() {
        let tmp = tempfile::tempdir().unwrap();
        let file = tmp.path().join("AGENTS.md");
        std::fs::write(&file, "# Agents\n<!-- am:blurb -->\nSome content").unwrap();
        let mut files = 0u64;
        let mut insertions = 0u64;
        scan_markdown_for_blurbs(tmp.path(), 0, 3, false, &mut files, &mut insertions).unwrap();
        assert_eq!(files, 1);
        assert_eq!(insertions, 1);
        // Verify the end marker was inserted.
        let content = std::fs::read_to_string(&file).unwrap();
        assert!(
            content.contains("<!-- am:blurb:end -->"),
            "end marker should be inserted"
        );
        assert!(
            content.contains("<!-- am:blurb -->"),
            "start marker should be preserved"
        );
    }

    #[test]
    fn scan_markdown_for_blurbs_dry_run_no_file_changes() {
        let tmp = tempfile::tempdir().unwrap();
        let file = tmp.path().join("CLAUDE.md");
        let original = "# Claude\n<!-- am:blurb -->\nContent";
        std::fs::write(&file, original).unwrap();
        let mut files = 0u64;
        let mut insertions = 0u64;
        scan_markdown_for_blurbs(tmp.path(), 0, 3, true, &mut files, &mut insertions).unwrap();
        assert_eq!(insertions, 1, "dry run should count insertions");
        // File should NOT be modified.
        let content = std::fs::read_to_string(&file).unwrap();
        assert_eq!(content, original, "dry run must not modify files");
    }

    #[test]
    fn scan_markdown_for_blurbs_idempotent() {
        let tmp = tempfile::tempdir().unwrap();
        let file = tmp.path().join("AGENTS.md");
        std::fs::write(&file, "# Agents\n<!-- am:blurb -->\nContent").unwrap();

        // First pass: insert.
        let mut files = 0u64;
        let mut insertions = 0u64;
        scan_markdown_for_blurbs(tmp.path(), 0, 3, false, &mut files, &mut insertions).unwrap();
        assert_eq!(insertions, 1);
        let after_first = std::fs::read_to_string(&file).unwrap();

        // Second pass: should be idempotent (no more insertions).
        let mut files2 = 0u64;
        let mut insertions2 = 0u64;
        scan_markdown_for_blurbs(tmp.path(), 0, 3, false, &mut files2, &mut insertions2).unwrap();
        assert_eq!(
            insertions2, 0,
            "second pass should not insert (already has end marker)"
        );
        let after_second = std::fs::read_to_string(&file).unwrap();
        assert_eq!(
            after_first, after_second,
            "file should not change on second pass"
        );
    }

    #[test]
    fn scan_markdown_for_blurbs_skips_already_complete() {
        let tmp = tempfile::tempdir().unwrap();
        let file = tmp.path().join("README.md");
        std::fs::write(
            &file,
            "# Hello\n<!-- am:blurb -->\nContent\n<!-- am:blurb:end -->\n",
        )
        .unwrap();
        let mut files = 0u64;
        let mut insertions = 0u64;
        scan_markdown_for_blurbs(tmp.path(), 0, 3, false, &mut files, &mut insertions).unwrap();
        assert_eq!(files, 1);
        assert_eq!(
            insertions, 0,
            "already-complete file should not trigger insertion"
        );
    }

    #[test]
    fn scan_markdown_for_blurbs_respects_max_depth() {
        let tmp = tempfile::tempdir().unwrap();
        let deep = tmp.path().join("a").join("b").join("c").join("d");
        std::fs::create_dir_all(&deep).unwrap();
        std::fs::write(deep.join("test.md"), "<!-- am:blurb -->\n").unwrap();

        // max_depth=2 should not reach depth 4.
        let mut files = 0u64;
        let mut insertions = 0u64;
        scan_markdown_for_blurbs(tmp.path(), 0, 2, true, &mut files, &mut insertions).unwrap();
        assert_eq!(files, 0, "max_depth=2 should not find file at depth 4");

        // max_depth=5 should find it.
        let mut files2 = 0u64;
        let mut insertions2 = 0u64;
        scan_markdown_for_blurbs(tmp.path(), 0, 5, true, &mut files2, &mut insertions2).unwrap();
        assert_eq!(files2, 1, "max_depth=5 should find file at depth 4");
    }

    #[test]
    fn scan_markdown_for_blurbs_ignores_non_md_files() {
        let tmp = tempfile::tempdir().unwrap();
        std::fs::write(tmp.path().join("notes.txt"), "<!-- am:blurb -->").unwrap();
        std::fs::write(tmp.path().join("data.json"), "<!-- am:blurb -->").unwrap();
        let mut files = 0u64;
        let mut insertions = 0u64;
        scan_markdown_for_blurbs(tmp.path(), 0, 3, true, &mut files, &mut insertions).unwrap();
        assert_eq!(files, 0, "non-.md files should be ignored");
    }

    #[test]
    fn scan_markdown_for_blurbs_handles_subdirectories() {
        let tmp = tempfile::tempdir().unwrap();
        let sub = tmp.path().join("subdir");
        std::fs::create_dir(&sub).unwrap();
        std::fs::write(sub.join("AGENTS.md"), "<!-- am:blurb -->\nHello").unwrap();
        std::fs::write(tmp.path().join("ROOT.md"), "No markers").unwrap();

        let mut files = 0u64;
        let mut insertions = 0u64;
        scan_markdown_for_blurbs(tmp.path(), 0, 3, true, &mut files, &mut insertions).unwrap();
        assert_eq!(files, 2, "should count both .md files");
        assert_eq!(insertions, 1, "only the file with marker should count");
    }

    #[test]
    fn scan_markdown_for_blurbs_nonexistent_dir_no_error() {
        let result = scan_markdown_for_blurbs(
            Path::new("/nonexistent/path"),
            0,
            3,
            true,
            &mut 0u64,
            &mut 0u64,
        );
        assert!(result.is_ok(), "nonexistent dir should not error");
    }

    //  Doctor commands tests (br-2ei.5.4) 

    #[test]
    fn clap_parses_doctor_check_defaults() {
        let cli = Cli::try_parse_from(["am", "doctor", "check"]).unwrap();
        match cli.command {
            Commands::Doctor {
                action:
                    DoctorCommand::Check {
                        project,
                        verbose,
                        json,
                    },
            } => {
                assert!(project.is_none());
                assert!(!verbose);
                assert!(!json);
            }
            _ => panic!("expected Doctor Check"),
        }
    }

    #[test]
    fn clap_parses_doctor_check_all_flags() {
        let cli =
            Cli::try_parse_from(["am", "doctor", "check", "my-proj", "-v", "--json"]).unwrap();
        match cli.command {
            Commands::Doctor {
                action:
                    DoctorCommand::Check {
                        project,
                        verbose,
                        json,
                    },
            } => {
                assert_eq!(project.as_deref(), Some("my-proj"));
                assert!(verbose);
                assert!(json);
            }
            _ => panic!("expected Doctor Check"),
        }
    }

    #[test]
    fn clap_parses_doctor_repair_defaults() {
        let cli = Cli::try_parse_from(["am", "doctor", "repair"]).unwrap();
        match cli.command {
            Commands::Doctor {
                action:
                    DoctorCommand::Repair {
                        project,
                        dry_run,
                        yes,
                        backup_dir,
                    },
            } => {
                assert!(project.is_none());
                assert!(!dry_run);
                assert!(!yes);
                assert!(backup_dir.is_none());
            }
            _ => panic!("expected Doctor Repair"),
        }
    }

    #[test]
    fn clap_parses_doctor_repair_all_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "doctor",
            "repair",
            "proj",
            "--dry-run",
            "-y",
            "--backup-dir",
            "/tmp/bak",
        ])
        .unwrap();
        match cli.command {
            Commands::Doctor {
                action:
                    DoctorCommand::Repair {
                        project,
                        dry_run,
                        yes,
                        backup_dir,
                    },
            } => {
                assert_eq!(project.as_deref(), Some("proj"));
                assert!(dry_run);
                assert!(yes);
                assert_eq!(backup_dir.unwrap(), PathBuf::from("/tmp/bak"));
            }
            _ => panic!("expected Doctor Repair"),
        }
    }

    #[test]
    fn clap_parses_doctor_backups_defaults() {
        let cli = Cli::try_parse_from(["am", "doctor", "backups"]).unwrap();
        match cli.command {
            Commands::Doctor {
                action: DoctorCommand::Backups { json },
            } => assert!(!json),
            _ => panic!("expected Doctor Backups"),
        }
    }

    #[test]
    fn clap_parses_doctor_backups_json() {
        let cli = Cli::try_parse_from(["am", "doctor", "backups", "--json"]).unwrap();
        match cli.command {
            Commands::Doctor {
                action: DoctorCommand::Backups { json },
            } => assert!(json),
            _ => panic!("expected Doctor Backups"),
        }
    }

    #[test]
    fn clap_parses_doctor_restore_required_path() {
        let cli = Cli::try_parse_from(["am", "doctor", "restore", "/tmp/backup.sqlite3"]).unwrap();
        match cli.command {
            Commands::Doctor {
                action:
                    DoctorCommand::Restore {
                        backup_path,
                        dry_run,
                        yes,
                    },
            } => {
                assert_eq!(backup_path, PathBuf::from("/tmp/backup.sqlite3"));
                assert!(!dry_run);
                assert!(!yes);
            }
            _ => panic!("expected Doctor Restore"),
        }
    }

    #[test]
    fn clap_parses_doctor_restore_all_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "doctor",
            "restore",
            "/tmp/backup.sqlite3",
            "--dry-run",
            "-y",
        ])
        .unwrap();
        match cli.command {
            Commands::Doctor {
                action:
                    DoctorCommand::Restore {
                        backup_path,
                        dry_run,
                        yes,
                    },
            } => {
                assert_eq!(backup_path, PathBuf::from("/tmp/backup.sqlite3"));
                assert!(dry_run);
                assert!(yes);
            }
            _ => panic!("expected Doctor Restore"),
        }
    }

    #[test]
    fn doctor_backups_lists_sqlite3_files_only() {
        let tmp = tempfile::tempdir().unwrap();
        let backup_dir = tmp.path().join("backups");
        std::fs::create_dir_all(&backup_dir).unwrap();
        std::fs::write(
            backup_dir.join("pre_repair_20260101_120000.sqlite3"),
            b"data1",
        )
        .unwrap();
        std::fs::write(
            backup_dir.join("pre_repair_20260102_120000.sqlite3"),
            b"data22",
        )
        .unwrap();
        std::fs::write(backup_dir.join("notes.txt"), b"not a backup").unwrap();

        let mut count = 0u32;
        for entry in std::fs::read_dir(&backup_dir).unwrap().flatten() {
            if entry.path().extension().and_then(|s| s.to_str()) == Some("sqlite3") {
                count += 1;
            }
        }
        assert_eq!(count, 2, "should find exactly 2 .sqlite3 files");
    }

    #[test]
    fn doctor_restore_rejects_missing_backup() {
        let result =
            handle_doctor_restore(PathBuf::from("/nonexistent/backup.sqlite3"), true, true);
        assert!(result.is_err());
        match result.unwrap_err() {
            CliError::InvalidArgument(msg) => {
                assert!(msg.contains("backup not found"), "got: {msg}");
            }
            other => panic!("expected InvalidArgument, got: {other:?}"),
        }
    }

    #[test]
    fn doctor_check_json_output_shape() {
        let checks = vec![
            serde_json::json!({"check": "database", "status": "ok", "detail": "accessible"}),
            serde_json::json!({"check": "storage_root", "status": "warn", "detail": "/tmp"}),
        ];
        let all_ok = checks.iter().all(|c| c["status"] != "fail");
        let output = serde_json::json!({"healthy": all_ok, "checks": checks});
        assert!(output["healthy"].as_bool().unwrap());
        assert_eq!(output["checks"].as_array().unwrap().len(), 2);
        for c in output["checks"].as_array().unwrap() {
            assert!(c["check"].is_string());
            assert!(c["status"].is_string());
            assert!(c["detail"].is_string());
        }
    }

    #[test]
    fn doctor_check_fail_makes_healthy_false() {
        let checks = [serde_json::json!({"check": "database", "status": "fail", "detail": "err"})];
        let all_ok = checks.iter().all(|c| c["status"] != "fail");
        assert!(!all_ok);
    }

    #[test]
    fn doctor_check_status_icon_mapping() {
        for (status, expected) in [("ok", "OK"), ("warn", "WARN"), ("fail", "FAIL")] {
            let icon = match status {
                "ok" => "OK",
                "warn" => "WARN",
                _ => "FAIL",
            };
            assert_eq!(icon, expected);
        }
    }

    #[test]
    fn doctor_repair_integrity_result_parsing() {
        assert!("ok" == "ok", "ok should be healthy");
        let bad = "*** in database main ***";
        assert!(bad != "ok", "corruption string should not be healthy");
    }

    #[test]
    fn doctor_backup_filename_format() {
        let ts = chrono::Utc::now().format("%Y%m%d_%H%M%S");
        let name = format!("pre_repair_{ts}.sqlite3");
        assert!(name.starts_with("pre_repair_"));
        assert!(name.ends_with(".sqlite3"));
        // "pre_repair_" (11) + "YYYYMMDD_HHMMSS" (15) + ".sqlite3" (8) = 34
        assert_eq!(name.len(), 34, "unexpected length: {name}");
    }

    #[test]
    fn format_bytes_human_readable() {
        assert_eq!(format_bytes(0), "0 B");
        assert_eq!(format_bytes(100), "100 B");
        assert_eq!(format_bytes(1024), "1.0 KiB");
        assert_eq!(format_bytes(1536), "1.5 KiB");
        assert_eq!(format_bytes(1_048_576), "1.0 MiB");
        assert_eq!(format_bytes(1_073_741_824), "1.0 GiB");
    }

    //  br-2ei.5.7.1: unit parsing + defaults 

    #[test]
    fn clap_parses_serve_stdio() {
        let cli = Cli::try_parse_from(["am", "serve-stdio"]).unwrap();
        assert!(matches!(cli.command, Commands::ServeStdio));
    }

    #[test]
    fn clap_parses_lint() {
        let cli = Cli::try_parse_from(["am", "lint"]).unwrap();
        assert!(matches!(cli.command, Commands::Lint));
    }

    #[test]
    fn clap_parses_typecheck() {
        let cli = Cli::try_parse_from(["am", "typecheck"]).unwrap();
        assert!(matches!(cli.command, Commands::Typecheck));
    }

    #[test]
    fn clap_parses_list_projects_defaults() {
        let cli = Cli::try_parse_from(["am", "list-projects"]).unwrap();
        match cli.command {
            Commands::ListProjects {
                include_agents,
                json,
            } => {
                assert!(!include_agents);
                assert!(!json);
            }
            other => panic!("expected ListProjects, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_list_projects_flags() {
        let cli =
            Cli::try_parse_from(["am", "list-projects", "--include-agents", "--json"]).unwrap();
        match cli.command {
            Commands::ListProjects {
                include_agents,
                json,
            } => {
                assert!(include_agents);
                assert!(json);
            }
            other => panic!("expected ListProjects, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_list_acks() {
        let cli = Cli::try_parse_from([
            "am",
            "list-acks",
            "--project",
            "/tmp/proj",
            "--agent",
            "BlueLake",
        ])
        .unwrap();
        match cli.command {
            Commands::ListAcks {
                project_key,
                agent_name,
                limit,
            } => {
                assert_eq!(project_key, "/tmp/proj");
                assert_eq!(agent_name, "BlueLake");
                assert_eq!(limit, 20); // default
            }
            other => panic!("expected ListAcks, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_list_acks_custom_limit() {
        let cli = Cli::try_parse_from([
            "am",
            "list-acks",
            "--project",
            "/tmp/proj",
            "--agent",
            "BlueLake",
            "--limit",
            "5",
        ])
        .unwrap();
        match cli.command {
            Commands::ListAcks { limit, .. } => assert_eq!(limit, 5),
            other => panic!("expected ListAcks, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_guard_install() {
        let cli =
            Cli::try_parse_from(["am", "guard", "install", "my-project", "/tmp/repo"]).unwrap();
        match cli.command {
            Commands::Guard {
                action:
                    GuardCommand::Install {
                        project,
                        repo,
                        prepush,
                        no_prepush,
                    },
            } => {
                assert_eq!(project, "my-project");
                assert_eq!(repo, PathBuf::from("/tmp/repo"));
                assert!(!prepush);
                assert!(!no_prepush);
            }
            other => panic!("expected Guard Install, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_guard_install_prepush() {
        let cli = Cli::try_parse_from(["am", "guard", "install", "proj", "/tmp/repo", "--prepush"])
            .unwrap();
        match cli.command {
            Commands::Guard {
                action: GuardCommand::Install { prepush, .. },
            } => assert!(prepush),
            other => panic!("expected Guard Install, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_guard_uninstall() {
        let cli = Cli::try_parse_from(["am", "guard", "uninstall", "/tmp/repo"]).unwrap();
        match cli.command {
            Commands::Guard {
                action: GuardCommand::Uninstall { repo },
            } => assert_eq!(repo, PathBuf::from("/tmp/repo")),
            other => panic!("expected Guard Uninstall, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_guard_status() {
        let cli = Cli::try_parse_from(["am", "guard", "status", "/tmp/repo"]).unwrap();
        match cli.command {
            Commands::Guard {
                action: GuardCommand::Status { repo },
            } => assert_eq!(repo, PathBuf::from("/tmp/repo")),
            other => panic!("expected Guard Status, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_guard_check_defaults() {
        let cli = Cli::try_parse_from(["am", "guard", "check"]).unwrap();
        match cli.command {
            Commands::Guard {
                action:
                    GuardCommand::Check {
                        stdin_nul,
                        advisory,
                        repo,
                    },
            } => {
                assert!(!stdin_nul);
                assert!(!advisory);
                assert!(repo.is_none());
            }
            other => panic!("expected Guard Check, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_guard_check_all_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "guard",
            "check",
            "--stdin-nul",
            "--advisory",
            "--repo",
            "/tmp/repo",
        ])
        .unwrap();
        match cli.command {
            Commands::Guard {
                action:
                    GuardCommand::Check {
                        stdin_nul,
                        advisory,
                        repo,
                    },
            } => {
                assert!(stdin_nul);
                assert!(advisory);
                assert_eq!(repo, Some(PathBuf::from("/tmp/repo")));
            }
            other => panic!("expected Guard Check, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_file_reservations_list() {
        let cli = Cli::try_parse_from(["am", "file_reservations", "list", "my-project"]).unwrap();
        match cli.command {
            Commands::FileReservations {
                action:
                    FileReservationsCommand::List {
                        project,
                        active_only,
                        all,
                    },
            } => {
                assert_eq!(project, "my-project");
                assert!(!active_only);
                assert!(!all);
            }
            other => panic!("expected FileReservations List, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_file_reservations_list_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "file_reservations",
            "list",
            "proj",
            "--active-only",
            "--all",
        ])
        .unwrap();
        match cli.command {
            Commands::FileReservations {
                action:
                    FileReservationsCommand::List {
                        active_only, all, ..
                    },
            } => {
                assert!(active_only);
                assert!(all);
            }
            other => panic!("expected FileReservations List, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_file_reservations_active() {
        let cli = Cli::try_parse_from(["am", "file_reservations", "active", "proj"]).unwrap();
        match cli.command {
            Commands::FileReservations {
                action: FileReservationsCommand::Active { project, limit },
            } => {
                assert_eq!(project, "proj");
                assert!(limit.is_none());
            }
            other => panic!("expected FileReservations Active, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_file_reservations_soon() {
        let cli =
            Cli::try_parse_from(["am", "file_reservations", "soon", "proj", "--minutes", "15"])
                .unwrap();
        match cli.command {
            Commands::FileReservations {
                action: FileReservationsCommand::Soon { project, minutes },
            } => {
                assert_eq!(project, "proj");
                assert_eq!(minutes, Some(15));
            }
            other => panic!("expected FileReservations Soon, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_acks_pending() {
        let cli = Cli::try_parse_from(["am", "acks", "pending", "proj", "BlueLake"]).unwrap();
        match cli.command {
            Commands::Acks {
                action:
                    AcksCommand::Pending {
                        project,
                        agent,
                        limit,
                    },
            } => {
                assert_eq!(project, "proj");
                assert_eq!(agent, "BlueLake");
                assert_eq!(limit, 20); // default
            }
            other => panic!("expected Acks Pending, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_acks_remind() {
        let cli = Cli::try_parse_from(["am", "acks", "remind", "proj", "BlueLake"]).unwrap();
        match cli.command {
            Commands::Acks {
                action:
                    AcksCommand::Remind {
                        project,
                        agent,
                        min_age_minutes,
                        limit,
                    },
            } => {
                assert_eq!(project, "proj");
                assert_eq!(agent, "BlueLake");
                assert_eq!(min_age_minutes, 30); // default
                assert_eq!(limit, 50); // default
            }
            other => panic!("expected Acks Remind, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_acks_overdue() {
        let cli = Cli::try_parse_from([
            "am",
            "acks",
            "overdue",
            "proj",
            "BlueLake",
            "--ttl-minutes",
            "120",
            "--limit",
            "10",
        ])
        .unwrap();
        match cli.command {
            Commands::Acks {
                action:
                    AcksCommand::Overdue {
                        project,
                        agent,
                        ttl_minutes,
                        limit,
                    },
            } => {
                assert_eq!(project, "proj");
                assert_eq!(agent, "BlueLake");
                assert_eq!(ttl_minutes, 120);
                assert_eq!(limit, 10);
            }
            other => panic!("expected Acks Overdue, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_config_set_port() {
        let cli = Cli::try_parse_from(["am", "config", "set-port", "9999"]).unwrap();
        match cli.command {
            Commands::Config {
                action: ConfigCommand::SetPort { port, env_file },
            } => {
                assert_eq!(port, 9999);
                assert!(env_file.is_none());
            }
            other => panic!("expected Config SetPort, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_config_set_port_env_file() {
        let cli = Cli::try_parse_from([
            "am",
            "config",
            "set-port",
            "8080",
            "--env-file",
            "/tmp/.env",
        ])
        .unwrap();
        match cli.command {
            Commands::Config {
                action: ConfigCommand::SetPort { port, env_file },
            } => {
                assert_eq!(port, 8080);
                assert_eq!(env_file, Some(PathBuf::from("/tmp/.env")));
            }
            other => panic!("expected Config SetPort, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_config_show_port() {
        let cli = Cli::try_parse_from(["am", "config", "show-port"]).unwrap();
        assert!(matches!(
            cli.command,
            Commands::Config {
                action: ConfigCommand::ShowPort
            }
        ));
    }

    #[test]
    fn clap_parses_projects_mark_identity() {
        let cli = Cli::try_parse_from(["am", "projects", "mark-identity", "/tmp/proj"]).unwrap();
        match cli.command {
            Commands::Projects {
                action:
                    ProjectsCommand::MarkIdentity {
                        project_path,
                        commit,
                        no_commit,
                    },
            } => {
                assert_eq!(project_path, PathBuf::from("/tmp/proj"));
                assert!(commit); // default true
                assert!(!no_commit);
            }
            other => panic!("expected Projects MarkIdentity, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_projects_mark_identity_no_commit() {
        let cli = Cli::try_parse_from([
            "am",
            "projects",
            "mark-identity",
            "/tmp/proj",
            "--no-commit",
        ])
        .unwrap();
        match cli.command {
            Commands::Projects {
                action: ProjectsCommand::MarkIdentity { no_commit, .. },
            } => assert!(no_commit),
            other => panic!("expected Projects MarkIdentity, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_projects_discovery_init() {
        let cli = Cli::try_parse_from(["am", "projects", "discovery-init", "/tmp/proj"]).unwrap();
        match cli.command {
            Commands::Projects {
                action:
                    ProjectsCommand::DiscoveryInit {
                        project_path,
                        product,
                    },
            } => {
                assert_eq!(project_path, PathBuf::from("/tmp/proj"));
                assert!(product.is_none());
            }
            other => panic!("expected Projects DiscoveryInit, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_projects_discovery_init_product() {
        let cli = Cli::try_parse_from([
            "am",
            "projects",
            "discovery-init",
            "/tmp/proj",
            "-P",
            "my-product",
        ])
        .unwrap();
        match cli.command {
            Commands::Projects {
                action: ProjectsCommand::DiscoveryInit { product, .. },
            } => assert_eq!(product, Some("my-product".to_string())),
            other => panic!("expected Projects DiscoveryInit, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_projects_adopt_defaults() {
        let cli = Cli::try_parse_from(["am", "projects", "adopt", "/tmp/src", "/tmp/dst"]).unwrap();
        match cli.command {
            Commands::Projects {
                action:
                    ProjectsCommand::Adopt {
                        source,
                        target,
                        dry_run,
                        apply,
                    },
            } => {
                assert_eq!(source, PathBuf::from("/tmp/src"));
                assert_eq!(target, PathBuf::from("/tmp/dst"));
                assert!(dry_run); // default true
                assert!(!apply);
            }
            other => panic!("expected Projects Adopt, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_projects_adopt_apply() {
        let cli =
            Cli::try_parse_from(["am", "projects", "adopt", "/tmp/src", "/tmp/dst", "--apply"])
                .unwrap();
        match cli.command {
            Commands::Projects {
                action: ProjectsCommand::Adopt { apply, .. },
            } => assert!(apply),
            other => panic!("expected Projects Adopt, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_mail_status() {
        let cli = Cli::try_parse_from(["am", "mail", "status", "/tmp/proj"]).unwrap();
        match cli.command {
            Commands::Mail {
                action: MailCommand::Status { project_path },
            } => assert_eq!(project_path, PathBuf::from("/tmp/proj")),
            other => panic!("expected Mail Status, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_products_ensure_defaults() {
        let cli = Cli::try_parse_from(["am", "products", "ensure"]).unwrap();
        match cli.command {
            Commands::Products {
                action:
                    ProductsCommand::Ensure {
                        product_key,
                        name,
                        json,
                    },
            } => {
                assert!(product_key.is_none());
                assert!(name.is_none());
                assert!(!json);
            }
            other => panic!("expected Products Ensure, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_products_ensure_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "products",
            "ensure",
            "pk-1",
            "-n",
            "MyProduct",
            "--json",
        ])
        .unwrap();
        match cli.command {
            Commands::Products {
                action:
                    ProductsCommand::Ensure {
                        product_key,
                        name,
                        json,
                    },
            } => {
                assert_eq!(product_key, Some("pk-1".to_string()));
                assert_eq!(name, Some("MyProduct".to_string()));
                assert!(json);
            }
            other => panic!("expected Products Ensure, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_products_link() {
        let cli =
            Cli::try_parse_from(["am", "products", "link", "pk-1", "proj-1", "--json"]).unwrap();
        match cli.command {
            Commands::Products {
                action:
                    ProductsCommand::Link {
                        product_key,
                        project,
                        json,
                    },
            } => {
                assert_eq!(product_key, "pk-1");
                assert_eq!(project, "proj-1");
                assert!(json);
            }
            other => panic!("expected Products Link, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_products_status() {
        let cli = Cli::try_parse_from(["am", "products", "status", "pk-1"]).unwrap();
        match cli.command {
            Commands::Products {
                action: ProductsCommand::Status { product_key, json },
            } => {
                assert_eq!(product_key, "pk-1");
                assert!(!json); // default
            }
            other => panic!("expected Products Status, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_products_summarize_thread() {
        let cli = Cli::try_parse_from(["am", "products", "summarize-thread", "pk-1", "thread-abc"])
            .unwrap();
        match cli.command {
            Commands::Products {
                action:
                    ProductsCommand::SummarizeThread {
                        product_key,
                        thread_id,
                        per_thread_limit,
                        no_llm,
                        json,
                    },
            } => {
                assert_eq!(product_key, "pk-1");
                assert_eq!(thread_id, "thread-abc");
                assert_eq!(per_thread_limit, 50); // default
                assert!(!no_llm);
                assert!(!json);
            }
            other => panic!("expected Products SummarizeThread, got {other:?}"),
        }
    }

    #[test]
    fn clap_parses_products_summarize_thread_flags() {
        let cli = Cli::try_parse_from([
            "am",
            "products",
            "summarize-thread",
            "pk-1",
            "thread-abc",
            "-n",
            "10",
            "--no-llm",
            "--json",
        ])
        .unwrap();
        match cli.command {
            Commands::Products {
                action:
                    ProductsCommand::SummarizeThread {
                        per_thread_limit,
                        no_llm,
                        json,
                        ..
                    },
            } => {
                assert_eq!(per_thread_limit, 10);
                assert!(no_llm);
                assert!(json);
            }
            other => panic!("expected Products SummarizeThread, got {other:?}"),
        }
    }

    //  Invalid arg / exit code tests 

    #[test]
    fn clap_rejects_serve_http_invalid_port() {
        let err = Cli::try_parse_from(["am", "serve-http", "--port", "not_a_number"]);
        assert!(err.is_err());
    }

    #[test]
    fn clap_rejects_list_acks_missing_project() {
        let err = Cli::try_parse_from(["am", "list-acks", "--agent", "BlueLake"]);
        assert!(err.is_err());
    }

    #[test]
    fn clap_rejects_list_acks_missing_agent() {
        let err = Cli::try_parse_from(["am", "list-acks", "--project", "/tmp"]);
        assert!(err.is_err());
    }

    #[test]
    fn clap_rejects_guard_install_missing_repo() {
        let err = Cli::try_parse_from(["am", "guard", "install", "proj"]);
        assert!(err.is_err());
    }

    #[test]
    fn clap_rejects_acks_pending_missing_agent() {
        let err = Cli::try_parse_from(["am", "acks", "pending", "proj"]);
        assert!(err.is_err());
    }

    #[test]
    fn clap_rejects_config_set_port_invalid() {
        let err = Cli::try_parse_from(["am", "config", "set-port", "99999"]);
        assert!(err.is_err());
    }

    #[test]
    fn clap_rejects_unknown_subcommand() {
        let err = Cli::try_parse_from(["am", "nonexistent"]);
        assert!(err.is_err());
    }

    #[test]
    fn clap_rejects_mail_status_missing_path() {
        let err = Cli::try_parse_from(["am", "mail", "status"]);
        assert!(err.is_err());
    }

    //  br-2ei.5.7.3: golden help snapshots 
    //
    // Verify that help text contains expected commands and flags.
    // Uses clap's error rendering (--help triggers a clap error) to
    // capture help text without spawning a subprocess.

    fn help_text_for(args: &[&str]) -> String {
        match Cli::try_parse_from(args) {
            Ok(_) => panic!("expected --help to trigger clap exit"),
            Err(e) => e.to_string(),
        }
    }

    #[test]
    fn help_top_level_lists_all_subcommands() {
        let h = help_text_for(&["am", "--help"]);
        let expected = [
            "serve-http",
            "serve-stdio",
            "lint",
            "typecheck",
            "share",
            "archive",
            "guard",
            "acks",
            "list-acks",
            "migrate",
            "list-projects",
            "clear-and-reset-everything",
            "config",
            "amctl",
            "am-run",
            "projects",
            "mail",
            "products",
            "docs",
            "doctor",
        ];
        for cmd in expected {
            assert!(
                h.contains(cmd),
                "top-level help missing subcommand '{cmd}'\n--- help ---\n{h}"
            );
        }
    }

    #[test]
    fn help_serve_http_lists_flags() {
        let h = help_text_for(&["am", "serve-http", "--help"]);
        for flag in ["--host", "--port", "--path"] {
            assert!(
                h.contains(flag),
                "serve-http help missing flag '{flag}'\n{h}"
            );
        }
    }

    #[test]
    fn help_share_lists_subcommands() {
        let h = help_text_for(&["am", "share", "--help"]);
        for cmd in ["export", "update", "preview", "verify", "decrypt", "wizard"] {
            assert!(
                h.contains(cmd),
                "share help missing subcommand '{cmd}'\n{h}"
            );
        }
    }

    #[test]
    fn help_share_export_lists_flags() {
        let h = help_text_for(&["am", "share", "export", "--help"]);
        for flag in [
            "--output",
            "--interactive",
            "--project",
            "--inline-threshold",
            "--detach-threshold",
            "--scrub-preset",
            "--chunk-threshold",
            "--chunk-size",
            "--dry-run",
            "--zip",
            "--signing-key",
            "--age-recipient",
        ] {
            assert!(
                h.contains(flag),
                "share export help missing flag '{flag}'\n{h}"
            );
        }
    }

    #[test]
    fn help_guard_lists_subcommands() {
        let h = help_text_for(&["am", "guard", "--help"]);
        for cmd in ["install", "uninstall", "status", "check"] {
            assert!(
                h.contains(cmd),
                "guard help missing subcommand '{cmd}'\n{h}"
            );
        }
    }

    #[test]
    fn help_guard_check_lists_flags() {
        let h = help_text_for(&["am", "guard", "check", "--help"]);
        for flag in ["--stdin-nul", "--advisory", "--repo"] {
            assert!(
                h.contains(flag),
                "guard check help missing flag '{flag}'\n{h}"
            );
        }
    }

    #[test]
    fn help_doctor_lists_subcommands() {
        let h = help_text_for(&["am", "doctor", "--help"]);
        for cmd in ["check", "repair", "backups", "restore"] {
            assert!(
                h.contains(cmd),
                "doctor help missing subcommand '{cmd}'\n{h}"
            );
        }
    }

    #[test]
    fn help_doctor_repair_lists_flags() {
        let h = help_text_for(&["am", "doctor", "repair", "--help"]);
        for flag in ["--dry-run", "--yes", "--backup-dir"] {
            assert!(
                h.contains(flag),
                "doctor repair help missing flag '{flag}'\n{h}"
            );
        }
    }

    #[test]
    fn help_archive_lists_subcommands() {
        let h = help_text_for(&["am", "archive", "--help"]);
        for cmd in ["save", "list", "restore"] {
            assert!(
                h.contains(cmd),
                "archive help missing subcommand '{cmd}'\n{h}"
            );
        }
    }

    #[test]
    fn help_products_lists_subcommands() {
        let h = help_text_for(&["am", "products", "--help"]);
        for cmd in [
            "ensure",
            "link",
            "status",
            "search",
            "inbox",
            "summarize-thread",
        ] {
            assert!(
                h.contains(cmd),
                "products help missing subcommand '{cmd}'\n{h}"
            );
        }
    }

    #[test]
    fn help_acks_lists_subcommands() {
        let h = help_text_for(&["am", "acks", "--help"]);
        for cmd in ["pending", "remind", "overdue"] {
            assert!(h.contains(cmd), "acks help missing subcommand '{cmd}'\n{h}");
        }
    }

    #[test]
    fn help_projects_lists_subcommands() {
        let h = help_text_for(&["am", "projects", "--help"]);
        for cmd in ["mark-identity", "discovery-init", "adopt"] {
            assert!(
                h.contains(cmd),
                "projects help missing subcommand '{cmd}'\n{h}"
            );
        }
    }

    #[test]
    fn help_config_lists_subcommands() {
        let h = help_text_for(&["am", "config", "--help"]);
        for cmd in ["set-port", "show-port"] {
            assert!(
                h.contains(cmd),
                "config help missing subcommand '{cmd}'\n{h}"
            );
        }
    }

    #[test]
    fn help_clear_and_reset_lists_flags() {
        let h = help_text_for(&["am", "clear-and-reset-everything", "--help"]);
        for flag in ["--force", "--archive", "--no-archive"] {
            assert!(
                h.contains(flag),
                "clear-and-reset-everything help missing flag '{flag}'\n{h}"
            );
        }
    }

    #[test]
    fn help_docs_lists_subcommands() {
        let h = help_text_for(&["am", "docs", "--help"]);
        assert!(
            h.contains("insert-blurbs"),
            "docs help missing subcommand 'insert-blurbs'\n{h}"
        );
    }

    #[test]
    fn help_am_run_lists_flags() {
        let h = help_text_for(&["am", "am-run", "--help"]);
        for flag in [
            "--path",
            "--agent",
            "--ttl-seconds",
            "--shared",
            "--exclusive",
            "--block-on-conflicts",
        ] {
            assert!(h.contains(flag), "am-run help missing flag '{flag}'\n{h}");
        }
    }

    #[test]
    fn help_list_acks_lists_flags() {
        let h = help_text_for(&["am", "list-acks", "--help"]);
        for flag in ["--project", "--agent", "--limit"] {
            assert!(
                h.contains(flag),
                "list-acks help missing flag '{flag}'\n{h}"
            );
        }
    }

    #[test]
    fn help_top_level_contains_name_and_version() {
        let h = help_text_for(&["am", "--help"]);
        assert!(h.contains("am") || h.contains("MCP Agent Mail"));
    }

    //  br-2ei.5.7.4: JSON output stability 
    //
    // Verify JSON schemas for commands that produce machine-readable output.

    #[test]
    fn json_list_projects_schema_fields() {
        // list-projects --json emits an array of objects with:
        // { id, slug, human_key, created_at }
        let entry = serde_json::json!({
            "id": 1,
            "slug": "proj-abc123",
            "human_key": "/tmp/my-project",
            "created_at": "2026-01-01T00:00:00Z"
        });
        assert!(entry["id"].is_i64());
        assert!(entry["slug"].is_string());
        assert!(entry["human_key"].is_string());
        assert!(entry["created_at"].is_string());
    }

    #[test]
    fn json_list_projects_with_agents_schema() {
        // When --include-agents is set, each project gains an "agents" array.
        let entry = serde_json::json!({
            "id": 1,
            "slug": "proj-abc",
            "human_key": "/tmp/proj",
            "created_at": "2026-01-01T00:00:00Z",
            "agents": [
                {"name": "BlueLake", "program": "claude-code", "model": "opus"}
            ]
        });
        assert!(entry["agents"].is_array());
        let agent = &entry["agents"][0];
        assert!(agent["name"].is_string());
        assert!(agent["program"].is_string());
        assert!(agent["model"].is_string());
    }

    #[test]
    fn json_doctor_check_schema_stable() {
        let output = serde_json::json!({
            "healthy": true,
            "checks": [
                {"check": "database", "status": "ok", "detail": "accessible"},
                {"check": "storage_root", "status": "ok", "detail": "/tmp/store"}
            ]
        });
        assert!(output["healthy"].is_boolean());
        assert!(output["checks"].is_array());
        for check in output["checks"].as_array().unwrap() {
            assert!(check["check"].is_string(), "check field must be string");
            assert!(check["status"].is_string(), "status field must be string");
            assert!(check["detail"].is_string(), "detail field must be string");
            let status = check["status"].as_str().unwrap();
            assert!(
                ["ok", "warn", "fail"].contains(&status),
                "status must be ok/warn/fail, got {status}"
            );
        }
    }

    #[test]
    fn json_doctor_backups_schema() {
        // doctor backups --json emits an array of { name, size }
        let arr = serde_json::json!([
            {"name": "pre_repair_20260101_120000.sqlite3", "size": 4096},
            {"name": "pre_repair_20260102_130000.sqlite3", "size": 8192}
        ]);
        assert!(arr.is_array());
        for item in arr.as_array().unwrap() {
            assert!(item["name"].is_string());
            assert!(item["size"].is_number());
        }
    }

    #[test]
    fn json_archive_list_schema() {
        // archive list --json emits array of { file, size_bytes, modified, label }
        let entry = serde_json::json!({
            "file": "archive_20260101.sqlite3",
            "size_bytes": 12345,
            "modified": "2026-01-01T12:00:00Z",
            "label": "my-label"
        });
        assert!(entry["file"].is_string());
        assert!(entry["size_bytes"].is_number());
        assert!(entry["modified"].is_string());
    }

    #[test]
    fn json_lease_record_schema() {
        // am-run lease records follow LeaseRecord schema
        let lease = serde_json::json!({
            "slot": "frontend-build",
            "agent": "BlueLake",
            "branch": "main",
            "exclusive": true,
            "acquired_ts": "2026-01-01T00:00:00Z",
            "expires_ts": "2026-01-01T01:00:00Z"
        });
        assert!(lease["slot"].is_string());
        assert!(lease["agent"].is_string());
        assert!(lease["branch"].is_string());
        assert!(lease["exclusive"].is_boolean());
        assert!(lease["acquired_ts"].is_string());
        assert!(lease["expires_ts"].is_string());
        assert!(lease.get("released_ts").is_none() || lease["released_ts"].is_null());
    }

    #[test]
    fn json_lease_record_roundtrips_through_serde() {
        let lease = LeaseRecord {
            slot: "build".to_string(),
            agent: "BlueLake".to_string(),
            branch: "main".to_string(),
            exclusive: true,
            acquired_ts: "2026-01-01T00:00:00Z".to_string(),
            expires_ts: "2026-01-01T01:00:00Z".to_string(),
            released_ts: None,
        };
        let json = serde_json::to_string(&lease).unwrap();
        let parsed: serde_json::Value = serde_json::from_str(&json).unwrap();
        assert_eq!(parsed["slot"], "build");
        assert_eq!(parsed["agent"], "BlueLake");
        assert!(!json.contains("released_ts")); // skip_serializing_if None
    }

    #[test]
    fn json_lease_record_released_ts_included_when_set() {
        let lease = LeaseRecord {
            slot: "build".to_string(),
            agent: "BlueLake".to_string(),
            branch: "main".to_string(),
            exclusive: false,
            acquired_ts: "2026-01-01T00:00:00Z".to_string(),
            expires_ts: "2026-01-01T01:00:00Z".to_string(),
            released_ts: Some("2026-01-01T00:30:00Z".to_string()),
        };
        let json = serde_json::to_string(&lease).unwrap();
        assert!(json.contains("released_ts"));
        let parsed: serde_json::Value = serde_json::from_str(&json).unwrap();
        assert_eq!(parsed["released_ts"], "2026-01-01T00:30:00Z");
    }

    //  br-2ei.5.7.2: integration exit codes 
    //
    // Tests that exercise the actual command handlers and verify exit behavior.

    #[test]
    fn integration_migrate_and_list_projects_json() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let db_path = dir.path().join("test.sqlite3");
        let db_url = format!("sqlite:///{}", db_path.display());

        // Migrate
        let result = handle_migrate_with_database_url(&db_url);
        assert!(result.is_ok(), "migrate failed: {result:?}");

        // list-projects should succeed with empty output
        let capture = ftui_runtime::StdioCapture::install().unwrap();
        let result = handle_list_projects_with_database_url(&db_url, false, true);
        let output = capture.drain_to_string();
        assert!(result.is_ok(), "list-projects --json failed: {result:?}");

        // Parse JSON output - should be empty array
        let parsed: serde_json::Value = serde_json::from_str(output.trim()).unwrap();
        assert!(parsed.is_array(), "expected JSON array, got: {parsed}");
        assert_eq!(parsed.as_array().unwrap().len(), 0);
    }

    #[test]
    fn integration_doctor_check_on_fresh_db() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let db_path = dir.path().join("test.sqlite3");
        let db_url = format!("sqlite:///{}", db_path.display());

        handle_migrate_with_database_url(&db_url).expect("migrate");

        // Doctor check should succeed on a fresh DB
        let capture = ftui_runtime::StdioCapture::install().unwrap();
        let result = handle_doctor_check_with(&db_url, dir.path(), None, false, true);
        let output = capture.drain_to_string();

        assert!(result.is_ok(), "doctor check failed: {result:?}");
        // JSON output should have "healthy" field
        if !output.trim().is_empty() {
            let parsed: serde_json::Value = serde_json::from_str(output.trim()).unwrap();
            assert!(parsed["healthy"].is_boolean());
        }
    }

    #[test]
    fn integration_doctor_backups_empty_dir() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();

        let capture = ftui_runtime::StdioCapture::install().unwrap();
        let result = handle_doctor_backups_with_storage_root(dir.path(), true);
        let output = capture.drain_to_string();

        assert!(result.is_ok(), "doctor backups --json failed: {result:?}");
        if !output.trim().is_empty() {
            let parsed: serde_json::Value = serde_json::from_str(output.trim()).unwrap();
            assert!(parsed.is_array());
        }
    }

    #[test]
    fn integration_config_show_port_returns_ok() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let capture = ftui_runtime::StdioCapture::install().unwrap();
        let result = handle_config(ConfigCommand::ShowPort);
        let output = capture.drain_to_string();
        assert!(result.is_ok(), "config show-port failed: {result:?}");
        // Should output a port number
        assert!(
            output.trim().parse::<u16>().is_ok() || output.contains("8765"),
            "expected port number, got: {output}"
        );
    }

    #[test]
    fn integration_config_set_port_to_file() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let env_file = dir.path().join(".env");
        let result = handle_config(ConfigCommand::SetPort {
            port: 9999,
            env_file: Some(env_file.clone()),
        });
        assert!(result.is_ok(), "config set-port failed: {result:?}");
        let content = std::fs::read_to_string(&env_file).unwrap_or_default();
        assert!(
            content.contains("9999"),
            "env file should contain port 9999, got: {content}"
        );
    }

    /// Helper: seed a DB with projects, agents, messages, and file_reservations for CLI tests.
    fn seed_acks_and_reservations_db(db_path: &Path) -> sqlmodel_sqlite::SqliteConnection {
        use mcp_agent_mail_db::sqlmodel::Value as SqlValue;

        let conn = sqlmodel_sqlite::SqliteConnection::open_file(db_path.display().to_string())
            .expect("open sqlite db");
        conn.execute_raw(&mcp_agent_mail_db::schema::init_schema_sql())
            .expect("init schema");

        let now_us = mcp_agent_mail_db::timestamps::now_micros();

        // Project
        conn.execute_sync(
            "INSERT INTO projects (id, slug, human_key, created_at) VALUES (?, ?, ?, ?)",
            &[
                SqlValue::BigInt(1),
                SqlValue::Text("test-proj".to_string()),
                SqlValue::Text("/tmp/test-proj".to_string()),
                SqlValue::BigInt(now_us),
            ],
        )
        .unwrap();

        // Agents
        let agent_insert = "INSERT INTO agents (\
                id, project_id, name, program, model, task_description, \
                inception_ts, last_active_ts, attachments_policy, contact_policy\
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
        conn.execute_sync(
            agent_insert,
            &[
                SqlValue::BigInt(1),
                SqlValue::BigInt(1),
                SqlValue::Text("BlueLake".to_string()),
                SqlValue::Text("test".to_string()),
                SqlValue::Text("test".to_string()),
                SqlValue::Text(String::new()),
                SqlValue::BigInt(now_us),
                SqlValue::BigInt(now_us),
                SqlValue::Text("auto".to_string()),
                SqlValue::Text("auto".to_string()),
            ],
        )
        .unwrap();
        conn.execute_sync(
            agent_insert,
            &[
                SqlValue::BigInt(2),
                SqlValue::BigInt(1),
                SqlValue::Text("RedFox".to_string()),
                SqlValue::Text("test".to_string()),
                SqlValue::Text("test".to_string()),
                SqlValue::Text(String::new()),
                SqlValue::BigInt(now_us),
                SqlValue::BigInt(now_us),
                SqlValue::Text("auto".to_string()),
                SqlValue::Text("auto".to_string()),
            ],
        )
        .unwrap();

        // Messages (ack_required=1 from RedFox to BlueLake)
        let msg_insert = "INSERT INTO messages (\
                id, project_id, sender_id, thread_id, subject, body_md, importance, \
                ack_required, created_ts, attachments\
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
        conn.execute_sync(
            msg_insert,
            &[
                SqlValue::BigInt(100),
                SqlValue::BigInt(1),
                SqlValue::BigInt(2), // sender: RedFox
                SqlValue::Null,
                SqlValue::Text("Please review PR".to_string()),
                SqlValue::Text("body".to_string()),
                SqlValue::Text("high".to_string()),
                SqlValue::BigInt(1),                    // ack_required
                SqlValue::BigInt(now_us - 120_000_000), // 2 min ago
                SqlValue::Text("[]".to_string()),
            ],
        )
        .unwrap();
        // Non-ack message
        conn.execute_sync(
            msg_insert,
            &[
                SqlValue::BigInt(101),
                SqlValue::BigInt(1),
                SqlValue::BigInt(2),
                SqlValue::Null,
                SqlValue::Text("FYI update".to_string()),
                SqlValue::Text("body".to_string()),
                SqlValue::Text("normal".to_string()),
                SqlValue::BigInt(0),                   // not ack_required
                SqlValue::BigInt(now_us - 60_000_000), // 1 min ago
                SqlValue::Text("[]".to_string()),
            ],
        )
        .unwrap();

        // Recipients
        let recip_insert =
            "INSERT INTO message_recipients (message_id, agent_id, kind) VALUES (?, ?, ?)";
        conn.execute_sync(
            recip_insert,
            &[
                SqlValue::BigInt(100),
                SqlValue::BigInt(1), // BlueLake
                SqlValue::Text("to".to_string()),
            ],
        )
        .unwrap();
        conn.execute_sync(
            recip_insert,
            &[
                SqlValue::BigInt(101),
                SqlValue::BigInt(1),
                SqlValue::Text("to".to_string()),
            ],
        )
        .unwrap();

        // File reservations (active, by BlueLake)
        let future_ts = now_us + 3_600_000_000; // 1 hour from now
        conn.execute_sync(
            "INSERT INTO file_reservations (\
                id, project_id, agent_id, path_pattern, exclusive, reason, \
                created_ts, expires_ts, released_ts\
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
            &[
                SqlValue::BigInt(1),
                SqlValue::BigInt(1),
                SqlValue::BigInt(1), // BlueLake
                SqlValue::Text("src/api/*.rs".to_string()),
                SqlValue::BigInt(1),
                SqlValue::Text("refactoring API".to_string()),
                SqlValue::BigInt(now_us),
                SqlValue::BigInt(future_ts),
                SqlValue::Null, // not released
            ],
        )
        .unwrap();

        conn
    }

    #[test]
    fn integration_acks_pending_shows_unacked_messages() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let db_path = dir.path().join("test.sqlite3");
        let conn = seed_acks_and_reservations_db(&db_path);

        let capture = ftui_runtime::StdioCapture::install().unwrap();
        let result = handle_acks_with_conn(
            &conn,
            AcksCommand::Pending {
                project: "test-proj".to_string(),
                agent: "BlueLake".to_string(),
                limit: 20,
            },
        );
        let output = capture.drain_to_string();
        assert!(result.is_ok(), "acks pending failed: {result:?}");
        // Should show the ack-required message from RedFox
        assert!(
            output.contains("RedFox") && output.contains("Please review PR"),
            "expected ack-required message in output, got: {output}"
        );
    }

    #[test]
    fn integration_acks_pending_empty_when_no_acks() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let db_path = dir.path().join("test.sqlite3");
        let conn = seed_acks_and_reservations_db(&db_path);

        let capture = ftui_runtime::StdioCapture::install().unwrap();
        // RedFox has no ack-required messages
        let result = handle_acks_with_conn(
            &conn,
            AcksCommand::Pending {
                project: "test-proj".to_string(),
                agent: "RedFox".to_string(),
                limit: 20,
            },
        );
        let output = capture.drain_to_string();
        assert!(result.is_ok(), "acks pending failed: {result:?}");
        assert!(
            output.contains("No pending acks"),
            "expected empty result, got: {output}"
        );
    }

    #[test]
    fn integration_acks_overdue_finds_old_messages() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let db_path = dir.path().join("test.sqlite3");
        let conn = seed_acks_and_reservations_db(&db_path);

        let capture = ftui_runtime::StdioCapture::install().unwrap();
        // ttl_minutes=1 means messages older than 1 min are overdue;
        // our message is 2 min old
        let result = handle_acks_with_conn(
            &conn,
            AcksCommand::Overdue {
                project: "test-proj".to_string(),
                agent: "BlueLake".to_string(),
                ttl_minutes: 1,
                limit: 50,
            },
        );
        let output = capture.drain_to_string();
        assert!(result.is_ok(), "acks overdue failed: {result:?}");
        assert!(
            output.contains("OVERDUE") && output.contains("RedFox"),
            "expected overdue ack in output, got: {output}"
        );
    }

    #[test]
    fn integration_list_acks_shows_ack_required_messages() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let db_path = dir.path().join("test.sqlite3");
        let conn = seed_acks_and_reservations_db(&db_path);

        let capture = ftui_runtime::StdioCapture::install().unwrap();
        let result = handle_list_acks_with_conn(&conn, "test-proj", "BlueLake", 20);
        let output = capture.drain_to_string();
        assert!(result.is_ok(), "list-acks failed: {result:?}");
        assert!(
            output.contains("RedFox") && output.contains("pending"),
            "expected ack-required message with pending status, got: {output}"
        );
    }

    #[test]
    fn integration_list_acks_empty_for_nonexistent_agent() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let db_path = dir.path().join("test.sqlite3");
        let conn = seed_acks_and_reservations_db(&db_path);

        let capture = ftui_runtime::StdioCapture::install().unwrap();
        let result = handle_list_acks_with_conn(&conn, "test-proj", "GhostAgent", 20);
        let output = capture.drain_to_string();
        assert!(result.is_ok(), "list-acks failed: {result:?}");
        assert!(
            output.contains("No ack-required messages"),
            "expected empty result, got: {output}"
        );
    }

    #[test]
    fn integration_file_reservations_list_shows_active() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let db_path = dir.path().join("test.sqlite3");
        let conn = seed_acks_and_reservations_db(&db_path);

        let capture = ftui_runtime::StdioCapture::install().unwrap();
        let result = handle_file_reservations_with_conn(
            &conn,
            FileReservationsCommand::List {
                project: "test-proj".to_string(),
                active_only: false,
                all: false,
            },
        );
        let output = capture.drain_to_string();
        assert!(result.is_ok(), "file_reservations list failed: {result:?}");
        assert!(
            output.contains("src/api/*.rs") && output.contains("BlueLake"),
            "expected reservation in output, got: {output}"
        );
    }

    #[test]
    fn integration_file_reservations_active_shows_active() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let db_path = dir.path().join("test.sqlite3");
        let conn = seed_acks_and_reservations_db(&db_path);

        let capture = ftui_runtime::StdioCapture::install().unwrap();
        let result = handle_file_reservations_with_conn(
            &conn,
            FileReservationsCommand::Active {
                project: "test-proj".to_string(),
                limit: None,
            },
        );
        let output = capture.drain_to_string();
        assert!(
            result.is_ok(),
            "file_reservations active failed: {result:?}"
        );
        assert!(
            output.contains("src/api/*.rs") && output.contains("BlueLake"),
            "expected active reservation, got: {output}"
        );
    }

    #[test]
    fn integration_file_reservations_empty_project() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let db_path = dir.path().join("test.sqlite3");
        let conn = seed_acks_and_reservations_db(&db_path);

        let capture = ftui_runtime::StdioCapture::install().unwrap();
        let result = handle_file_reservations_with_conn(
            &conn,
            FileReservationsCommand::List {
                project: "nonexistent-proj".to_string(),
                active_only: false,
                all: false,
            },
        );
        let output = capture.drain_to_string();
        assert!(result.is_ok(), "file_reservations list failed: {result:?}");
        assert!(
            output.contains("No file reservations"),
            "expected empty result, got: {output}"
        );
    }

    #[test]
    fn integration_acks_remind_finds_stale() {
        let _guard = stdio_capture_lock().lock().unwrap();
        let dir = tempfile::tempdir().unwrap();
        let db_path = dir.path().join("test.sqlite3");
        let conn = seed_acks_and_reservations_db(&db_path);

        let capture = ftui_runtime::StdioCapture::install().unwrap();
        // min_age_minutes=1 means messages older than 1 min are stale;
        // our ack-required message is 2 min old
        let result = handle_acks_with_conn(
            &conn,
            AcksCommand::Remind {
                project: "test-proj".to_string(),
                agent: "BlueLake".to_string(),
                min_age_minutes: 1,
                limit: 50,
            },
        );
        let output = capture.drain_to_string();
        assert!(result.is_ok(), "acks remind failed: {result:?}");
        assert!(
            output.contains("Stale acks") && output.contains("RedFox"),
            "expected stale ack reminder, got: {output}"
        );
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct LeaseRecord {
    slot: String,
    agent: String,
    branch: String,
    exclusive: bool,
    acquired_ts: String,
    expires_ts: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    released_ts: Option<String>,
}

fn handle_am_run(args: AmRunArgs) -> CliResult<()> {
    let config = Config::from_env();
    let server_url = format!(
        "http://{}:{}{}",
        config.http_host, config.http_port, config.http_path
    );
    handle_am_run_with(
        &config,
        Some(server_url.as_str()),
        config.http_bearer_token.as_deref(),
        args,
    )
}

#[allow(clippy::too_many_lines)]
fn handle_am_run_with(
    config: &Config,
    server_url: Option<&str>,
    bearer: Option<&str>,
    args: AmRunArgs,
) -> CliResult<()> {
    use std::time::Duration;

    let identity = resolve_project_identity(args.path.to_string_lossy().as_ref());
    let agent_name = args
        .agent
        .or_else(|| std::env::var("AGENT_NAME").ok())
        .unwrap_or_else(|| "Unknown".to_string());
    let branch = identity
        .branch
        .clone()
        .filter(|b| !b.is_empty())
        .or_else(|| compute_git_branch(&args.path))
        .unwrap_or_else(|| "unknown".to_string());

    let shared = resolve_bool(args.shared, args.exclusive, false);
    let block_on_conflicts =
        resolve_bool(args.block_on_conflicts, args.no_block_on_conflicts, false);

    let cache_key = format!(
        "am-cache-{}-{}-{}",
        identity.project_uid, agent_name, branch
    );

    let ttl_seconds = args.ttl_seconds.max(60);
    let now = Utc::now();
    let expires = now + chrono::Duration::seconds(ttl_seconds);
    let lease = LeaseRecord {
        slot: args.slot.clone(),
        agent: agent_name.clone(),
        branch: branch.clone(),
        exclusive: !shared,
        acquired_ts: now.to_rfc3339(),
        expires_ts: expires.to_rfc3339(),
        released_ts: None,
    };

    // Ensure local lease path exists upfront so tests can observe it even if server path is used.
    // This is best-effort (legacy behavior) because server-based build slot leases don't strictly
    // require local filesystem writes.
    let mut slot_dir_opt: Option<PathBuf> = None;
    let mut lease_path_opt: Option<PathBuf> = None;
    if let Ok(dir) = ensure_slot_dir(config, &identity.slug, &args.slot) {
        let path = lease_path(&dir, &agent_name, &branch);
        let _ = write_lease(&path, &lease);
        slot_dir_opt = Some(dir);
        lease_path_opt = Some(path);
    }

    #[derive(Debug, Clone, Copy, PartialEq, Eq)]
    enum LeaseBackend {
        Server,
        Local,
        None,
    }

    let mut backend = LeaseBackend::None;
    let mut acquired_via_server = false;
    let mut planned_exit_code: Option<i32> = None;

    let mut stop_tx: Option<std::sync::mpsc::Sender<()>> = None;
    let mut renew_thread: Option<std::thread::JoinHandle<()>> = None;

    if config.worktrees_enabled {
        // Prefer server tools when available; fallback to local filesystem leases.
        let mut server_conflicts: Vec<serde_json::Value> = Vec::new();
        if let Some(url) = server_url {
            use asupersync::runtime::RuntimeBuilder;

            let runtime = RuntimeBuilder::current_thread()
                .build()
                .map_err(|e| CliError::Other(format!("runtime init failed: {e}")))?;

            let ensure_ok = runtime
                .block_on(async {
                    try_call_server_tool(
                        url,
                        bearer,
                        "ensure_project",
                        serde_json::json!({ "human_key": identity.human_key.clone() }),
                    )
                    .await
                })
                .is_some();

            if ensure_ok {
                let acquired = runtime.block_on(async {
                    try_call_server_tool(
                        url,
                        bearer,
                        "acquire_build_slot",
                        serde_json::json!({
                            "project_key": identity.human_key.clone(),
                            "agent_name": agent_name.clone(),
                            "slot": args.slot.clone(),
                            "ttl_seconds": ttl_seconds,
                            "exclusive": !shared,
                        }),
                    )
                    .await
                });

                if let Some(result) = acquired.and_then(coerce_tool_result_json) {
                    backend = LeaseBackend::Server;
                    acquired_via_server = true;
                    server_conflicts = result
                        .get("conflicts")
                        .and_then(|v| v.as_array())
                        .cloned()
                        .unwrap_or_default();
                }
            }
        }

        if backend != LeaseBackend::Server {
            backend = LeaseBackend::Local;
        }

        if backend == LeaseBackend::Server {
            if !server_conflicts.is_empty() {
                if guard_mode_warn() {
                    ftui_runtime::ftui_eprintln!(
                        "warning: build slot conflicts (server advisory, proceeding)"
                    );
                    for c in &server_conflicts {
                        let slot = c.get("slot").and_then(|v| v.as_str()).unwrap_or("");
                        let agent = c.get("agent").and_then(|v| v.as_str()).unwrap_or("");
                        let branch = c.get("branch").and_then(|v| v.as_str()).unwrap_or("");
                        let expires_ts = c.get("expires_ts").and_then(|v| v.as_str()).unwrap_or("");
                        ftui_runtime::ftui_eprintln!(
                            "  - slot={slot} agent={agent} branch={branch} expires={expires_ts}"
                        );
                    }
                }
                if !shared && block_on_conflicts {
                    ftui_runtime::ftui_eprintln!(
                        "error: build slot conflicts detected and --block-on-conflicts set; aborting."
                    );
                    planned_exit_code = Some(1);
                }
            }
        } else {
            let slot_dir = match slot_dir_opt {
                Some(dir) => dir,
                None => ensure_slot_dir(config, &identity.slug, &args.slot)?,
            };
            if lease_path_opt.is_none() {
                let path = lease_path(&slot_dir, &agent_name, &branch);
                let _ = write_lease(&path, &lease);
                lease_path_opt = Some(path);
            }

            let conflicts = read_active_leases(&slot_dir, &agent_name, &branch, shared);
            if !conflicts.is_empty() {
                if guard_mode_warn() {
                    ftui_runtime::ftui_eprintln!(
                        "warning: build slot conflicts (advisory, proceeding)"
                    );
                    for conflict in &conflicts {
                        ftui_runtime::ftui_eprintln!(
                            "  - slot={} agent={} branch={} expires={}",
                            conflict.slot,
                            conflict.agent,
                            conflict.branch,
                            conflict.expires_ts
                        );
                    }
                }
                if !shared && block_on_conflicts {
                    ftui_runtime::ftui_eprintln!(
                        "error: build slot conflicts detected and --block-on-conflicts set; aborting."
                    );
                    planned_exit_code = Some(1);
                }
            }
        }

        // Start renewer thread only if we are proceeding with the child command.
        if planned_exit_code.is_none() {
            let (tx, rx) = std::sync::mpsc::channel::<()>();
            stop_tx = Some(tx);

            let interval = std::cmp::max(60, ttl_seconds / 2);
            if backend == LeaseBackend::Server {
                let Some(url) = server_url.map(|s| s.to_string()) else {
                    return Err(CliError::Other(
                        "server_url missing while using server backend".to_string(),
                    ));
                };
                let bearer = bearer.map(|s| s.to_string());
                let project_key = identity.human_key.clone();
                let agent_name = agent_name.clone();
                let slot = args.slot.clone();

                renew_thread = Some(std::thread::spawn(move || {
                    use asupersync::runtime::RuntimeBuilder;

                    let Ok(runtime) = RuntimeBuilder::current_thread().build() else {
                        return;
                    };
                    loop {
                        match rx.recv_timeout(Duration::from_secs(interval as u64)) {
                            Ok(()) | Err(std::sync::mpsc::RecvTimeoutError::Disconnected) => break,
                            Err(std::sync::mpsc::RecvTimeoutError::Timeout) => {
                                let _ = runtime.block_on(async {
                                    try_call_server_tool(
                                        &url,
                                        bearer.as_deref(),
                                        "renew_build_slot",
                                        serde_json::json!({
                                            "project_key": project_key,
                                            "agent_name": agent_name,
                                            "slot": slot,
                                            "extend_seconds": interval,
                                        }),
                                    )
                                    .await
                                });
                            }
                        }
                    }
                }));
            } else {
                let Some(lease_path) = lease_path_opt.clone() else {
                    return Err(CliError::Other(
                        "internal error: missing lease path for local build slot backend"
                            .to_string(),
                    ));
                };
                let slot_key = args.slot.clone();
                let agent_name = agent_name.clone();
                let branch = branch.clone();
                let exclusive = !shared;

                renew_thread = Some(std::thread::spawn(move || {
                    loop {
                        match rx.recv_timeout(Duration::from_secs(interval as u64)) {
                            Ok(()) | Err(std::sync::mpsc::RecvTimeoutError::Disconnected) => break,
                            Err(std::sync::mpsc::RecvTimeoutError::Timeout) => {
                                let now = Utc::now();
                                let expires = now + chrono::Duration::seconds(interval);
                                let mut updated =
                                    read_lease(&lease_path).unwrap_or_else(|| LeaseRecord {
                                        slot: slot_key.clone(),
                                        agent: agent_name.clone(),
                                        branch: branch.clone(),
                                        exclusive,
                                        acquired_ts: now.to_rfc3339(),
                                        expires_ts: expires.to_rfc3339(),
                                        released_ts: None,
                                    });
                                updated.expires_ts = expires.to_rfc3339();
                                let _ = write_lease(&lease_path, &updated);
                            }
                        }
                    }
                }));
            }
        }
    }

    let mut cmd = std::process::Command::new(&args.cmd[0]);
    if args.cmd.len() > 1 {
        cmd.args(&args.cmd[1..]);
    }
    cmd.env("AM_SLOT", &args.slot)
        .env("SLUG", &identity.slug)
        .env("PROJECT_UID", &identity.project_uid)
        .env("BRANCH", &branch)
        .env("AGENT", &agent_name)
        .env("CACHE_KEY", &cache_key);

    let exit_code = if let Some(code) = planned_exit_code {
        code
    } else {
        ftui_runtime::ftui_println!("$ {}  (slot={})", args.cmd.join(" "), args.slot);

        let status = cmd.status();
        match status {
            Ok(s) => s.code().unwrap_or(1),
            Err(e) if e.kind() == std::io::ErrorKind::NotFound => 127,
            Err(_) => 1,
        }
    };

    if config.worktrees_enabled {
        // Stop renewal, then release (server best-effort, local fallback).
        if let Some(tx) = stop_tx {
            let _ = tx.send(());
        }
        if let Some(handle) = renew_thread {
            let _ = handle.join();
        }

        let mut released_locally = false;
        if backend == LeaseBackend::Server && acquired_via_server {
            let server_released = if let Some(url) = server_url {
                use asupersync::runtime::RuntimeBuilder;
                match RuntimeBuilder::current_thread().build() {
                    Ok(runtime) => runtime
                        .block_on(async {
                            try_call_server_tool(
                                url,
                                bearer,
                                "release_build_slot",
                                serde_json::json!({
                                    "project_key": identity.human_key.clone(),
                                    "agent_name": agent_name.clone(),
                                    "slot": args.slot.clone(),
                                }),
                            )
                            .await
                        })
                        .is_some(),
                    Err(_) => false,
                }
            } else {
                false
            };

            if !server_released {
                if let Some(path) = lease_path_opt.as_ref() {
                    let now = Utc::now().to_rfc3339();
                    if let Some(mut lease) = read_lease(path) {
                        lease.released_ts = Some(now.clone());
                        lease.expires_ts = now.clone();
                        let _ = write_lease(path, &lease);
                        released_locally = true;
                    }
                }
            }
        } else {
            if let Some(path) = lease_path_opt.as_ref() {
                let now = Utc::now().to_rfc3339();
                if let Some(mut lease) = read_lease(path) {
                    lease.released_ts = Some(now.clone());
                    lease.expires_ts = now.clone();
                    let _ = write_lease(path, &lease);
                    released_locally = true;
                }
            }
        }

        if !released_locally && backend == LeaseBackend::Local {
            // If local lease couldn't be read (should be rare), do not treat as fatal.
        }
    }

    if exit_code != 0 {
        return Err(CliError::ExitCode(exit_code));
    }
    Ok(())
}

fn resolve_bool(primary: bool, negated: bool, default: bool) -> bool {
    if negated {
        return false;
    }
    if primary {
        return true;
    }
    default
}

fn ensure_dir(path: &Path) -> CliResult<()> {
    if !path.exists() {
        return Err(CliError::InvalidArgument(format!(
            "path not found: {}",
            path.display()
        )));
    }
    if !path.is_dir() {
        return Err(CliError::InvalidArgument(format!(
            "expected directory: {}",
            path.display()
        )));
    }
    Ok(())
}

fn compute_git_branch(path: &Path) -> Option<String> {
    let output = std::process::Command::new("git")
        .arg("-C")
        .arg(path)
        .args(["rev-parse", "--abbrev-ref", "HEAD"])
        .output()
        .ok()?;
    if !output.status.success() {
        return None;
    }
    let text = String::from_utf8_lossy(&output.stdout).trim().to_string();
    if text.is_empty() || text == "HEAD" {
        None
    } else {
        Some(text)
    }
}

fn ensure_slot_dir(config: &Config, slug: &str, slot: &str) -> CliResult<PathBuf> {
    let safe_slot = safe_component(slot);
    let slot_dir = config
        .storage_root
        .join("projects")
        .join(slug)
        .join("build_slots")
        .join(safe_slot);
    std::fs::create_dir_all(&slot_dir)?;
    Ok(slot_dir)
}

fn lease_path(slot_dir: &Path, agent: &str, branch: &str) -> PathBuf {
    let holder = safe_component(&format!("{agent}__{branch}"));
    slot_dir.join(format!("{holder}.json"))
}

fn safe_component(value: &str) -> String {
    let mut out = value.trim().to_string();
    for ch in ['/', '\\', ':', '*', '?', '"', '<', '>', '|', ' '] {
        out = out.replace(ch, "_");
    }
    if out.is_empty() {
        "unknown".to_string()
    } else {
        out
    }
}

fn guard_mode_warn() -> bool {
    matches!(
        std::env::var("AGENT_MAIL_GUARD_MODE")
            .unwrap_or_else(|_| "block".to_string())
            .trim()
            .to_ascii_lowercase()
            .as_str(),
        "warn" | "advisory" | "adv"
    )
}

fn read_active_leases(
    slot_dir: &Path,
    agent: &str,
    branch: &str,
    shared: bool,
) -> Vec<LeaseRecord> {
    let mut out = Vec::new();
    let now = Utc::now();
    let entries = match std::fs::read_dir(slot_dir) {
        Ok(e) => e,
        Err(_) => return out,
    };
    for entry in entries.flatten() {
        let path = entry.path();
        if path.extension().and_then(|s| s.to_str()) != Some("json") {
            continue;
        }
        let lease = match read_lease(&path) {
            Some(l) => l,
            None => continue,
        };
        if let Some(exp) = parse_rfc3339(&lease.expires_ts) {
            if exp <= now {
                continue;
            }
        }
        if lease.exclusive && !shared && !(lease.agent == agent && lease.branch == branch) {
            out.push(lease);
        }
    }
    out
}

fn parse_rfc3339(value: &str) -> Option<DateTime<Utc>> {
    DateTime::parse_from_rfc3339(value)
        .map(|dt| dt.with_timezone(&Utc))
        .ok()
}

fn read_lease(path: &Path) -> Option<LeaseRecord> {
    let text = std::fs::read_to_string(path).ok()?;
    serde_json::from_str(&text).ok()
}

fn write_lease(path: &Path, lease: &LeaseRecord) -> CliResult<()> {
    let payload = serde_json::to_string_pretty(lease)
        .map_err(|e| CliError::InvalidArgument(e.to_string()))?;
    std::fs::write(path, payload)?;
    Ok(())
}

// ---------------------------------------------------------------------------
// Share export pipeline
// ---------------------------------------------------------------------------

#[derive(Debug, Clone)]
struct ShareExportWizardDefaults {
    projects: Vec<String>,
    inline_threshold: i64,
    detach_threshold: i64,
    scrub_preset: String,
    chunk_threshold: i64,
    chunk_size: i64,
    zip: bool,
}

#[derive(Debug, Clone)]
struct ShareExportWizardResult {
    projects: Vec<String>,
    inline_threshold: i64,
    detach_threshold: i64,
    scrub_preset: String,
    chunk_threshold: i64,
    chunk_size: i64,
    zip: bool,
}

fn share_export_wizard(defaults: ShareExportWizardDefaults) -> CliResult<ShareExportWizardResult> {
    ftui_runtime::ftui_eprintln!("Interactive share export wizard\n");

    let projects_default = if defaults.projects.is_empty() {
        "all".to_string()
    } else {
        defaults.projects.join(", ")
    };
    let projects_line = prompt_line(&format!(
        "Project filters (comma-separated; empty = all) [{projects_default}]: "
    ))?;
    let projects = if projects_line.trim().is_empty() {
        defaults.projects
    } else {
        projects_line
            .split(',')
            .map(|s| s.trim())
            .filter(|s| !s.is_empty())
            .map(|s| s.to_string())
            .collect::<Vec<_>>()
    };

    let inline_threshold = prompt_i64("Inline threshold bytes", defaults.inline_threshold, |v| {
        v >= 0
    })?;
    let detach_threshold = prompt_i64("Detach threshold bytes", defaults.detach_threshold, |v| {
        v >= 0
    })?;
    let chunk_threshold = prompt_i64("Chunk threshold bytes", defaults.chunk_threshold, |v| {
        v >= 0
    })?;
    let chunk_size = prompt_i64("Chunk size bytes (min 1024)", defaults.chunk_size, |v| {
        v >= 1024
    })?;

    let scrub_preset = loop {
        let line = prompt_line(&format!(
            "Scrub preset (standard/strict/archive) [{}]: ",
            defaults.scrub_preset
        ))?;
        let candidate = if line.trim().is_empty() {
            defaults.scrub_preset.clone()
        } else {
            line.trim().to_string()
        };
        match share::normalize_scrub_preset(&candidate) {
            Ok(preset) => break preset.as_str().to_string(),
            Err(_) => {
                ftui_runtime::ftui_eprintln!(
                    "Invalid scrub preset: {candidate}. Expected: standard, strict, archive."
                );
            }
        }
    };

    let zip = prompt_bool("Package as ZIP", defaults.zip)?;

    Ok(ShareExportWizardResult {
        projects,
        inline_threshold,
        detach_threshold,
        scrub_preset,
        chunk_threshold,
        chunk_size,
        zip,
    })
}

fn prompt_line(prompt: &str) -> CliResult<String> {
    use std::io::Write;

    ftui_runtime::ftui_eprintln!("{prompt}");
    let _ = std::io::stderr().flush();
    let mut buf = String::new();
    std::io::stdin()
        .read_line(&mut buf)
        .map_err(|e| CliError::Other(format!("failed to read input: {e}")))?;
    Ok(buf.trim_end().to_string())
}

fn prompt_i64<F>(label: &str, default: i64, validate: F) -> CliResult<i64>
where
    F: Fn(i64) -> bool,
{
    loop {
        let line = prompt_line(&format!("{label} [{default}]: "))?;
        if line.trim().is_empty() {
            return Ok(default);
        }
        match line.trim().parse::<i64>() {
            Ok(value) if validate(value) => return Ok(value),
            Ok(_) => ftui_runtime::ftui_eprintln!("Invalid value for {label}."),
            Err(_) => ftui_runtime::ftui_eprintln!("Invalid integer for {label}."),
        }
    }
}

fn prompt_bool(label: &str, default: bool) -> CliResult<bool> {
    let suffix = if default { "[Y/n]" } else { "[y/N]" };
    loop {
        let line = prompt_line(&format!("{label}? {suffix}: "))?;
        let trimmed = line.trim().to_ascii_lowercase();
        if trimmed.is_empty() {
            return Ok(default);
        }
        match trimmed.as_str() {
            "y" | "yes" | "true" | "1" => return Ok(true),
            "n" | "no" | "false" | "0" => return Ok(false),
            _ => ftui_runtime::ftui_eprintln!("Please answer y/n."),
        }
    }
}

fn prepare_share_export_output_dir(output: &Path) -> CliResult<()> {
    if output.exists() {
        if !output.is_dir() {
            return Err(CliError::Other(format!(
                "export path {} exists and is not a directory",
                output.display()
            )));
        }
        let mut entries = output.read_dir()?;
        match entries.next() {
            None => {}
            Some(Ok(_)) => {
                return Err(CliError::Other(format!(
                    "export path {} is not empty; choose a new directory",
                    output.display()
                )));
            }
            Some(Err(e)) => return Err(CliError::Io(e)),
        }
        return Ok(());
    }

    std::fs::create_dir_all(output)?;
    Ok(())
}

fn zip_archive_path_for_dir(dir: &Path) -> PathBuf {
    let parent = dir.parent().unwrap_or_else(|| Path::new("."));
    let name = dir.file_name().and_then(|s| s.to_str()).unwrap_or("bundle");
    parent.join(format!("{name}.zip"))
}

fn sha256_file(path: &Path) -> CliResult<String> {
    use sha2::{Digest, Sha256};
    use std::io::Read;

    let mut file = std::fs::File::open(path)?;
    let mut hasher = Sha256::new();
    let mut buf = [0u8; 8192];
    loop {
        let n = file.read(&mut buf)?;
        if n == 0 {
            break;
        }
        hasher.update(&buf[..n]);
    }
    Ok(hex::encode(hasher.finalize()))
}

struct ShareExportParams {
    output: PathBuf,
    projects: Vec<String>,
    inline_threshold: usize,
    detach_threshold: usize,
    scrub_preset: share::ScrubPreset,
    chunk_threshold: usize,
    chunk_size: usize,
    dry_run: bool,
    zip: bool,
    signing_key: Option<PathBuf>,
    signing_public_out: Option<PathBuf>,
    age_recipients: Vec<String>,
}

struct ShareUpdateParams {
    bundle: PathBuf,
    projects: Vec<String>,
    inline_threshold: usize,
    detach_threshold: usize,
    scrub_preset: share::ScrubPreset,
    chunk_threshold: usize,
    chunk_size: usize,
    zip: bool,
    signing_key: Option<PathBuf>,
    signing_public_out: Option<PathBuf>,
    age_recipients: Vec<String>,
}

fn run_share_export(params: ShareExportParams) -> CliResult<()> {
    let cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
    let source_path = cfg
        .sqlite_path()
        .map_err(|e| CliError::Other(format!("bad database URL: {e}")))?;
    let source = std::path::Path::new(&source_path);

    if !source.exists() {
        return Err(CliError::Other(format!(
            "database not found: {source_path}"
        )));
    }

    ftui_runtime::ftui_println!("Source database: {source_path}");
    ftui_runtime::ftui_println!("Scrub preset:   {}", params.scrub_preset);

    // Dry run: create snapshot in temp dir and print summary only (no output artifacts).
    if params.dry_run {
        ftui_runtime::ftui_println!("Dry run - validating export in a temp directory.");

        let tmp = tempfile::tempdir()?;
        let snapshot_path = tmp.path().join("_snapshot.sqlite3");
        let snap_ctx = share::create_snapshot_context(
            source,
            &snapshot_path,
            &params.projects,
            params.scrub_preset,
        )?;

        ftui_runtime::ftui_println!("\nSummary:");
        ftui_runtime::ftui_println!("  Projects kept:        {}", snap_ctx.scope.projects.len());
        ftui_runtime::ftui_println!(
            "  Secrets replaced:     {}",
            snap_ctx.scrub_summary.secrets_replaced
        );
        ftui_runtime::ftui_println!(
            "  Bodies redacted:      {}",
            snap_ctx.scrub_summary.bodies_redacted
        );
        ftui_runtime::ftui_println!(
            "  Ack flags cleared:    {}",
            snap_ctx.scrub_summary.ack_flags_cleared
        );
        ftui_runtime::ftui_println!(
            "  Recipients cleared:   {}",
            snap_ctx.scrub_summary.recipients_cleared
        );
        ftui_runtime::ftui_println!(
            "  File reservations rm: {}",
            snap_ctx.scrub_summary.file_reservations_removed
        );
        ftui_runtime::ftui_println!(
            "  Agent links rm:       {}",
            snap_ctx.scrub_summary.agent_links_removed
        );

        ftui_runtime::ftui_println!("\nSecurity checklist:");
        ftui_runtime::ftui_println!("  1. Confirm the scrub preset matches your sharing intent.");
        ftui_runtime::ftui_println!(
            "  2. Review for any remaining secrets (search for \"sk-\", \"ghp_\", \"github_pat_\", \"xox\" in the exported content)."
        );
        ftui_runtime::ftui_println!(
            "  3. Double-check attachment handling (inline={}, detach={}).",
            params.inline_threshold,
            params.detach_threshold
        );
        ftui_runtime::ftui_println!(
            "  4. Run `am share verify <bundle>` after export (and after signing)."
        );

        return Ok(());
    }

    let output = &params.output;
    prepare_share_export_output_dir(output)?;

    // 1. Snapshot + scope + scrub + finalize
    ftui_runtime::ftui_println!("Creating snapshot...");
    let snapshot_path = output.join("_snapshot.sqlite3");
    if snapshot_path.exists() {
        std::fs::remove_file(&snapshot_path)?;
    }
    let snap_ctx = share::create_snapshot_context(
        source,
        &snapshot_path,
        &params.projects,
        params.scrub_preset,
    )?;

    ftui_runtime::ftui_println!("  Projects: {} kept", snap_ctx.scope.projects.len());
    ftui_runtime::ftui_println!(
        "  Scrub: {} secrets replaced, {} bodies redacted",
        snap_ctx.scrub_summary.secrets_replaced,
        snap_ctx.scrub_summary.bodies_redacted
    );

    // 2. Bundle attachments
    ftui_runtime::ftui_println!("Bundling attachments...");
    let config = Config::from_env();
    let att_manifest = share::bundle_attachments(
        &snapshot_path,
        output,
        &config.storage_root,
        params.inline_threshold,
        params.detach_threshold,
    )?;
    ftui_runtime::ftui_println!(
        "  Attachments: {} inline, {} copied, {} external, {} missing",
        att_manifest.stats.inline,
        att_manifest.stats.copied,
        att_manifest.stats.externalized,
        att_manifest.stats.missing
    );

    // 3. Copy DB to bundle
    let db_dest = output.join("mailbox.sqlite3");
    std::fs::copy(&snapshot_path, &db_dest)?;
    let db_sha256 = sha256_file(&db_dest)?;
    let db_size = db_dest.metadata()?.len();

    // 4. Maybe chunk
    let chunk =
        share::maybe_chunk_database(&db_dest, output, params.chunk_threshold, params.chunk_size)?;
    if let Some(ref c) = chunk {
        ftui_runtime::ftui_println!("  Database chunked into {} parts", c.chunk_count);
    }

    // 5. Viewer assets
    ftui_runtime::ftui_println!("Copying viewer assets...");
    let copied = share::copy_viewer_assets(output)?;
    ftui_runtime::ftui_println!("  Viewer assets: {} files", copied.len());

    // 6. Viewer data
    ftui_runtime::ftui_println!("Exporting viewer data...");
    let viewer_data = share::export_viewer_data(&snapshot_path, output, snap_ctx.fts_enabled)?;

    // 7. SRI hashes
    let sri = share::compute_viewer_sri(output);

    // 8. Hosting hints
    let hints = share::detect_hosting_hints(output);
    if !hints.is_empty() {
        ftui_runtime::ftui_println!(
            "  Hosting hint: {} (confidence: {})",
            hints[0].title,
            hints[0].signals.len()
        );
    }

    // 9. Scaffolding
    ftui_runtime::ftui_println!("Writing manifest and scaffolding...");
    share::write_bundle_scaffolding(
        output,
        &snap_ctx.scope,
        &snap_ctx.scrub_summary,
        &att_manifest,
        chunk.as_ref(),
        params.chunk_threshold,
        params.chunk_size,
        &hints,
        snap_ctx.fts_enabled,
        "mailbox.sqlite3",
        &db_sha256,
        db_size,
        Some(&viewer_data),
        &sri,
    )?;

    // 10. Sign
    if let Some(ref key_path) = params.signing_key {
        ftui_runtime::ftui_println!("Signing manifest...");
        let sig = share::sign_manifest(
            &output.join("manifest.json"),
            key_path,
            &output.join("manifest.sig.json"),
            true,
        )?;
        ftui_runtime::ftui_println!("  Algorithm: {}", sig.algorithm);
        if let Some(ref pub_out) = params.signing_public_out {
            std::fs::write(pub_out, &sig.public_key)?;
            ftui_runtime::ftui_println!("  Public key written to: {}", pub_out.display());
        }
    }

    // 11. Clean up snapshot
    let _ = std::fs::remove_file(&snapshot_path);

    // 12. ZIP
    let mut archive_path: Option<PathBuf> = None;
    let final_path = if params.zip {
        ftui_runtime::ftui_println!("Packaging as ZIP...");
        let zip_path = zip_archive_path_for_dir(output);
        share::package_directory_as_zip(output, &zip_path)?;
        ftui_runtime::ftui_println!("  ZIP: {}", zip_path.display());
        archive_path = Some(zip_path.clone());
        zip_path
    } else {
        output.clone()
    };

    // 13. Encrypt
    if !params.age_recipients.is_empty() {
        if let Some(ref archive) = archive_path {
            ftui_runtime::ftui_println!("Encrypting with age...");
            let encrypted = share::encrypt_with_age(archive, &params.age_recipients)?;
            ftui_runtime::ftui_println!("  Encrypted: {}", encrypted.display());
        } else {
            ftui_runtime::ftui_eprintln!(
                "warning: skipped age encryption because --zip was not enabled."
            );
        }
    }

    ftui_runtime::ftui_println!("Export complete: {}", final_path.display());
    Ok(())
}

fn run_share_update(params: ShareUpdateParams) -> CliResult<()> {
    fn copy_file(src: &Path, dst: &Path) -> CliResult<()> {
        if let Some(parent) = dst.parent() {
            std::fs::create_dir_all(parent)?;
        }
        std::fs::copy(src, dst)?;
        Ok(())
    }

    fn copy_dir_recursive(src: &Path, dst: &Path) -> CliResult<()> {
        std::fs::create_dir_all(dst)?;
        for entry in std::fs::read_dir(src)? {
            let entry = entry?;
            let src_path = entry.path();
            let dst_path = dst.join(entry.file_name());
            let ty = entry.file_type()?;
            if ty.is_dir() {
                copy_dir_recursive(&src_path, &dst_path)?;
                continue;
            }
            if ty.is_file() {
                std::fs::copy(&src_path, &dst_path)?;
                continue;
            }
            return Err(CliError::Other(format!(
                "unsupported file type in bundle: {}",
                src_path.display()
            )));
        }
        Ok(())
    }

    fn replace_dir(src: &Path, dst: &Path) -> CliResult<()> {
        if dst.exists() {
            std::fs::remove_dir_all(dst)?;
        }
        copy_dir_recursive(src, dst)
    }

    fn remove_file_if_exists(path: &Path) -> CliResult<()> {
        if path.exists() {
            std::fs::remove_file(path)?;
        }
        Ok(())
    }

    fn remove_dir_if_exists(path: &Path) -> CliResult<()> {
        if path.exists() {
            std::fs::remove_dir_all(path)?;
        }
        Ok(())
    }

    let cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
    let source_path = cfg
        .sqlite_path()
        .map_err(|e| CliError::Other(format!("bad database URL: {e}")))?;
    let source = std::path::Path::new(&source_path);
    if !source.exists() {
        return Err(CliError::Other(format!(
            "database not found: {source_path}"
        )));
    }

    if !params.bundle.is_dir() {
        return Err(CliError::Other(format!(
            "bundle path {} does not exist or is not a directory",
            params.bundle.display()
        )));
    }

    let existing_signature = params.bundle.join("manifest.sig.json").exists();

    ftui_runtime::ftui_println!("Source database: {source_path}");
    ftui_runtime::ftui_println!("Updating bundle: {}", params.bundle.display());
    ftui_runtime::ftui_println!("Scrub preset:   {}", params.scrub_preset);

    let tmp = tempfile::tempdir()?;
    let temp_bundle = tmp.path().join("bundle");
    std::fs::create_dir_all(&temp_bundle)?;

    // Build updated bundle assets into a temp directory.
    ftui_runtime::ftui_println!("Building updated bundle in temp directory...");

    // 1. Snapshot + scope + scrub + finalize
    ftui_runtime::ftui_println!("Creating snapshot...");
    let snapshot_path = temp_bundle.join("_snapshot.sqlite3");
    if snapshot_path.exists() {
        std::fs::remove_file(&snapshot_path)?;
    }
    let snap_ctx = share::create_snapshot_context(
        source,
        &snapshot_path,
        &params.projects,
        params.scrub_preset,
    )?;

    ftui_runtime::ftui_println!("  Projects: {} kept", snap_ctx.scope.projects.len());
    ftui_runtime::ftui_println!(
        "  Scrub: {} secrets replaced, {} bodies redacted",
        snap_ctx.scrub_summary.secrets_replaced,
        snap_ctx.scrub_summary.bodies_redacted
    );

    // 2. Bundle attachments
    ftui_runtime::ftui_println!("Bundling attachments...");
    let config = Config::from_env();
    let att_manifest = share::bundle_attachments(
        &snapshot_path,
        &temp_bundle,
        &config.storage_root,
        params.inline_threshold,
        params.detach_threshold,
    )?;
    ftui_runtime::ftui_println!(
        "  Attachments: {} inline, {} copied, {} external, {} missing",
        att_manifest.stats.inline,
        att_manifest.stats.copied,
        att_manifest.stats.externalized,
        att_manifest.stats.missing
    );

    // 3. Copy DB to bundle
    let db_dest = temp_bundle.join("mailbox.sqlite3");
    std::fs::copy(&snapshot_path, &db_dest)?;
    let db_sha256 = sha256_file(&db_dest)?;
    let db_size = db_dest.metadata()?.len();

    // 4. Maybe chunk
    let chunk = share::maybe_chunk_database(
        &db_dest,
        &temp_bundle,
        params.chunk_threshold,
        params.chunk_size,
    )?;
    if let Some(ref c) = chunk {
        ftui_runtime::ftui_println!("  Database chunked into {} parts", c.chunk_count);
    }

    // 5. Viewer assets
    ftui_runtime::ftui_println!("Copying viewer assets...");
    let copied = share::copy_viewer_assets(&temp_bundle)?;
    ftui_runtime::ftui_println!("  Viewer assets: {} files", copied.len());

    // 6. Viewer data
    ftui_runtime::ftui_println!("Exporting viewer data...");
    let viewer_data =
        share::export_viewer_data(&snapshot_path, &temp_bundle, snap_ctx.fts_enabled)?;

    // 7. SRI hashes
    let sri = share::compute_viewer_sri(&temp_bundle);

    // 8. Hosting hints (use destination bundle location for parity; temp dirs don't have git remotes).
    let hints = share::detect_hosting_hints(&params.bundle);
    if !hints.is_empty() {
        ftui_runtime::ftui_println!(
            "  Hosting hint: {} (confidence: {})",
            hints[0].title,
            hints[0].signals.len()
        );
    }

    // 9. Scaffolding
    ftui_runtime::ftui_println!("Writing manifest and scaffolding...");
    share::write_bundle_scaffolding(
        &temp_bundle,
        &snap_ctx.scope,
        &snap_ctx.scrub_summary,
        &att_manifest,
        chunk.as_ref(),
        params.chunk_threshold,
        params.chunk_size,
        &hints,
        snap_ctx.fts_enabled,
        "mailbox.sqlite3",
        &db_sha256,
        db_size,
        Some(&viewer_data),
        &sri,
    )?;

    // 10. Clean up snapshot
    let _ = std::fs::remove_file(&snapshot_path);

    ftui_runtime::ftui_println!(
        "Synchronizing updated bundle into: {}",
        params.bundle.display()
    );

    // Replace top-level generated files (but intentionally do NOT touch manifest.sig.json unless re-signing).
    let files = [
        "manifest.json",
        "README.md",
        "HOW_TO_DEPLOY.md",
        "index.html",
        ".nojekyll",
        "_headers",
        "mailbox.sqlite3",
    ];
    for name in files {
        copy_file(&temp_bundle.join(name), &params.bundle.join(name))?;
    }

    // Ensure bundle doesn't accumulate WAL/SHM files.
    remove_file_if_exists(&params.bundle.join("mailbox.sqlite3-wal"))?;
    remove_file_if_exists(&params.bundle.join("mailbox.sqlite3-shm"))?;
    remove_file_if_exists(&params.bundle.join("_snapshot.sqlite3"))?;

    // Viewer + attachments are always owned by the export; replace wholesale.
    replace_dir(&temp_bundle.join("viewer"), &params.bundle.join("viewer"))?;
    replace_dir(
        &temp_bundle.join("attachments"),
        &params.bundle.join("attachments"),
    )?;

    // Chunk artefacts: if the refreshed snapshot no longer needs chunking, prune the old chunk files.
    if chunk.is_some() {
        replace_dir(&temp_bundle.join("chunks"), &params.bundle.join("chunks"))?;
        copy_file(
            &temp_bundle.join("chunks.sha256"),
            &params.bundle.join("chunks.sha256"),
        )?;
        copy_file(
            &temp_bundle.join("mailbox.sqlite3.config.json"),
            &params.bundle.join("mailbox.sqlite3.config.json"),
        )?;
    } else {
        remove_dir_if_exists(&params.bundle.join("chunks"))?;
        remove_file_if_exists(&params.bundle.join("chunks.sha256"))?;
        remove_file_if_exists(&params.bundle.join("mailbox.sqlite3.config.json"))?;
    }

    // Sign (optional).
    if let Some(ref key_path) = params.signing_key {
        ftui_runtime::ftui_println!("Signing manifest...");
        let sig = share::sign_manifest(
            &params.bundle.join("manifest.json"),
            key_path,
            &params.bundle.join("manifest.sig.json"),
            true,
        )?;
        ftui_runtime::ftui_println!("  Algorithm: {}", sig.algorithm);
        if let Some(ref pub_out) = params.signing_public_out {
            std::fs::write(pub_out, &sig.public_key)?;
            ftui_runtime::ftui_println!("  Public key written to: {}", pub_out.display());
        }
    } else if existing_signature {
        ftui_runtime::ftui_eprintln!(
            "warning: existing manifest signature may no longer match; re-run with --signing-key to refresh it."
        );
    }

    // Package ZIP (optional).
    let mut archive_path: Option<PathBuf> = None;
    if params.zip {
        ftui_runtime::ftui_println!("Packaging as ZIP...");
        let zip_path = zip_archive_path_for_dir(&params.bundle);
        share::package_directory_as_zip(&params.bundle, &zip_path)?;
        ftui_runtime::ftui_println!("  ZIP: {}", zip_path.display());
        archive_path = Some(zip_path);
    }

    // Encrypt (optional). For update parity, warn but do not fail when --zip is not enabled.
    if !params.age_recipients.is_empty() {
        if let Some(ref archive) = archive_path {
            ftui_runtime::ftui_println!("Encrypting with age...");
            let encrypted = share::encrypt_with_age(archive, &params.age_recipients)?;
            ftui_runtime::ftui_println!("  Encrypted: {}", encrypted.display());
        } else {
            ftui_runtime::ftui_eprintln!(
                "warning: skipped age encryption because --zip was not enabled."
            );
        }
    }

    ftui_runtime::ftui_println!("Update complete: {}", params.bundle.display());
    Ok(())
}

// ---------------------------------------------------------------------------
// Archive commands
// ---------------------------------------------------------------------------

const ARCHIVE_DIR_NAME: &str = "archived_mailbox_states";
const ARCHIVE_METADATA_FILENAME: &str = "metadata.json";
const ARCHIVE_SNAPSHOT_RELATIVE: &str = "snapshot/mailbox.sqlite3";
const ARCHIVE_STORAGE_DIRNAME: &str = "storage_repo";

fn detect_project_root() -> PathBuf {
    let cwd = std::env::current_dir().unwrap_or_else(|_| PathBuf::from("."));
    let resolved = cwd.canonicalize().unwrap_or(cwd);

    // Archive root detection (where `archived_mailbox_states/` is created):
    // 1) Cargo.toml (Rust repos)
    // 2) pyproject.toml (legacy Python repos)
    // 3) .git (fallback)
    for candidate in resolved.ancestors() {
        if candidate.join("Cargo.toml").exists() {
            return candidate.to_path_buf();
        }
    }
    for candidate in resolved.ancestors() {
        if candidate.join("pyproject.toml").exists() {
            return candidate.to_path_buf();
        }
    }
    for candidate in resolved.ancestors() {
        if candidate.join(".git").exists() {
            return candidate.to_path_buf();
        }
    }

    resolved
}

fn archive_states_dir(create: bool) -> CliResult<PathBuf> {
    let root = detect_project_root();
    let archive_dir = root.join(ARCHIVE_DIR_NAME);
    if create {
        std::fs::create_dir_all(&archive_dir)?;
    }
    Ok(archive_dir)
}

fn slugify(value: &str) -> String {
    let trimmed = value.trim();
    let mut out = String::with_capacity(trimmed.len());
    let mut last_was_dash = false;

    for b in trimmed.bytes() {
        let lower = b.to_ascii_lowercase();
        if lower.is_ascii_alphanumeric() {
            out.push(lower as char);
            last_was_dash = false;
            continue;
        }
        if !out.is_empty() && !last_was_dash {
            out.push('-');
            last_was_dash = true;
        }
    }

    while out.ends_with('-') {
        out.pop();
    }

    if out.is_empty() {
        "project".to_string()
    } else {
        out
    }
}

fn compose_archive_basename(
    timestamp: DateTime<Utc>,
    project_filters: &[String],
    scrub_preset: &str,
    label: Option<&str>,
) -> String {
    let ts_segment = timestamp.format("%Y%m%d-%H%M%SZ").to_string();
    let projects_segment = if project_filters.is_empty() {
        "all-projects".to_string()
    } else {
        project_filters
            .iter()
            .map(|v| slugify(v))
            .collect::<Vec<_>>()
            .join("-")
    };
    let preset_segment = slugify(scrub_preset);

    let mut segments = vec![
        "mailbox-state".to_string(),
        ts_segment,
        projects_segment,
        preset_segment,
    ];
    if let Some(label) = label {
        segments.push(slugify(label));
    }
    segments.join("-")
}

fn ensure_unique_archive_path(base_dir: &Path, base_name: &str) -> PathBuf {
    let mut candidate = base_dir.join(format!("{base_name}.zip"));
    let mut counter = 1;
    while candidate.exists() {
        candidate = base_dir.join(format!("{base_name}-{counter:02}.zip"));
        counter += 1;
    }
    candidate
}

fn detect_git_head(repo_path: &Path) -> Option<String> {
    let git_dir = repo_path.join(".git");
    if !git_dir.exists() {
        return None;
    }

    let head_path = git_dir.join("HEAD");
    let head_contents = std::fs::read_to_string(head_path).ok()?;
    let head_contents = head_contents.trim();
    if head_contents.is_empty() {
        return None;
    }

    if let Some(ref_name) = head_contents.strip_prefix("ref:") {
        let ref_name = ref_name.trim();
        let ref_path = git_dir.join(ref_name);
        if ref_path.exists() {
            if let Ok(value) = std::fs::read_to_string(ref_path) {
                let value = value.trim();
                if !value.is_empty() {
                    return Some(value.to_string());
                }
            }
        }

        let packed_refs = git_dir.join("packed-refs");
        if packed_refs.exists() {
            if let Ok(text) = std::fs::read_to_string(packed_refs) {
                for line in text.lines() {
                    let line = line.trim();
                    if line.is_empty() || line.starts_with('#') {
                        continue;
                    }
                    let Some((commit, reference)) = line.split_once(' ') else {
                        continue;
                    };
                    if reference.trim() == ref_name {
                        return Some(commit.trim().to_string());
                    }
                }
            }
        }

        return None;
    }

    Some(head_contents.to_string())
}

fn next_backup_path(path: &Path, timestamp: &str) -> PathBuf {
    let filename = path
        .file_name()
        .map(|s| s.to_string_lossy().to_string())
        .unwrap_or_else(|| "backup".to_string());
    let mut candidate = path.with_file_name(format!("{filename}.backup-{timestamp}"));
    let mut counter = 1;
    while candidate.exists() {
        candidate = path.with_file_name(format!("{filename}.backup-{timestamp}-{counter:02}"));
        counter += 1;
    }
    candidate
}

fn sort_json_keys(value: &serde_json::Value) -> serde_json::Value {
    match value {
        serde_json::Value::Object(map) => {
            let mut keys: Vec<String> = map.keys().cloned().collect();
            keys.sort();
            let mut sorted = serde_json::Map::new();
            for key in keys {
                if let Some(v) = map.get(&key) {
                    sorted.insert(key, sort_json_keys(v));
                }
            }
            serde_json::Value::Object(sorted)
        }
        serde_json::Value::Array(arr) => {
            serde_json::Value::Array(arr.iter().map(sort_json_keys).collect())
        }
        other => other.clone(),
    }
}

fn iso_from_micros(micros: i64) -> String {
    DateTime::<Utc>::from_timestamp_micros(micros)
        .map(|dt| dt.to_rfc3339_opts(chrono::SecondsFormat::Secs, false))
        .unwrap_or_default()
}

fn projects_included_from_snapshot(snapshot_path: &Path) -> CliResult<Vec<serde_json::Value>> {
    let path_str = snapshot_path.display().to_string();
    let conn = sqlmodel_sqlite::SqliteConnection::open_file(&path_str)
        .map_err(|e| CliError::Other(format!("cannot open snapshot for metadata: {e}")))?;
    let rows = conn
        .query_sync(
            "SELECT slug, human_key, created_at FROM projects ORDER BY id",
            &[],
        )
        .map_err(|e| CliError::Other(format!("SELECT projects failed: {e}")))?;

    let mut out = Vec::new();
    for row in &rows {
        let slug: String = row.get_named("slug").unwrap_or_default();
        let human_key: String = row.get_named("human_key").unwrap_or_default();
        let created_at: i64 = row.get_named("created_at").unwrap_or(0);
        out.push(serde_json::json!({
            "slug": slug,
            "human_key": human_key,
            "created_at": if created_at == 0 {
                String::new()
            } else {
                iso_from_micros(created_at)
            },
        }));
    }
    Ok(out)
}

fn load_archive_metadata(zip_path: &Path) -> (serde_json::Value, Option<String>) {
    use std::io::Read;

    let file = match std::fs::File::open(zip_path) {
        Ok(f) => f,
        Err(e) => {
            return (
                serde_json::Value::Object(serde_json::Map::new()),
                Some(format!("Invalid metadata: {e}")),
            );
        }
    };

    let mut archive = match zip::ZipArchive::new(file) {
        Ok(a) => a,
        Err(e) => {
            return (
                serde_json::Value::Object(serde_json::Map::new()),
                Some(format!("Invalid metadata: {e}")),
            );
        }
    };

    let mut meta_file = match archive.by_name(ARCHIVE_METADATA_FILENAME) {
        Ok(f) => f,
        Err(zip::result::ZipError::FileNotFound) => {
            return (
                serde_json::Value::Object(serde_json::Map::new()),
                Some(format!("{ARCHIVE_METADATA_FILENAME} missing")),
            );
        }
        Err(e) => {
            return (
                serde_json::Value::Object(serde_json::Map::new()),
                Some(format!("Invalid metadata: {e}")),
            );
        }
    };

    let mut contents = String::new();
    if let Err(e) = meta_file.read_to_string(&mut contents) {
        return (
            serde_json::Value::Object(serde_json::Map::new()),
            Some(format!("Invalid metadata: {e}")),
        );
    }

    match serde_json::from_str::<serde_json::Value>(&contents) {
        Ok(value) => (value, None),
        Err(e) => (
            serde_json::Value::Object(serde_json::Map::new()),
            Some(format!("Invalid metadata: {e}")),
        ),
    }
}

fn resolve_archive_path(candidate: &Path) -> CliResult<PathBuf> {
    if candidate.exists() {
        return Ok(candidate
            .canonicalize()
            .unwrap_or_else(|_| candidate.to_path_buf()));
    }
    let archive_dir = archive_states_dir(false)?;
    let fallback = match candidate.file_name() {
        Some(name) => archive_dir.join(name),
        None => archive_dir.join(candidate),
    };
    if fallback.exists() {
        return Ok(fallback.canonicalize().unwrap_or(fallback));
    }
    Err(CliError::InvalidArgument(format!(
        "Archive '{}' not found (checked {} and {}).",
        candidate.display(),
        candidate.display(),
        fallback.display()
    )))
}

fn collect_files(base: &Path, dir: &Path, out: &mut Vec<PathBuf>) -> CliResult<()> {
    for entry in std::fs::read_dir(dir)? {
        let entry = entry?;
        let path = entry.path();
        if path.is_dir() {
            collect_files(base, &path, out)?;
        } else if path.is_file() {
            if let Ok(rel) = path.strip_prefix(base) {
                out.push(rel.to_path_buf());
            }
        }
    }
    Ok(())
}

#[cfg(unix)]
fn file_mode(path: &Path) -> u32 {
    use std::os::unix::fs::MetadataExt;
    std::fs::metadata(path)
        .map(|m| m.mode() & 0o777)
        .unwrap_or(0o644)
}

#[cfg(not(unix))]
fn file_mode(_path: &Path) -> u32 {
    0o644
}

fn confirm(prompt: &str, default: bool) -> CliResult<bool> {
    use std::io::Write;

    let suffix = if default { "[Y/n]" } else { "[y/N]" };
    ftui_runtime::ftui_println!("{prompt} {suffix}");
    let _ = std::io::stdout().flush();

    let mut input = String::new();
    std::io::stdin().read_line(&mut input)?;
    let input = input.trim().to_ascii_lowercase();
    if input.is_empty() {
        return Ok(default);
    }
    if input == "y" || input == "yes" {
        return Ok(true);
    }
    if input == "n" || input == "no" {
        return Ok(false);
    }
    Ok(default)
}

#[allow(dead_code)]
fn archive_save_state(
    source_db: &Path,
    storage_root: &Path,
    projects: Vec<String>,
    scrub_preset: String,
    label: Option<String>,
) -> CliResult<PathBuf> {
    use chrono::Timelike;
    use std::io::Write;

    if source_db.to_string_lossy() == ":memory:" {
        return Err(CliError::Other(
            "cannot archive an in-memory database (:memory:)".to_string(),
        ));
    }

    let preset = match share::normalize_scrub_preset(&scrub_preset) {
        Ok(p) => p,
        Err(_) => {
            ftui_runtime::ftui_eprintln!(
                "Invalid scrub preset '{scrub_preset}'. Choose one of: {}.",
                share::SCRUB_PRESETS.join(", ")
            );
            return Err(CliError::ExitCode(1));
        }
    };
    let preset_str = preset.as_str().to_string();

    if !source_db.exists() {
        return Err(CliError::Other(format!(
            "database not found: {}",
            source_db.display()
        )));
    }
    if !storage_root.exists() {
        return Err(CliError::Other(format!(
            "Storage root {} does not exist; cannot archive.",
            storage_root.display()
        )));
    }

    let archive_dir = archive_states_dir(true)?;
    let timestamp = Utc::now();
    let timestamp = timestamp.with_nanosecond(0).unwrap_or(timestamp);
    let base_name = compose_archive_basename(timestamp, &projects, &preset_str, label.as_deref());
    let destination = ensure_unique_archive_path(&archive_dir, &base_name);

    let temp_dir = tempfile::Builder::new()
        .prefix("mailbox-archive-")
        .tempdir()?;
    let snapshot_path = temp_dir.path().join("mailbox.sqlite3");

    ftui_runtime::ftui_println!("Creating mailbox archive...");
    let context = share::create_snapshot_context(source_db, &snapshot_path, &projects, preset)?;

    let snapshot_size = std::fs::metadata(&snapshot_path)?.len();
    let destination_name = destination
        .file_name()
        .map(|s| s.to_string_lossy().to_string())
        .unwrap_or_else(|| "mailbox-state.zip".to_string());
    let projects_included = projects_included_from_snapshot(&snapshot_path).unwrap_or_else(|_| {
        context
            .scope
            .projects
            .iter()
            .map(|p| {
                serde_json::json!({
                    "slug": p.slug.clone(),
                    "human_key": p.human_key.clone(),
                    "created_at": "",
                })
            })
            .collect()
    });

    let projects_requested = projects.clone();
    let label_value = label.clone().unwrap_or_default();
    let source_path = source_db.display().to_string();

    let metadata = serde_json::json!({
        "version": 1,
        "created_at": timestamp.to_rfc3339_opts(chrono::SecondsFormat::Secs, false),
        "projects_requested": projects_requested,
        "projects_included": projects_included,
        "projects_removed": context.scope.removed_count,
        "scrub_preset": preset_str.clone(),
        "scrub_summary": context.scrub_summary,
        "fts_enabled": context.fts_enabled,
        "database": {
            "source_path": source_path,
            "snapshot": ARCHIVE_SNAPSHOT_RELATIVE,
            "size_bytes": snapshot_size,
        },
        "storage": {
            "source_path": storage_root.display().to_string(),
            "git_head": detect_git_head(storage_root),
            "archive_dir": ARCHIVE_STORAGE_DIRNAME,
        },
        "label": label_value,
        "tooling": {
            "package": "mcp-agent-mail",
            "version": env!("CARGO_PKG_VERSION"),
            "python": "",
        },
        "notes": [
            format!("Restore with `mcp-agent-mail archive restore {}`", destination_name)
        ],
    });
    let sorted_metadata = sort_json_keys(&metadata);
    let metadata_json =
        serde_json::to_string_pretty(&sorted_metadata).unwrap_or_else(|_| "{}".to_string());

    if let Some(parent) = destination.parent() {
        std::fs::create_dir_all(parent)?;
    }

    // Write to a temp file under the archive directory, then move into place (atomic).
    let zip_dir = tempfile::Builder::new()
        .prefix("mailbox-archive-zip-")
        .tempdir_in(&archive_dir)?;
    let temp_zip_path = zip_dir.path().join("mailbox-state.zip");

    use zip::DateTime;
    use zip::write::SimpleFileOptions;

    let file = std::fs::OpenOptions::new()
        .write(true)
        .create_new(true)
        .open(&temp_zip_path)?;
    let mut zip = zip::ZipWriter::new(file);
    let fixed_time = DateTime::from_date_and_time(1980, 1, 1, 0, 0, 0)
        .map_err(|e| CliError::Other(format!("zip time error: {e}")))?;
    let base_options = SimpleFileOptions::default()
        .compression_method(zip::CompressionMethod::Deflated)
        .compression_level(Some(9))
        .last_modified_time(fixed_time);

    // metadata.json
    zip.start_file(ARCHIVE_METADATA_FILENAME, base_options)
        .map_err(|e| CliError::Other(format!("zip write error: {e}")))?;
    zip.write_all(metadata_json.as_bytes())?;

    // snapshot/mailbox.sqlite3
    let snapshot_zip_name = ARCHIVE_SNAPSHOT_RELATIVE.replace('\\', "/");
    let snapshot_mode = file_mode(&snapshot_path);
    zip.start_file(
        snapshot_zip_name,
        base_options.unix_permissions(snapshot_mode),
    )
    .map_err(|e| CliError::Other(format!("zip write error: {e}")))?;
    let mut snapshot_file = std::fs::File::open(&snapshot_path)?;
    std::io::copy(&mut snapshot_file, &mut zip)?;

    // storage_repo/*
    let mut files = Vec::new();
    collect_files(storage_root, storage_root, &mut files)?;
    files.sort();
    for rel in files {
        let full_path = storage_root.join(&rel);
        let rel_str = rel.to_string_lossy().replace('\\', "/");
        let zip_name = format!("{ARCHIVE_STORAGE_DIRNAME}/{rel_str}");
        let mode = file_mode(&full_path);

        zip.start_file(zip_name, base_options.unix_permissions(mode))
            .map_err(|e| CliError::Other(format!("zip write error: {e}")))?;
        let mut f = std::fs::File::open(&full_path)?;
        std::io::copy(&mut f, &mut zip)?;
    }

    zip.finish()
        .map_err(|e| CliError::Other(format!("zip finalize error: {e}")))?;

    std::fs::rename(&temp_zip_path, &destination)?;

    let size_bytes = std::fs::metadata(&destination)
        .map(|m| m.len())
        .unwrap_or(0);
    let projects_desc = if projects.is_empty() {
        vec!["all".to_string()]
    } else {
        projects
    };

    ftui_runtime::ftui_println!(" Mailbox state saved to: {}", destination.display());
    ftui_runtime::ftui_println!(
        "Preset: {} | Projects: {} | Size: {}",
        preset_str,
        projects_desc.join(", "),
        format_bytes(size_bytes),
    );
    ftui_runtime::ftui_println!(
        "Restore later with: mcp-agent-mail archive restore {}",
        destination_name
    );

    Ok(destination)
}

#[allow(dead_code)]
fn archive_restore_state(
    archive_file: PathBuf,
    database_path: &Path,
    storage_root: &Path,
    force: bool,
    dry_run: bool,
) -> CliResult<()> {
    use std::io::IsTerminal;

    let archive_path = resolve_archive_path(&archive_file)?;
    let (meta, meta_error) = load_archive_metadata(&archive_path);
    if let Some(err) = meta_error {
        ftui_runtime::ftui_eprintln!("Warning: {err}");
    }

    if database_path.to_string_lossy() == ":memory:" {
        return Err(CliError::Other(
            "cannot restore into an in-memory database (:memory:)".to_string(),
        ));
    }

    let database_path = database_path.to_path_buf();
    let storage_root = storage_root.to_path_buf();

    let archive_db_path = meta
        .get("database")
        .and_then(|v| v.get("source_path"))
        .and_then(|v| v.as_str());
    let archive_storage_path = meta
        .get("storage")
        .and_then(|v| v.get("source_path"))
        .and_then(|v| v.as_str());

    if let Some(path) = archive_db_path {
        if path != database_path.display().to_string() {
            ftui_runtime::ftui_eprintln!(
                "Archive was created from database {path}, current config is {}. Continuing...",
                database_path.display()
            );
        }
    }
    if let Some(path) = archive_storage_path {
        if path != storage_root.display().to_string() {
            ftui_runtime::ftui_eprintln!(
                "Archive used storage root {path}, current config is {}. Continuing...",
                storage_root.display()
            );
        }
    }

    // Planned operations (and safety backups)
    let timestamp = Utc::now().format("%Y%m%d-%H%M%S").to_string();
    let mut planned_ops: Vec<String> = Vec::new();
    if database_path.exists() {
        planned_ops.push(format!(
            "backup {} -> {}",
            database_path.display(),
            next_backup_path(&database_path, &timestamp).display()
        ));
    }
    for suffix in ["-wal", "-shm"] {
        let wal_path = PathBuf::from(format!("{}{}", database_path.display(), suffix));
        if wal_path.exists() {
            planned_ops.push(format!(
                "backup {} -> {}",
                wal_path.display(),
                next_backup_path(&wal_path, &timestamp).display()
            ));
        }
    }
    if storage_root.exists() {
        planned_ops.push(format!(
            "backup {} -> {}",
            storage_root.display(),
            next_backup_path(&storage_root, &timestamp).display()
        ));
    }
    planned_ops.push(format!("restore snapshot -> {}", database_path.display()));
    planned_ops.push(format!(
        "restore storage repo -> {}",
        storage_root.display()
    ));

    if dry_run {
        ftui_runtime::ftui_println!("Dry-run plan:");
        for op in &planned_ops {
            ftui_runtime::ftui_println!("  - {op}");
        }
        return Ok(());
    }

    if !force {
        if !std::io::stdin().is_terminal() {
            return Err(CliError::Other(
                "refusing to prompt on non-interactive stdin; pass --force / -f to apply"
                    .to_string(),
            ));
        }
        ftui_runtime::ftui_println!("The following operations will be performed:");
        for op in &planned_ops {
            ftui_runtime::ftui_println!("  - {op}");
        }
        if !confirm("Proceed with restore?", false)? {
            return Err(CliError::ExitCode(1));
        }
    }

    // Open archive for restore.
    let file = std::fs::File::open(&archive_path)?;
    let mut archive = zip::ZipArchive::new(file).map_err(|e| CliError::Other(format!("{e}")))?;

    // Ensure snapshot exists.
    let snapshot_entry_name = ARCHIVE_SNAPSHOT_RELATIVE;
    if archive.by_name(snapshot_entry_name).is_err() {
        return Err(CliError::Other(format!(
            "Snapshot missing inside archive ({snapshot_entry_name})."
        )));
    }
    // Ensure storage exists.
    let prefix_string = format!("{ARCHIVE_STORAGE_DIRNAME}/");
    let mut has_storage = false;
    for i in 0..archive.len() {
        if let Ok(file) = archive.by_index(i) {
            if file.name().starts_with(&prefix_string) {
                has_storage = true;
                break;
            }
        }
    }
    if !has_storage {
        return Err(CliError::Other(format!(
            "Storage repository missing inside archive ({ARCHIVE_STORAGE_DIRNAME})."
        )));
    }

    // Back up existing files/dirs.
    let mut backup_paths: Vec<PathBuf> = Vec::new();
    if database_path.exists() {
        let backup = next_backup_path(&database_path, &timestamp);
        std::fs::rename(&database_path, &backup)?;
        backup_paths.push(backup);
    }
    for suffix in ["-wal", "-shm"] {
        let wal_path = PathBuf::from(format!("{}{}", database_path.display(), suffix));
        if wal_path.exists() {
            let backup = next_backup_path(&wal_path, &timestamp);
            std::fs::rename(&wal_path, &backup)?;
            backup_paths.push(backup);
        }
    }
    if storage_root.exists() {
        let backup = next_backup_path(&storage_root, &timestamp);
        std::fs::rename(&storage_root, &backup)?;
        backup_paths.push(backup);
    }

    // Restore snapshot.
    if let Some(parent) = database_path.parent() {
        if !parent.as_os_str().is_empty() {
            std::fs::create_dir_all(parent)?;
        }
    }
    {
        let mut snapshot_file = archive
            .by_name(snapshot_entry_name)
            .map_err(|e| CliError::Other(format!("{e}")))?;
        let mut out = std::fs::File::create(&database_path)?;
        std::io::copy(&mut snapshot_file, &mut out)?;
    }

    // Restore storage repo entries.
    if let Some(parent) = storage_root.parent() {
        if !parent.as_os_str().is_empty() {
            std::fs::create_dir_all(parent)?;
        }
    }
    std::fs::create_dir_all(&storage_root)?;

    let prefix_path = Path::new(ARCHIVE_STORAGE_DIRNAME);
    for i in 0..archive.len() {
        let mut file = archive
            .by_index(i)
            .map_err(|e| CliError::Other(format!("{e}")))?;
        let Some(enclosed) = file.enclosed_name().map(|p| p.to_path_buf()) else {
            continue;
        };
        if !enclosed.starts_with(prefix_path) {
            continue;
        }
        let rel = match enclosed.strip_prefix(prefix_path) {
            Ok(p) => p,
            Err(_) => continue,
        };
        if rel.as_os_str().is_empty() {
            continue;
        }
        let out_path = storage_root.join(rel);
        if file.is_dir() {
            std::fs::create_dir_all(&out_path)?;
            continue;
        }
        if let Some(parent) = out_path.parent() {
            std::fs::create_dir_all(parent)?;
        }
        let mut out = std::fs::File::create(&out_path)?;
        std::io::copy(&mut file, &mut out)?;

        #[cfg(unix)]
        if let Some(mode) = file.unix_mode() {
            use std::os::unix::fs::PermissionsExt;
            let _ = std::fs::set_permissions(&out_path, std::fs::Permissions::from_mode(mode));
        }
    }

    ftui_runtime::ftui_println!(" Restore complete from {}.", archive_path.display());
    if !backup_paths.is_empty() {
        ftui_runtime::ftui_println!("Backups preserved at:");
        for path in &backup_paths {
            ftui_runtime::ftui_println!("  - {}", path.display());
        }
    }
    ftui_runtime::ftui_println!(
        "Database: {}\nStorage root: {}\nNeed to revert? Use the backups above or rerun with another archive.",
        database_path.display(),
        storage_root.display()
    );

    Ok(())
}

fn handle_archive(action: ArchiveCommand) -> CliResult<()> {
    match action {
        ArchiveCommand::Save {
            projects,
            scrub_preset,
            label,
        } => {
            let cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
            let source_path = cfg
                .sqlite_path()
                .map_err(|e| CliError::Other(format!("bad database URL: {e}")))?;
            if source_path == ":memory:" {
                return Err(CliError::Other(
                    "cannot archive an in-memory database (:memory:)".to_string(),
                ));
            }
            let source_db = PathBuf::from(&source_path);

            let config = Config::from_env();
            let storage_root = config.storage_root;

            let _path =
                archive_save_state(&source_db, &storage_root, projects, scrub_preset, label)?;
            Ok(())
        }
        ArchiveCommand::List { limit, json } => {
            #[derive(Debug, Serialize)]
            struct ArchiveListEntry {
                file: String,
                path: String,
                size_bytes: u64,
                created_at: String,
                scrub_preset: String,
                projects: Vec<String>,
                #[serde(skip_serializing_if = "Option::is_none")]
                error: Option<String>,
            }

            if limit < 0 {
                return Err(CliError::InvalidArgument(
                    "--limit/-n must be >= 0".to_string(),
                ));
            }

            let archive_dir = archive_states_dir(false)?;
            if !archive_dir.exists() {
                if json {
                    ftui_runtime::ftui_println!("[]");
                } else {
                    ftui_runtime::ftui_println!(
                        "Archive directory {} does not exist yet.",
                        archive_dir.display()
                    );
                }
                return Ok(());
            }

            let mut files: Vec<(PathBuf, std::time::SystemTime)> = Vec::new();
            for entry in std::fs::read_dir(&archive_dir)?.flatten() {
                let path = entry.path();
                if path.extension().and_then(|s| s.to_str()) != Some("zip") {
                    continue;
                }
                let modified = path
                    .metadata()
                    .and_then(|m| m.modified())
                    .unwrap_or(std::time::UNIX_EPOCH);
                files.push((path, modified));
            }
            files.sort_by_key(|(_, m)| std::cmp::Reverse(*m));

            if files.is_empty() {
                if json {
                    ftui_runtime::ftui_println!("[]");
                } else {
                    ftui_runtime::ftui_println!(
                        "No saved mailbox states found under {}.",
                        archive_dir.display()
                    );
                }
                return Ok(());
            }

            let files = if limit > 0 {
                files.into_iter().take(limit as usize).collect::<Vec<_>>()
            } else {
                files
            };

            let mut entries: Vec<ArchiveListEntry> = Vec::new();
            for (path, modified) in files {
                let file_name = path
                    .file_name()
                    .map(|s| s.to_string_lossy().to_string())
                    .unwrap_or_else(|| "?".to_string());
                let size_bytes = path.metadata().map(|m| m.len()).unwrap_or(0);
                let (meta, error) = load_archive_metadata(&path);

                let created_at = meta
                    .get("created_at")
                    .and_then(|v| v.as_str())
                    .map(|s| s.to_string())
                    .unwrap_or_else(|| {
                        let dt = DateTime::<Utc>::from(modified);
                        dt.to_rfc3339_opts(chrono::SecondsFormat::Secs, false)
                    });

                let scrub_preset = meta
                    .get("scrub_preset")
                    .and_then(|v| v.as_str())
                    .unwrap_or("")
                    .to_string();
                let projects = meta
                    .get("projects_requested")
                    .and_then(|v| v.as_array())
                    .map(|arr| {
                        arr.iter()
                            .filter_map(|v| v.as_str().map(|s| s.to_string()))
                            .collect::<Vec<_>>()
                    })
                    .filter(|v| !v.is_empty())
                    .unwrap_or_else(|| vec!["all".to_string()]);

                entries.push(ArchiveListEntry {
                    file: file_name,
                    path: path.display().to_string(),
                    size_bytes,
                    created_at,
                    scrub_preset,
                    projects,
                    error,
                });
            }

            if json {
                ftui_runtime::ftui_println!(
                    "{}",
                    serde_json::to_string_pretty(&entries).unwrap_or_else(|_| "[]".to_string())
                );
                return Ok(());
            }

            ftui_runtime::ftui_println!(
                "{:<32} {:<25} {:>10} {:<9} {:<20} {}",
                "File",
                "Created (UTC)",
                "Size",
                "Preset",
                "Projects",
                "Notes"
            );
            for entry in &entries {
                ftui_runtime::ftui_println!(
                    "{:<32} {:<25} {:>10} {:<9} {:<20} {}",
                    &entry.file[..entry.file.len().min(32)],
                    &entry.created_at[..entry.created_at.len().min(25)],
                    format_bytes(entry.size_bytes),
                    entry.scrub_preset,
                    entry.projects.join(", "),
                    entry.error.clone().unwrap_or_default()
                );
            }
            ftui_runtime::ftui_println!(
                "Archives live under {}. Restore with `mcp-agent-mail archive restore <file>`.",
                archive_dir.display()
            );
            Ok(())
        }
        ArchiveCommand::Restore {
            archive_file,
            force,
            dry_run,
        } => {
            let cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
            let db_path = cfg
                .sqlite_path()
                .map_err(|e| CliError::Other(format!("bad database URL: {e}")))?;
            if db_path == ":memory:" {
                return Err(CliError::Other(
                    "cannot restore into an in-memory database (:memory:)".to_string(),
                ));
            }
            let database_path = PathBuf::from(&db_path);

            let config = Config::from_env();
            let storage_root = config.storage_root;
            archive_restore_state(archive_file, &database_path, &storage_root, force, dry_run)
        }
    }
}

// ---------------------------------------------------------------------------
// Doctor repair, backups, restore
// ---------------------------------------------------------------------------

fn handle_doctor_repair(
    project: Option<String>,
    dry_run: bool,
    _yes: bool,
    backup_dir: Option<PathBuf>,
) -> CliResult<()> {
    let conn = open_db_sync()?;

    ftui_runtime::ftui_println!("Running database repair...");

    // 1. Integrity check
    let integrity = conn
        .query_sync("PRAGMA integrity_check", &[])
        .map_err(|e| CliError::Other(format!("integrity check failed: {e}")))?;
    let integrity_ok = integrity
        .first()
        .and_then(|r| r.get_named::<String>("integrity_check").ok())
        .map(|s| s == "ok")
        .unwrap_or(false);

    ftui_runtime::ftui_println!(
        "  Integrity: {}",
        if integrity_ok { "OK" } else { "FAILED" }
    );

    if !integrity_ok && !dry_run {
        ftui_runtime::ftui_eprintln!(
            "  Database corruption detected. Consider restoring from backup."
        );
        return Err(CliError::ExitCode(1));
    }

    // 2. Optional backup before repair
    if !dry_run {
        let config = Config::from_env();
        let bak_dir = backup_dir.unwrap_or_else(|| config.storage_root.join("backups"));
        std::fs::create_dir_all(&bak_dir)?;
        let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
        let bak_name = format!("pre_repair_{timestamp}.sqlite3");
        let cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
        let db_path = cfg.sqlite_path().unwrap_or_default();
        if std::path::Path::new(&db_path).exists() {
            let bak_path = bak_dir.join(&bak_name);
            std::fs::copy(&db_path, &bak_path)?;
            ftui_runtime::ftui_println!("  Backup: {}", bak_path.display());
        }
    }

    // 3. Rebuild FTS if tables exist
    if !dry_run {
        let fts_tables = conn
            .query_sync(
                "SELECT name FROM sqlite_master WHERE type='table' AND name LIKE '%_fts%'",
                &[],
            )
            .unwrap_or_default();
        if !fts_tables.is_empty() {
            for row in &fts_tables {
                let name: String = row.get_named("name").unwrap_or_default();
                let rebuild_sql = format!("INSERT INTO {name}({name}) VALUES('rebuild')");
                match conn.execute_raw(&rebuild_sql) {
                    Ok(_) => ftui_runtime::ftui_println!("  Rebuilt FTS: {name}"),
                    Err(e) => ftui_runtime::ftui_eprintln!("  FTS rebuild failed for {name}: {e}"),
                }
            }
        }
    }

    // 4. VACUUM + ANALYZE
    if !dry_run {
        conn.execute_raw("VACUUM")
            .map_err(|e| CliError::Other(format!("VACUUM failed: {e}")))?;
        conn.execute_raw("ANALYZE")
            .map_err(|e| CliError::Other(format!("ANALYZE failed: {e}")))?;
        ftui_runtime::ftui_println!("  VACUUM + ANALYZE complete.");
    }

    // 5. Check orphan records
    let orphan_msgs = conn
        .query_sync(
            "SELECT COUNT(*) AS cnt FROM messages m \
             LEFT JOIN projects p ON p.id = m.project_id \
             WHERE p.id IS NULL",
            &[],
        )
        .unwrap_or_default();
    let orphan_count: i64 = orphan_msgs
        .first()
        .and_then(|r| r.get_named("cnt").ok())
        .unwrap_or(0);
    if orphan_count > 0 {
        ftui_runtime::ftui_println!("  Orphan messages: {orphan_count}");
        if !dry_run {
            conn.execute_raw(
                "DELETE FROM messages WHERE project_id NOT IN (SELECT id FROM projects)",
            )
            .ok();
            ftui_runtime::ftui_println!("  Cleaned orphan messages.");
        }
    }

    if let Some(ref slug) = project {
        ftui_runtime::ftui_println!("  Scoped to project: {slug}");
    }

    ftui_runtime::ftui_println!(
        "Repair {}.",
        if dry_run {
            "dry run complete"
        } else {
            "complete"
        }
    );
    Ok(())
}

fn handle_doctor_backups(json: bool) -> CliResult<()> {
    let config = Config::from_env();
    handle_doctor_backups_with_storage_root(&config.storage_root, json)
}

fn handle_doctor_backups_with_storage_root(storage_root: &Path, json: bool) -> CliResult<()> {
    let backup_dir = storage_root.join("backups");

    if !backup_dir.exists() {
        if json {
            ftui_runtime::ftui_println!("[]");
        } else {
            ftui_runtime::ftui_println!("No backups found.");
        }
        return Ok(());
    }

    let mut backups: Vec<(String, u64, std::time::SystemTime)> = Vec::new();
    for entry in std::fs::read_dir(&backup_dir)?.flatten() {
        let path = entry.path();
        if path.extension().and_then(|s| s.to_str()) == Some("sqlite3") {
            if let Ok(meta) = path.metadata() {
                let name = path
                    .file_name()
                    .and_then(|n| n.to_str())
                    .unwrap_or("?")
                    .to_string();
                let modified = meta.modified().unwrap_or(std::time::UNIX_EPOCH);
                backups.push((name, meta.len(), modified));
            }
        }
    }
    backups.sort_by_key(|x| std::cmp::Reverse(x.2));

    if json {
        let arr: Vec<serde_json::Value> = backups
            .iter()
            .map(|(name, size, _)| serde_json::json!({"name": name, "size": size}))
            .collect();
        ftui_runtime::ftui_println!("{}", serde_json::to_string_pretty(&arr).unwrap_or_default());
    } else {
        if backups.is_empty() {
            output::empty_result(false, "No backups found.");
            return Ok(());
        }
        let mut table = output::CliTable::new(vec!["BACKUP", "SIZE"]);
        for (name, size, _) in &backups {
            table.add_row(vec![name.clone(), format_bytes(*size)]);
        }
        table.render();
    }
    Ok(())
}

fn handle_doctor_restore(backup_path: PathBuf, dry_run: bool, _yes: bool) -> CliResult<()> {
    if !backup_path.exists() {
        return Err(CliError::InvalidArgument(format!(
            "backup not found: {}",
            backup_path.display()
        )));
    }

    let cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
    let dest_path = cfg
        .sqlite_path()
        .map_err(|e| CliError::Other(format!("bad database URL: {e}")))?;

    ftui_runtime::ftui_println!("Restore: {} -> {}", backup_path.display(), dest_path);

    if dry_run {
        ftui_runtime::ftui_println!("Dry run  no changes made.");
        return Ok(());
    }

    std::fs::copy(&backup_path, &dest_path)?;
    ftui_runtime::ftui_println!("Database restored from backup.");
    Ok(())
}

// ---------------------------------------------------------------------------
// Products commands
// ---------------------------------------------------------------------------

static PRODUCTS_HTTP_CLIENT: OnceLock<asupersync::http::h1::HttpClient> = OnceLock::new();
static PRODUCT_UID_COUNTER: AtomicU64 = AtomicU64::new(0);

fn products_http_client() -> &'static asupersync::http::h1::HttpClient {
    PRODUCTS_HTTP_CLIENT.get_or_init(asupersync::http::h1::HttpClient::new)
}

fn collapse_whitespace(input: &str) -> String {
    input.split_whitespace().collect::<Vec<_>>().join(" ")
}

fn is_hex_uid(candidate: &str) -> bool {
    let s = candidate.trim();
    if s.len() < 8 || s.len() > 64 {
        return false;
    }
    s.chars().all(|c| c.is_ascii_hexdigit())
}

fn generate_product_uid(now_micros: i64) -> String {
    let seq = PRODUCT_UID_COUNTER.fetch_add(1, Ordering::Relaxed);
    let pid = u64::from(std::process::id());
    let raw = format!("{now_micros:x}{pid:x}{seq:x}");
    let mut out = String::with_capacity(20);
    for ch in raw.chars() {
        if ch.is_ascii_hexdigit() {
            out.push(ch.to_ascii_lowercase());
        }
        if out.len() == 20 {
            break;
        }
    }
    while out.len() < 20 {
        out.push('0');
    }
    out
}

fn buffer_to_text_trim(buf: &ftui::Buffer) -> String {
    let mut lines: Vec<String> = Vec::with_capacity(buf.height() as usize);
    for y in 0..buf.height() {
        let mut line = String::with_capacity(buf.width() as usize);
        for x in 0..buf.width() {
            let cell = buf.get(x, y).expect("buffer cell");
            if cell.is_continuation() {
                continue;
            }
            if cell.is_empty() {
                line.push(' ');
            } else if let Some(c) = cell.content.as_char() {
                line.push(c);
            } else {
                // Unknown content (grapheme ID etc). Keep width-correct placeholder.
                let w = cell.content.width();
                for _ in 0..w.max(1) {
                    line.push('?');
                }
            }
        }
        lines.push(line.trim_end().to_string());
    }
    while matches!(lines.last(), Some(s) if s.trim().is_empty()) {
        lines.pop();
    }
    lines.join("\n")
}

fn render_table_text(title: Option<&str>, headers: &[&str], rows: Vec<Vec<String>>) -> String {
    use ftui::layout::{Constraint, Rect};
    use ftui::widgets::Widget;
    use ftui::widgets::block::Block;
    use ftui::widgets::borders::BorderType;
    use ftui::widgets::table::{Row, Table};

    let col_count = headers.len();
    let widths = (0..col_count)
        .map(|idx| match idx {
            // Heuristic widths: keep IDs compact, give text columns room.
            0 => Constraint::FitContentBounded { min: 2, max: 14 },
            1 => Constraint::FitContentBounded { min: 2, max: 16 },
            2 => Constraint::FitContentBounded { min: 4, max: 72 },
            3 => Constraint::FitContentBounded { min: 4, max: 28 },
            4 => Constraint::FitContentBounded { min: 4, max: 40 },
            _ => Constraint::FitContentBounded { min: 2, max: 80 },
        })
        .collect::<Vec<_>>();

    let row_count = rows.len();
    let header = Row::new(headers.to_vec());
    let ftui_rows = rows.into_iter().map(Row::new).collect::<Vec<_>>();

    let mut table = Table::new(ftui_rows, widths)
        .header(header)
        .column_spacing(2);
    if let Some(t) = title {
        table = table.block(Block::bordered().border_type(BorderType::Ascii).title(t));
    }

    // Render headless to a buffer and print as text. Keep the width stable for tests.
    let width: u16 = 120;
    let height = (row_count + 4).clamp(6, 200).try_into().unwrap_or(200u16);

    let mut pool = ftui::GraphemePool::new();
    let mut frame = ftui::Frame::new(width, height, &mut pool);
    let area = Rect::new(0, 0, width, height);
    table.render(area, &mut frame);

    buffer_to_text_trim(&frame.buffer)
}

fn print_table(title: Option<&str>, headers: &[&str], rows: Vec<Vec<String>>) {
    let rendered = render_table_text(title, headers, rows);
    ftui_runtime::ftui_println!("{rendered}");
}

async fn try_call_server_tool(
    server_url: &str,
    bearer: Option<&str>,
    tool_name: &str,
    arguments: serde_json::Value,
) -> Option<serde_json::Value> {
    use asupersync::http::h1::Method;

    let req = serde_json::json!({
        "jsonrpc": "2.0",
        "id": format!("cli-{tool_name}"),
        "method": "tools/call",
        "params": {
            "name": tool_name,
            "arguments": arguments,
        }
    });
    let body = serde_json::to_vec(&req).ok()?;

    let mut headers = vec![("Content-Type".to_string(), "application/json".to_string())];
    if let Some(tok) = bearer.filter(|s| !s.is_empty()) {
        headers.push(("Authorization".to_string(), format!("Bearer {tok}")));
    }

    let resp = products_http_client()
        .request(Method::Post, server_url, headers, body)
        .await
        .ok()?;
    if resp.status != 200 {
        return None;
    }

    let v: serde_json::Value = serde_json::from_slice(&resp.body).ok()?;
    v.get("result").cloned()
}

fn coerce_tool_result_json(result: serde_json::Value) -> Option<serde_json::Value> {
    match result {
        serde_json::Value::Null => None,
        serde_json::Value::String(s) => serde_json::from_str(&s).ok(),
        serde_json::Value::Object(map) => {
            if let Some(v) = map.get("structured_content") {
                return Some(v.clone());
            }
            if let Some(content) = map.get("content") {
                // FastMCP-style: { content: [{ type: "text", text: "..." }] }
                if let Some(text) = content
                    .as_array()
                    .and_then(|a| a.first())
                    .and_then(|v| v.get("text"))
                    .and_then(|v| v.as_str())
                {
                    if let Ok(parsed) = serde_json::from_str::<serde_json::Value>(text) {
                        return Some(parsed);
                    }
                }
            }
            Some(serde_json::Value::Object(map))
        }
        other => Some(other),
    }
}

async fn get_product_by_key(
    cx: &asupersync::Cx,
    pool: &mcp_agent_mail_db::DbPool,
    key: &str,
) -> CliResult<Option<mcp_agent_mail_db::ProductRow>> {
    use mcp_agent_mail_db::sqlmodel::Model;
    use mcp_agent_mail_db::sqlmodel::Value;

    let conn = match pool.acquire(cx).await {
        asupersync::Outcome::Ok(c) => c,
        asupersync::Outcome::Err(e) => {
            return Err(CliError::Other(format!("db acquire failed: {e}")));
        }
        asupersync::Outcome::Cancelled(_) => {
            return Err(CliError::Other("request cancelled".to_string()));
        }
        asupersync::Outcome::Panicked(p) => {
            return Err(CliError::Other(format!("internal panic: {}", p.message())));
        }
    };

    let sql = "SELECT * FROM products WHERE product_uid = ? OR name = ? LIMIT 1";
    let params = [Value::Text(key.to_string()), Value::Text(key.to_string())];
    let rows = conn
        .query_sync(sql, &params)
        .map_err(|e| CliError::Other(format!("product lookup failed: {e}")))?;
    let Some(row) = rows.into_iter().next() else {
        return Ok(None);
    };
    let product = mcp_agent_mail_db::ProductRow::from_row(&row)
        .map_err(|e| CliError::Other(format!("bad product row: {e}")))?;
    Ok(Some(product))
}

async fn get_project_record(
    cx: &asupersync::Cx,
    pool: &mcp_agent_mail_db::DbPool,
    identifier: &str,
) -> CliResult<mcp_agent_mail_db::ProjectRow> {
    let raw = identifier.trim();
    let mut canonical = raw.to_string();
    let path = Path::new(raw);
    if path.is_absolute() {
        if let Ok(resolved) = path.canonicalize() {
            canonical = resolved.display().to_string();
        }
    }
    let slug = mcp_agent_mail_core::compute_project_slug(&canonical);

    let out = mcp_agent_mail_db::queries::get_project_by_slug(cx, pool, &slug).await;
    match out {
        asupersync::Outcome::Ok(row) => return Ok(row),
        asupersync::Outcome::Err(_) => {}
        asupersync::Outcome::Cancelled(_) => {
            return Err(CliError::Other("request cancelled".to_string()));
        }
        asupersync::Outcome::Panicked(p) => {
            return Err(CliError::Other(format!("internal panic: {}", p.message())));
        }
    }

    let out = mcp_agent_mail_db::queries::get_project_by_human_key(cx, pool, &canonical).await;
    match out {
        asupersync::Outcome::Ok(row) => return Ok(row),
        asupersync::Outcome::Err(_) => {}
        asupersync::Outcome::Cancelled(_) => {
            return Err(CliError::Other("request cancelled".to_string()));
        }
        asupersync::Outcome::Panicked(p) => {
            return Err(CliError::Other(format!("internal panic: {}", p.message())));
        }
    }

    if canonical != raw {
        let out = mcp_agent_mail_db::queries::get_project_by_human_key(cx, pool, raw).await;
        match out {
            asupersync::Outcome::Ok(row) => return Ok(row),
            asupersync::Outcome::Err(_) => {}
            asupersync::Outcome::Cancelled(_) => {
                return Err(CliError::Other("request cancelled".to_string()));
            }
            asupersync::Outcome::Panicked(p) => {
                return Err(CliError::Other(format!("internal panic: {}", p.message())));
            }
        }
    }

    Err(CliError::Other(format!("Project '{raw}' not found")))
}

async fn ensure_product_local(
    cx: &asupersync::Cx,
    pool: &mcp_agent_mail_db::DbPool,
    product_key: Option<&str>,
    name: Option<&str>,
) -> CliResult<mcp_agent_mail_db::ProductRow> {
    let key_raw = product_key.or(name).unwrap_or("").trim();
    if key_raw.is_empty() {
        ftui_runtime::ftui_eprintln!("Provide a product_key or --name.");
        return Err(CliError::ExitCode(2));
    }

    if let Some(existing) = get_product_by_key(cx, pool, key_raw).await? {
        return Ok(existing);
    }

    let now = mcp_agent_mail_db::now_micros();
    let uid = match product_key {
        Some(pk) if is_hex_uid(pk) => pk.trim().to_ascii_lowercase(),
        _ => generate_product_uid(now),
    };
    let display_name_raw = name.unwrap_or(key_raw);
    let mut display_name = collapse_whitespace(display_name_raw)
        .chars()
        .take(255)
        .collect::<String>();
    if display_name.is_empty() {
        display_name = uid.clone();
    }

    let out = mcp_agent_mail_db::queries::ensure_product(
        cx,
        pool,
        Some(uid.as_str()),
        Some(display_name.as_str()),
    )
    .await;
    match out {
        asupersync::Outcome::Ok(row) => Ok(row),
        asupersync::Outcome::Err(e) => Err(CliError::Other(format!("ensure product failed: {e}"))),
        asupersync::Outcome::Cancelled(_) => Err(CliError::Other("request cancelled".to_string())),
        asupersync::Outcome::Panicked(p) => {
            Err(CliError::Other(format!("internal panic: {}", p.message())))
        }
    }
}

fn handle_products(action: ProductsCommand) -> CliResult<()> {
    use asupersync::runtime::RuntimeBuilder;

    let runtime = RuntimeBuilder::current_thread()
        .build()
        .map_err(|e| CliError::Other(format!("failed to build runtime: {e}")))?;
    runtime.block_on(async move { handle_products_async(action).await })
}

async fn handle_products_async(action: ProductsCommand) -> CliResult<()> {
    let config = Config::from_env();
    let server_url = format!(
        "http://{}:{}{}",
        config.http_host, config.http_port, config.http_path
    );
    let bearer = config.http_bearer_token.as_deref();

    let cx = asupersync::Cx::for_request();
    let pool_cfg = mcp_agent_mail_db::DbPoolConfig::from_env();
    let pool = mcp_agent_mail_db::get_or_create_pool(&pool_cfg)
        .map_err(|e| CliError::Other(format!("db pool init failed: {e}")))?;

    handle_products_with(&cx, &pool, Some(server_url.as_str()), bearer, action).await
}

async fn handle_products_with(
    cx: &asupersync::Cx,
    pool: &mcp_agent_mail_db::DbPool,
    server_url: Option<&str>,
    bearer: Option<&str>,
    action: ProductsCommand,
) -> CliResult<()> {
    match action {
        ProductsCommand::Ensure {
            product_key,
            name,
            json,
        } => {
            let key_raw = product_key
                .as_deref()
                .or(name.as_deref())
                .unwrap_or("")
                .trim()
                .to_string();
            if key_raw.is_empty() {
                ftui_runtime::ftui_eprintln!("Provide a product_key or --name.");
                return Err(CliError::ExitCode(2));
            }

            // Prefer server tool to ensure strict uid policy (legacy behavior).
            let mut args = serde_json::Map::new();
            if let Some(pk) = &product_key {
                args.insert(
                    "product_key".to_string(),
                    serde_json::Value::String(pk.clone()),
                );
            }
            if let Some(n) = &name {
                args.insert("name".to_string(), serde_json::Value::String(n.clone()));
            }
            let server_result = if let Some(url) = server_url {
                try_call_server_tool(
                    url,
                    bearer,
                    "ensure_product",
                    serde_json::Value::Object(args),
                )
                .await
                .and_then(coerce_tool_result_json)
            } else {
                None
            };

            let payload = if let Some(v) = server_result {
                v
            } else {
                let row =
                    ensure_product_local(cx, pool, product_key.as_deref(), name.as_deref()).await?;
                serde_json::json!({
                    "id": row.id.unwrap_or(0),
                    "product_uid": row.product_uid,
                    "name": row.name,
                    "created_at": mcp_agent_mail_db::micros_to_iso(row.created_at),
                })
            };

            if json {
                ftui_runtime::ftui_println!(
                    "{}",
                    serde_json::to_string_pretty(&payload).unwrap_or_default()
                );
                return Ok(());
            }

            let created_at = payload
                .get("created_at")
                .and_then(|v| v.as_str())
                .unwrap_or("");
            let rows = vec![
                vec![
                    "id".to_string(),
                    payload.get("id").cloned().unwrap_or_default().to_string(),
                ],
                vec![
                    "product_uid".to_string(),
                    payload
                        .get("product_uid")
                        .and_then(|v| v.as_str())
                        .unwrap_or("")
                        .to_string(),
                ],
                vec![
                    "name".to_string(),
                    payload
                        .get("name")
                        .and_then(|v| v.as_str())
                        .unwrap_or("")
                        .to_string(),
                ],
                vec!["created_at".to_string(), created_at.to_string()],
            ];
            print_table(Some("Product"), &["Field", "Value"], rows);
            Ok(())
        }
        ProductsCommand::Link {
            product_key,
            project,
            json,
        } => {
            let prod = get_product_by_key(cx, pool, product_key.trim())
                .await?
                .ok_or_else(|| CliError::Other(format!("Product '{product_key}' not found")))?;
            let proj = get_project_record(cx, pool, &project).await?;

            let prod_id = prod.id.unwrap_or(0);
            let proj_id = proj.id.unwrap_or(0);

            let out =
                mcp_agent_mail_db::queries::link_product_to_projects(cx, pool, prod_id, &[proj_id])
                    .await;
            match out {
                asupersync::Outcome::Ok(_) => {}
                asupersync::Outcome::Err(e) => {
                    return Err(CliError::Other(format!("link failed: {e}")));
                }
                asupersync::Outcome::Cancelled(_) => {
                    return Err(CliError::Other("request cancelled".to_string()));
                }
                asupersync::Outcome::Panicked(p) => {
                    return Err(CliError::Other(format!("internal panic: {}", p.message())));
                }
            }

            let payload = serde_json::json!({
                "product_uid": prod.product_uid,
                "product_name": prod.name,
                "project_slug": proj.slug,
            });

            if json {
                ftui_runtime::ftui_println!(
                    "{}",
                    serde_json::to_string_pretty(&payload).unwrap_or_default()
                );
                return Ok(());
            }

            ftui_runtime::ftui_println!(
                "Linked project '{}' into product '{}' ({}).",
                payload
                    .get("project_slug")
                    .and_then(|v| v.as_str())
                    .unwrap_or(""),
                payload
                    .get("product_name")
                    .and_then(|v| v.as_str())
                    .unwrap_or(""),
                payload
                    .get("product_uid")
                    .and_then(|v| v.as_str())
                    .unwrap_or(""),
            );
            Ok(())
        }
        ProductsCommand::Status { product_key, json } => {
            let prod = get_product_by_key(cx, pool, product_key.trim())
                .await?
                .ok_or_else(|| {
                    ftui_runtime::ftui_eprintln!("Product '{product_key}' not found.");
                    CliError::ExitCode(2)
                })?;
            let prod_id = prod.id.unwrap_or(0);
            let projects =
                match mcp_agent_mail_db::queries::list_product_projects(cx, pool, prod_id).await {
                    asupersync::Outcome::Ok(v) => v,
                    asupersync::Outcome::Err(e) => {
                        return Err(CliError::Other(format!("status query failed: {e}")));
                    }
                    asupersync::Outcome::Cancelled(_) => {
                        return Err(CliError::Other("request cancelled".to_string()));
                    }
                    asupersync::Outcome::Panicked(p) => {
                        return Err(CliError::Other(format!("internal panic: {}", p.message())));
                    }
                };

            let payload = serde_json::json!({
                "product": {
                    "id": prod.id.unwrap_or(0),
                    "product_uid": prod.product_uid,
                    "name": prod.name,
                    "created_at": mcp_agent_mail_db::micros_to_iso(prod.created_at),
                },
                "projects": projects.iter().map(|p| serde_json::json!({
                    "id": p.id.unwrap_or(0),
                    "slug": p.slug,
                    "human_key": p.human_key,
                })).collect::<Vec<_>>(),
            });

            if json {
                ftui_runtime::ftui_println!(
                    "{}",
                    serde_json::to_string_pretty(&payload).unwrap_or_default()
                );
                return Ok(());
            }

            let prod_title = payload
                .get("product")
                .and_then(|p| p.get("name"))
                .and_then(|v| v.as_str())
                .map(|n| format!("Product: {n}"))
                .unwrap_or_else(|| "Product".to_string());

            let p = payload.get("product").cloned().unwrap_or_default();
            let rows = vec![
                vec![
                    "id".to_string(),
                    p.get("id").cloned().unwrap_or_default().to_string(),
                ],
                vec![
                    "product_uid".to_string(),
                    p.get("product_uid")
                        .and_then(|v| v.as_str())
                        .unwrap_or("")
                        .to_string(),
                ],
                vec![
                    "name".to_string(),
                    p.get("name")
                        .and_then(|v| v.as_str())
                        .unwrap_or("")
                        .to_string(),
                ],
                vec![
                    "created_at".to_string(),
                    p.get("created_at")
                        .and_then(|v| v.as_str())
                        .unwrap_or("")
                        .to_string(),
                ],
            ];
            print_table(Some(&prod_title), &["Field", "Value"], rows);
            ftui_runtime::ftui_println!();

            let proj_rows = payload
                .get("projects")
                .and_then(|v| v.as_array())
                .cloned()
                .unwrap_or_default()
                .into_iter()
                .map(|p| {
                    vec![
                        p.get("id").cloned().unwrap_or_default().to_string(),
                        p.get("slug")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .to_string(),
                        p.get("human_key")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .to_string(),
                    ]
                })
                .collect::<Vec<_>>();
            print_table(
                Some("Linked Projects"),
                &["id", "slug", "human_key"],
                proj_rows,
            );
            Ok(())
        }
        ProductsCommand::Search {
            product_key,
            query,
            limit,
            json,
        } => {
            let Some(sanitized) = mcp_agent_mail_db::queries::sanitize_fts_query(&query) else {
                if json {
                    let payload = serde_json::json!({ "result": [] });
                    ftui_runtime::ftui_println!(
                        "{}",
                        serde_json::to_string_pretty(&payload).unwrap_or_default()
                    );
                } else {
                    ftui_runtime::ftui_println!("Query '{query}' cannot produce search results.");
                }
                return Ok(());
            };

            let prod = get_product_by_key(cx, pool, product_key.trim())
                .await?
                .ok_or_else(|| {
                    ftui_runtime::ftui_eprintln!("Product '{product_key}' not found.");
                    CliError::ExitCode(2)
                })?;
            let prod_id = prod.id.unwrap_or(0);
            let projects =
                match mcp_agent_mail_db::queries::list_product_projects(cx, pool, prod_id).await {
                    asupersync::Outcome::Ok(v) => v,
                    asupersync::Outcome::Err(e) => {
                        return Err(CliError::Other(format!("project list failed: {e}")));
                    }
                    asupersync::Outcome::Cancelled(_) => {
                        return Err(CliError::Other("request cancelled".to_string()));
                    }
                    asupersync::Outcome::Panicked(p) => {
                        return Err(CliError::Other(format!("internal panic: {}", p.message())));
                    }
                };
            let project_ids = projects.iter().filter_map(|p| p.id).collect::<Vec<_>>();
            if project_ids.is_empty() {
                if json {
                    let payload = serde_json::json!({ "result": [] });
                    ftui_runtime::ftui_println!(
                        "{}",
                        serde_json::to_string_pretty(&payload).unwrap_or_default()
                    );
                } else {
                    ftui_runtime::ftui_println!("No results.");
                }
                return Ok(());
            }

            use mcp_agent_mail_db::sqlmodel::Value;
            let conn = match pool.acquire(cx).await {
                asupersync::Outcome::Ok(c) => c,
                asupersync::Outcome::Err(e) => {
                    return Err(CliError::Other(format!("db acquire failed: {e}")));
                }
                asupersync::Outcome::Cancelled(_) => {
                    return Err(CliError::Other("request cancelled".to_string()));
                }
                asupersync::Outcome::Panicked(p) => {
                    return Err(CliError::Other(format!("internal panic: {}", p.message())));
                }
            };

            let limit_i64 = limit.max(0);
            let placeholders = std::iter::repeat_n("?", project_ids.len())
                .collect::<Vec<_>>()
                .join(", ");
            let sql = format!(
                "SELECT m.id, m.subject, m.created_ts, a.name AS sender_name, m.project_id \
                 FROM fts_messages \
                 JOIN messages m ON m.id = fts_messages.message_id \
                 JOIN agents a ON a.id = m.sender_id \
                 WHERE m.project_id IN ({placeholders}) AND fts_messages MATCH ? \
                 ORDER BY bm25(fts_messages) ASC, m.id ASC \
                 LIMIT ?"
            );
            let mut params: Vec<Value> = project_ids.into_iter().map(Value::BigInt).collect();
            params.push(Value::Text(sanitized));
            params.push(Value::BigInt(limit_i64));

            let rows = conn.query_sync(&sql, &params).unwrap_or_default(); // legacy: fail closed to empty

            let mut out = Vec::new();
            for r in rows {
                let id: i64 = r.get_named("id").unwrap_or(0);
                let subject: String = r.get_named("subject").unwrap_or_default();
                let from: String = r.get_named("sender_name").unwrap_or_default();
                let project_id: i64 = r.get_named("project_id").unwrap_or(0);
                let created_ts: i64 = r.get_named("created_ts").unwrap_or(0);
                out.push(serde_json::json!({
                    "project_id": project_id,
                    "id": id,
                    "subject": subject,
                    "from": from,
                    "created_ts": mcp_agent_mail_db::micros_to_iso(created_ts),
                }));
            }

            if out.is_empty() {
                if json {
                    let payload = serde_json::json!({ "result": [] });
                    ftui_runtime::ftui_println!(
                        "{}",
                        serde_json::to_string_pretty(&payload).unwrap_or_default()
                    );
                } else {
                    ftui_runtime::ftui_println!("No results.");
                }
                return Ok(());
            }

            let payload = serde_json::json!({ "result": out });
            if json {
                ftui_runtime::ftui_println!(
                    "{}",
                    serde_json::to_string_pretty(&payload).unwrap_or_default()
                );
                return Ok(());
            }

            let title = format!("Product search: '{query}'");
            let rows = payload
                .get("result")
                .and_then(|v| v.as_array())
                .cloned()
                .unwrap_or_default()
                .into_iter()
                .map(|r| {
                    vec![
                        r.get("project_id").cloned().unwrap_or_default().to_string(),
                        r.get("id").cloned().unwrap_or_default().to_string(),
                        r.get("subject")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .to_string(),
                        r.get("from")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .to_string(),
                        r.get("created_ts")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .to_string(),
                    ]
                })
                .collect::<Vec<_>>();
            print_table(
                Some(&title),
                &["project_id", "id", "subject", "from", "created_ts"],
                rows,
            );
            Ok(())
        }
        ProductsCommand::Inbox {
            product_key,
            agent,
            limit,
            urgent_only,
            all,
            include_bodies,
            no_bodies,
            since_ts,
            json,
        } => {
            let urgent_only = resolve_bool(urgent_only, all, false);
            let include_bodies = resolve_bool(include_bodies, no_bodies, false);

            // Prefer server tool, but fall back to local DB if server is unreachable or
            // returns an empty result set.
            let server_result = if let Some(url) = server_url {
                try_call_server_tool(
                    url,
                    bearer,
                    "fetch_inbox_product",
                    serde_json::json!({
                        "product_key": product_key,
                        "agent_name": agent,
                        "limit": limit,
                        "urgent_only": urgent_only,
                        "include_bodies": include_bodies,
                        "since_ts": since_ts.clone().unwrap_or_default(),
                    }),
                )
                .await
                .and_then(coerce_tool_result_json)
            } else {
                None
            };

            let mut items: Vec<serde_json::Value> = match server_result {
                Some(v) => match v {
                    serde_json::Value::Array(a) => a,
                    serde_json::Value::Object(obj) => obj
                        .get("result")
                        .and_then(|r| r.as_array())
                        .cloned()
                        .unwrap_or_default(),
                    _ => Vec::new(),
                },
                None => Vec::new(),
            };

            if items.is_empty() {
                // Local fallback.
                if let Some(prod) = get_product_by_key(cx, pool, product_key.trim()).await? {
                    let prod_id = prod.id.unwrap_or(0);
                    let projects =
                        match mcp_agent_mail_db::queries::list_product_projects(cx, pool, prod_id)
                            .await
                        {
                            asupersync::Outcome::Ok(v) => v,
                            asupersync::Outcome::Err(e) => {
                                return Err(CliError::Other(format!("project list failed: {e}")));
                            }
                            asupersync::Outcome::Cancelled(_) => {
                                return Err(CliError::Other("request cancelled".to_string()));
                            }
                            asupersync::Outcome::Panicked(p) => {
                                return Err(CliError::Other(format!(
                                    "internal panic: {}",
                                    p.message()
                                )));
                            }
                        };

                    let since_micros = since_ts
                        .as_deref()
                        .and_then(mcp_agent_mail_db::iso_to_micros);
                    let max_messages = usize::try_from(limit.max(0)).unwrap_or(0);

                    let mut merged: Vec<(i64, i64, serde_json::Value)> = Vec::new();
                    for p in projects {
                        let project_id = p.id.unwrap_or(0);
                        let agent_row = match mcp_agent_mail_db::queries::get_agent(
                            cx, pool, project_id, &agent,
                        )
                        .await
                        {
                            asupersync::Outcome::Ok(a) => a,
                            _ => continue, // legacy: skip missing agent in project
                        };
                        let rows = match mcp_agent_mail_db::queries::fetch_inbox(
                            cx,
                            pool,
                            project_id,
                            agent_row.id.unwrap_or(0),
                            urgent_only,
                            since_micros,
                            max_messages,
                        )
                        .await
                        {
                            asupersync::Outcome::Ok(v) => v,
                            _ => continue,
                        };
                        for row in rows {
                            let msg = row.message;
                            let id = msg.id.unwrap_or(0);
                            let created_ts = msg.created_ts;
                            let mut obj = serde_json::json!({
                                "id": id,
                                "project_id": msg.project_id,
                                "subject": msg.subject,
                                "importance": msg.importance,
                                "ack_required": msg.ack_required != 0,
                                "created_ts": mcp_agent_mail_db::micros_to_iso(created_ts),
                                "from": row.sender_name,
                                "kind": row.kind,
                            });
                            if include_bodies {
                                obj.as_object_mut().unwrap().insert(
                                    "body_md".to_string(),
                                    serde_json::Value::String(msg.body_md),
                                );
                            }
                            merged.push((created_ts, id, obj));
                        }
                    }

                    merged.sort_by(|(a_ts, a_id, _), (b_ts, b_id, _)| {
                        b_ts.cmp(a_ts).then_with(|| a_id.cmp(b_id))
                    });
                    items = merged
                        .into_iter()
                        .take(max_messages)
                        .map(|(_, _, v)| v)
                        .collect();
                }
            }

            if items.is_empty() {
                if json {
                    ftui_runtime::ftui_println!("[]");
                } else {
                    ftui_runtime::ftui_println!("No messages found.");
                }
                return Ok(());
            }

            if json {
                ftui_runtime::ftui_println!(
                    "{}",
                    serde_json::to_string_pretty(&items).unwrap_or_default()
                );
                return Ok(());
            }

            let title = format!("Inbox for {agent} in product '{product_key}'");
            let rows = items
                .iter()
                .map(|r| {
                    vec![
                        r.get("project_id").cloned().unwrap_or_default().to_string(),
                        r.get("id").cloned().unwrap_or_default().to_string(),
                        r.get("subject")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .to_string(),
                        r.get("from")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .to_string(),
                        r.get("importance")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .to_string(),
                        r.get("created_ts")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .to_string(),
                    ]
                })
                .collect::<Vec<_>>();
            print_table(
                Some(&title),
                &[
                    "project_id",
                    "id",
                    "subject",
                    "from",
                    "importance",
                    "created_ts",
                ],
                rows,
            );
            Ok(())
        }
        ProductsCommand::SummarizeThread {
            product_key,
            thread_id,
            per_thread_limit,
            no_llm,
            json,
        } => {
            let server_result = if let Some(url) = server_url {
                try_call_server_tool(
                    url,
                    bearer,
                    "summarize_thread_product",
                    serde_json::json!({
                        "product_key": product_key,
                        "thread_id": thread_id,
                        "include_examples": true,
                        "llm_mode": !no_llm,
                        "per_thread_limit": per_thread_limit,
                    }),
                )
                .await
                .and_then(coerce_tool_result_json)
            } else {
                None
            };

            let Some(payload) = server_result else {
                ftui_runtime::ftui_println!(
                    "Server unavailable; summarization requires server tool. Try again when server is running."
                );
                return Err(CliError::ExitCode(2));
            };

            if json {
                ftui_runtime::ftui_println!(
                    "{}",
                    serde_json::to_string_pretty(&payload).unwrap_or_default()
                );
                return Ok(());
            }

            let summary = payload.get("summary").cloned().unwrap_or_default();
            let participants = summary
                .get("participants")
                .and_then(|v| v.as_array())
                .map(|a| {
                    a.iter()
                        .filter_map(|v| v.as_str())
                        .collect::<Vec<_>>()
                        .join(", ")
                })
                .unwrap_or_default();

            let kv_rows = vec![
                vec!["participants".to_string(), participants],
                vec![
                    "total_messages".to_string(),
                    summary
                        .get("total_messages")
                        .cloned()
                        .unwrap_or_default()
                        .to_string(),
                ],
                vec![
                    "open_actions".to_string(),
                    summary
                        .get("open_actions")
                        .cloned()
                        .unwrap_or_default()
                        .to_string(),
                ],
                vec![
                    "done_actions".to_string(),
                    summary
                        .get("done_actions")
                        .cloned()
                        .unwrap_or_default()
                        .to_string(),
                ],
            ];
            let title = format!("Thread summary: {thread_id}");
            print_table(Some(&title), &["Key", "Value"], kv_rows);

            if let Some(points) = summary.get("key_points").and_then(|v| v.as_array()) {
                if !points.is_empty() {
                    let rows = points
                        .iter()
                        .map(|p| vec![p.as_str().unwrap_or("").to_string()])
                        .collect::<Vec<_>>();
                    ftui_runtime::ftui_println!();
                    print_table(Some("Key Points"), &["point"], rows);
                }
            }
            if let Some(items) = summary.get("action_items").and_then(|v| v.as_array()) {
                if !items.is_empty() {
                    let rows = items
                        .iter()
                        .map(|p| vec![p.as_str().unwrap_or("").to_string()])
                        .collect::<Vec<_>>();
                    ftui_runtime::ftui_println!();
                    print_table(Some("Action Items"), &["item"], rows);
                }
            }
            if let Some(examples) = payload.get("examples").and_then(|v| v.as_array()) {
                if !examples.is_empty() {
                    let rows = examples
                        .iter()
                        .map(|e| {
                            vec![
                                e.get("id").cloned().unwrap_or_default().to_string(),
                                e.get("subject")
                                    .and_then(|v| v.as_str())
                                    .unwrap_or("")
                                    .to_string(),
                                e.get("from")
                                    .and_then(|v| v.as_str())
                                    .unwrap_or("")
                                    .to_string(),
                                e.get("created_ts")
                                    .and_then(|v| v.as_str())
                                    .unwrap_or("")
                                    .to_string(),
                            ]
                        })
                        .collect::<Vec<_>>();
                    ftui_runtime::ftui_println!();
                    print_table(
                        Some("Examples"),
                        &["id", "subject", "from", "created_ts"],
                        rows,
                    );
                }
            }
            Ok(())
        }
    }
}

// ---------------------------------------------------------------------------
// Docs commands
// ---------------------------------------------------------------------------

fn handle_docs(action: DocsCommand) -> CliResult<()> {
    match action {
        DocsCommand::InsertBlurbs {
            scan_dir,
            yes: _,
            dry_run,
            max_depth,
        } => {
            let dirs = if scan_dir.is_empty() {
                vec![std::env::current_dir().unwrap_or_default()]
            } else {
                scan_dir
            };

            let max_depth = max_depth.unwrap_or(3) as usize;
            let mut total_files = 0u64;
            let mut total_insertions = 0u64;

            for dir in &dirs {
                ftui_runtime::ftui_println!("Scanning: {}", dir.display());
                scan_markdown_for_blurbs(
                    dir,
                    0,
                    max_depth,
                    dry_run,
                    &mut total_files,
                    &mut total_insertions,
                )?;
            }

            ftui_runtime::ftui_println!(
                "Scanned {} markdown files, {} insertions{}.",
                total_files,
                total_insertions,
                if dry_run { " (dry run)" } else { "" }
            );
            Ok(())
        }
    }
}

fn scan_markdown_for_blurbs(
    dir: &Path,
    depth: usize,
    max_depth: usize,
    dry_run: bool,
    total_files: &mut u64,
    total_insertions: &mut u64,
) -> CliResult<()> {
    if depth > max_depth || !dir.is_dir() {
        return Ok(());
    }
    for entry in std::fs::read_dir(dir)?.flatten() {
        let path = entry.path();
        if path.is_dir() {
            scan_markdown_for_blurbs(
                &path,
                depth + 1,
                max_depth,
                dry_run,
                total_files,
                total_insertions,
            )?;
        } else if path.extension().and_then(|s| s.to_str()) == Some("md") {
            *total_files += 1;
            let content = match std::fs::read_to_string(&path) {
                Ok(c) => c,
                Err(_) => continue,
            };
            // Look for <!-- am:blurb --> markers
            if content.contains("<!-- am:blurb -->") && !content.contains("<!-- am:blurb:end -->") {
                *total_insertions += 1;
                if !dry_run {
                    // Insert a placeholder end marker after each blurb marker
                    let updated = content.replace(
                        "<!-- am:blurb -->",
                        "<!-- am:blurb -->\n<!-- am:blurb:end -->",
                    );
                    std::fs::write(&path, updated)?;
                }
                ftui_runtime::ftui_println!(
                    "  {} blurb marker{}",
                    path.display(),
                    if dry_run {
                        " (would insert)"
                    } else {
                        " (inserted)"
                    }
                );
            }
        }
    }
    Ok(())
}

// ---------------------------------------------------------------------------
// Static file server for share preview
// ---------------------------------------------------------------------------

static PREVIEW_FORCE_TOKEN: AtomicU64 = AtomicU64::new(0);

#[derive(Debug, Clone, Serialize)]
struct PreviewStatusPayload {
    signature: String,
    files_indexed: usize,
    last_modified_ns: Option<u64>,
    last_modified_iso: Option<String>,
    manifest_ns: Option<u64>,
    manifest_iso: Option<String>,
    manual_token: u64,
}

fn bump_preview_force_token() -> u64 {
    PREVIEW_FORCE_TOKEN
        .fetch_add(1, Ordering::AcqRel)
        .wrapping_add(1)
}

fn iso_from_epoch_ns(ns: u64) -> Option<String> {
    let secs = (ns / 1_000_000_000) as i64;
    let nanos = (ns % 1_000_000_000) as u32;
    chrono::DateTime::<chrono::Utc>::from_timestamp(secs, nanos).map(|dt| dt.to_rfc3339())
}

fn collect_preview_status(bundle_path: &Path) -> PreviewStatusPayload {
    use sha2::{Digest, Sha256};

    let token = PREVIEW_FORCE_TOKEN.load(Ordering::Acquire);
    let bundle_path = bundle_path
        .canonicalize()
        .unwrap_or_else(|_| bundle_path.to_path_buf());

    let mut file_entries: Vec<(String, u64, u64)> = Vec::new();
    let mut latest_ns: u64 = 0;
    let mut manifest_ns: Option<u64> = None;
    if bundle_path.is_dir() {
        let _ = collect_preview_files(
            &bundle_path,
            &bundle_path,
            &mut file_entries,
            &mut latest_ns,
            &mut manifest_ns,
        );
    }

    file_entries.sort_by(|a, b| a.0.cmp(&b.0));

    let mut parts: Vec<String> = Vec::with_capacity(file_entries.len() + 1);
    for (rel, mtime_ns, size) in &file_entries {
        parts.push(format!("{rel}:{mtime_ns}:{size}"));
    }
    parts.push(format!("manual:{token}"));

    let signature = if parts.is_empty() {
        "0".to_string()
    } else {
        hex::encode(Sha256::digest(parts.join("|").as_bytes()))
    };

    let last_modified_ns = if latest_ns == 0 {
        None
    } else {
        Some(latest_ns)
    };
    let last_modified_iso = last_modified_ns.and_then(iso_from_epoch_ns);
    let manifest_iso = manifest_ns.and_then(iso_from_epoch_ns);

    PreviewStatusPayload {
        signature,
        files_indexed: parts.len(),
        last_modified_ns,
        last_modified_iso,
        manifest_ns,
        manifest_iso,
        manual_token: token,
    }
}

fn collect_preview_files(
    root: &Path,
    dir: &Path,
    out: &mut Vec<(String, u64, u64)>,
    latest_ns: &mut u64,
    manifest_ns: &mut Option<u64>,
) -> std::io::Result<()> {
    use std::time::UNIX_EPOCH;

    for entry in std::fs::read_dir(dir)? {
        let entry = match entry {
            Ok(e) => e,
            Err(_) => continue,
        };
        let path = entry.path();
        let metadata = match entry.metadata() {
            Ok(m) => m,
            Err(_) => continue,
        };
        if metadata.is_dir() {
            let _ = collect_preview_files(root, &path, out, latest_ns, manifest_ns);
            continue;
        }
        if !metadata.is_file() {
            continue;
        }
        let rel = path
            .strip_prefix(root)
            .ok()
            .and_then(|p| p.to_str())
            .unwrap_or("")
            .replace('\\', "/");
        if rel.is_empty() {
            continue;
        }
        let mtime_ns = metadata
            .modified()
            .ok()
            .and_then(|t| t.duration_since(UNIX_EPOCH).ok())
            .map(|d| d.as_nanos().min(u128::from(u64::MAX)) as u64)
            .unwrap_or(0);
        let size = metadata.len();
        *latest_ns = (*latest_ns).max(mtime_ns);
        if rel == "manifest.json" && mtime_ns > 0 {
            *manifest_ns = Some(mtime_ns);
        }
        out.push((rel, mtime_ns, size));
    }
    Ok(())
}

type PreviewLog = std::sync::Arc<std::sync::Mutex<std::fs::File>>;

fn preview_log_line(log: &Option<PreviewLog>, line: &str) {
    use std::io::Write;

    let Some(log) = log else {
        return;
    };
    let Ok(mut file) = log.lock() else {
        return;
    };
    let _ = writeln!(file, "{line}");
}

fn apply_preview_no_cache_headers(resp: &mut asupersync::http::h1::types::Response) {
    resp.headers.push((
        "Cache-Control".to_string(),
        "no-store, no-cache, must-revalidate".to_string(),
    ));
    resp.headers
        .push(("Pragma".to_string(), "no-cache".to_string()));
}

struct PreviewServerHandle {
    addr: std::net::SocketAddr,
    shutdown: asupersync::server::shutdown::ShutdownSignal,
    join: std::thread::JoinHandle<Result<(), String>>,
}

fn start_preview_server(
    dir: PathBuf,
    host: String,
    port: u16,
    log: Option<PreviewLog>,
) -> CliResult<PreviewServerHandle> {
    use asupersync::http::h1::listener::{Http1Listener, Http1ListenerConfig};
    use asupersync::http::h1::types::Response;
    use asupersync::runtime::RuntimeBuilder;
    use std::sync::mpsc;

    // Avoid serving files outside the preview root via symlink escape.
    let base_dir = dir.canonicalize().unwrap_or(dir);

    let socket_addr: std::net::SocketAddr = format!("{host}:{port}")
        .parse()
        .map_err(|e| CliError::InvalidArgument(format!("invalid address: {e}")))?;

    let (ready_tx, ready_rx) = mpsc::channel::<
        Result<
            (
                std::net::SocketAddr,
                asupersync::server::shutdown::ShutdownSignal,
            ),
            String,
        >,
    >();

    let join = std::thread::spawn(move || {
        let runtime = match RuntimeBuilder::current_thread().build() {
            Ok(runtime) => runtime,
            Err(e) => {
                let msg = format!("failed to build runtime: {e}");
                let _ = ready_tx.send(Err(msg.clone()));
                return Err(msg);
            }
        };
        let handle = runtime.handle();
        runtime.block_on(async move {
            let dir = base_dir.clone();
            let log = log.clone();
            let listener = match Http1Listener::bind_with_config(
                socket_addr,
                move |req| {
                    let dir = dir.clone();
                    let log = log.clone();
                    async move {
                        let uri = &req.uri;
                        let path = uri.split('?').next().unwrap_or("/");
                        preview_log_line(&log, &format!("GET {path}"));

                        if path.starts_with("/__preview__/status") {
                            let payload = collect_preview_status(&dir);
                            let body = serde_json::to_vec(&payload).unwrap_or_default();
                            let mut resp = Response::new(200, "OK", body);
                            let len = resp.body.len();
                            resp.headers
                                .push(("Content-Type".to_string(), "application/json".to_string()));
                            resp.headers
                                .push(("Content-Length".to_string(), len.to_string()));
                            apply_preview_no_cache_headers(&mut resp);
                            return resp;
                        }

                        if path == "/favicon.ico"
                            || path.ends_with(".map")
                            || path.starts_with("/.well-known/")
                        {
                            let mut resp = Response::new(204, "No Content", Vec::new());
                            resp.headers
                                .push(("Content-Length".to_string(), "0".to_string()));
                            apply_preview_no_cache_headers(&mut resp);
                            return resp;
                        }

                        let relative = path.trim_start_matches('/');
                        if relative.split('/').any(|seg| seg == "..") {
                            let mut resp = Response::new(404, "Not Found", b"Not Found".to_vec());
                            resp.headers
                                .push(("Content-Length".to_string(), resp.body.len().to_string()));
                            apply_preview_no_cache_headers(&mut resp);
                            return resp;
                        }

                        let mut file_path = if relative.is_empty() {
                            dir.join("index.html")
                        } else {
                            dir.join(relative)
                        };
                        if file_path.is_dir() {
                            file_path = file_path.join("index.html");
                        }

                        let resolved = file_path.canonicalize().ok();
                        let within_root = resolved.as_ref().is_some_and(|p| p.starts_with(&dir));
                        let mut resp = if within_root
                            && resolved.as_ref().is_some_and(|p| p.is_file())
                        {
                            let resolved = resolved.as_ref().unwrap();
                            match std::fs::read(resolved) {
                                Ok(content) => {
                                    let ct = guess_content_type(resolved);
                                    let mut resp = Response::new(200, "OK", content);
                                    resp.headers
                                        .push(("Content-Type".to_string(), ct.to_string()));
                                    resp.headers.push((
                                        "Content-Length".to_string(),
                                        resp.body.len().to_string(),
                                    ));
                                    resp
                                }
                                Err(_) => {
                                    let mut resp =
                                        Response::new(500, "Internal Server Error", Vec::new());
                                    resp.headers
                                        .push(("Content-Length".to_string(), "0".to_string()));
                                    resp
                                }
                            }
                        } else {
                            let mut resp = Response::new(404, "Not Found", b"Not Found".to_vec());
                            resp.headers
                                .push(("Content-Length".to_string(), resp.body.len().to_string()));
                            resp
                        };
                        apply_preview_no_cache_headers(&mut resp);
                        resp
                    }
                },
                Http1ListenerConfig::default(),
            )
            .await
            {
                Ok(listener) => listener,
                Err(e) => {
                    let msg = format!("failed to bind HTTP listener: {e}");
                    let _ = ready_tx.send(Err(msg.clone()));
                    return Err(msg);
                }
            };

            let shutdown = listener.shutdown_signal();
            let local_addr = match listener.local_addr() {
                Ok(addr) => addr,
                Err(e) => {
                    let msg = format!("failed to read local addr: {e}");
                    let _ = ready_tx.send(Err(msg.clone()));
                    return Err(msg);
                }
            };
            let _ = ready_tx.send(Ok((local_addr, shutdown.clone())));

            listener
                .run(&handle)
                .await
                .map(|_| ())
                .map_err(|e| format!("listener run error: {e}"))
        })
    });

    let (addr, shutdown) = ready_rx
        .recv_timeout(std::time::Duration::from_secs(10))
        .map_err(|e| CliError::Other(format!("preview server failed to start: {e}")))?
        .map_err(CliError::Other)?;

    Ok(PreviewServerHandle {
        addr,
        shutdown,
        join,
    })
}

fn run_share_preview(bundle: &Path, host: &str, port: u16, open_browser: bool) -> CliResult<()> {
    run_share_preview_with_control(
        bundle.to_path_buf(),
        host.to_string(),
        port,
        open_browser,
        None,
        None,
        None,
    )
}

fn run_share_preview_with_control(
    bundle: PathBuf,
    host: String,
    port: u16,
    open_browser: bool,
    key_rx: Option<std::sync::mpsc::Receiver<char>>,
    ready_addr_tx: Option<std::sync::mpsc::Sender<std::net::SocketAddr>>,
    artifacts_dir: Option<PathBuf>,
) -> CliResult<()> {
    use std::io::IsTerminal;

    // Prefer shipping the built-in assets in dev/preview mode; ignore errors (matches legacy).
    let _ = share::copy_viewer_assets(&bundle);

    let log = artifacts_dir.as_ref().and_then(|root| {
        let _ = std::fs::create_dir_all(root);
        std::fs::File::create(root.join("server.log"))
            .ok()
            .map(|f| std::sync::Arc::new(std::sync::Mutex::new(f)))
    });
    if let Some(log) = &log {
        preview_log_line(&Some(log.clone()), "preview server starting");
    }

    let server = start_preview_server(bundle.clone(), host.clone(), port, log.clone())?;
    let addr = server.addr;
    if let Some(tx) = ready_addr_tx {
        let _ = tx.send(addr);
    }

    ftui_runtime::ftui_println!(
        "Serving {} at http://{}:{}/ (Ctrl+C to stop)",
        bundle.display(),
        host,
        addr.port()
    );
    ftui_runtime::ftui_println!(
        "Commands: press 'r' to force refresh, 'd' to deploy now, 'q' to stop."
    );

    if open_browser {
        let browse_host = match host.as_str() {
            "0.0.0.0" | "::" => "127.0.0.1",
            other => other,
        };
        let url = format!("http://{}:{}/viewer/", browse_host, addr.port());
        let _ = std::process::Command::new("xdg-open")
            .arg(&url)
            .spawn()
            .or_else(|_| std::process::Command::new("open").arg(&url).spawn());
    }

    let mut deployment_requested = false;
    let mut stop_requested = false;

    if let Some(rx) = key_rx {
        while !stop_requested && !deployment_requested && !server.join.is_finished() {
            match rx.recv_timeout(std::time::Duration::from_millis(200)) {
                Ok(ch) => match ch.to_ascii_lowercase() {
                    'r' => {
                        let token = bump_preview_force_token();
                        ftui_runtime::ftui_println!("Reload signal sent (token {token}).");
                    }
                    'd' => {
                        deployment_requested = true;
                        stop_requested = true;
                    }
                    'q' => {
                        stop_requested = true;
                    }
                    _ => {}
                },
                Err(std::sync::mpsc::RecvTimeoutError::Timeout) => {}
                Err(std::sync::mpsc::RecvTimeoutError::Disconnected) => break,
            }
        }
    } else if std::io::stdin().is_terminal() {
        use crossterm::event::{Event, KeyCode, KeyModifiers, poll, read};

        struct RawModeGuard;
        impl Drop for RawModeGuard {
            fn drop(&mut self) {
                let _ = crossterm::terminal::disable_raw_mode();
            }
        }

        crossterm::terminal::enable_raw_mode()
            .map_err(|e| CliError::Other(format!("failed to enable raw mode: {e}")))?;
        let _raw = RawModeGuard;

        while !stop_requested && !deployment_requested && !server.join.is_finished() {
            if poll(std::time::Duration::from_millis(200))
                .map_err(|e| CliError::Other(format!("hotkey poll error: {e}")))?
            {
                if let Event::Key(key) =
                    read().map_err(|e| CliError::Other(format!("hotkey read error: {e}")))?
                {
                    if key.modifiers.contains(KeyModifiers::CONTROL)
                        && matches!(key.code, KeyCode::Char('c') | KeyCode::Char('d'))
                    {
                        stop_requested = true;
                        continue;
                    }

                    match key.code {
                        KeyCode::Char('r') | KeyCode::Char('R') => {
                            let token = bump_preview_force_token();
                            ftui_runtime::ftui_println!("Reload signal sent (token {token}).");
                        }
                        KeyCode::Char('d') | KeyCode::Char('D') => {
                            deployment_requested = true;
                            stop_requested = true;
                        }
                        KeyCode::Char('q') | KeyCode::Char('Q') => {
                            stop_requested = true;
                        }
                        _ => {}
                    }
                }
            }
        }
    } else {
        // Non-interactive stdin: keep serving until the process is interrupted.
        let _ = server.join.join();
        return Ok(());
    }

    ftui_runtime::ftui_println!("Stopping preview server...");
    let _ = server
        .shutdown
        .begin_drain(std::time::Duration::from_secs(2));
    let _ = server.join.join();
    ftui_runtime::ftui_println!("Preview server stopped.");

    if deployment_requested {
        return Err(CliError::ExitCode(42));
    }
    Ok(())
}

fn guess_content_type(path: &Path) -> &'static str {
    match path.extension().and_then(|s| s.to_str()) {
        Some("html") => "text/html; charset=utf-8",
        Some("json") => "application/json",
        Some("js") => "application/javascript",
        Some("css") => "text/css",
        Some("svg") => "image/svg+xml",
        Some("png") => "image/png",
        Some("jpg" | "jpeg") => "image/jpeg",
        Some("woff2") => "font/woff2",
        Some("wasm") => "application/wasm",
        Some("sqlite3") => "application/x-sqlite3",
        _ => "application/octet-stream",
    }
}

fn format_bytes(bytes: u64) -> String {
    let units = ["B", "KiB", "MiB", "GiB", "TiB"];
    let mut current = bytes as f64;
    for (idx, unit) in units.iter().enumerate() {
        let is_last = idx == units.len() - 1;
        if current < 1024.0 || is_last {
            if *unit == "B" {
                return format!("{bytes} {unit}");
            }
            return format!("{:.1} {unit}", current);
        }
        current /= 1024.0;
    }
    format!("{bytes} B")
}
