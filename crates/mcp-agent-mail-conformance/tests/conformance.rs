// Note: unsafe required for env::set_var in Rust 2024
#![allow(unsafe_code)]

use fastmcp::{Budget, CallToolParams, Content, Cx, ListToolsParams, ReadResourceParams};
use fastmcp_core::SessionState;
use mcp_agent_mail_conformance::{Case, ExpectedError, Fixtures, Normalize};
use serde::Deserialize;
use serde_json::Value;
use std::collections::BTreeMap;
use std::sync::{Mutex, OnceLock};

/// Auto-increment ID field names that are non-deterministic across test runs.
const AUTO_INCREMENT_ID_KEYS: &[&str] = &["id", "message_id", "reply_to"];

/// Tests in this file mutate process-wide environment variables (Rust has no per-test env isolation).
/// The Rust test harness runs tests in parallel by default, so serialize any env mutations and
/// `Config::from_env()` calls to avoid flakey cross-test races.
fn env_lock() -> &'static Mutex<()> {
    static LOCK: OnceLock<Mutex<()>> = OnceLock::new();
    LOCK.get_or_init(|| Mutex::new(()))
}

/// Recursively null out auto-increment integer ID fields in a JSON value.
/// This handles the fact that fixture cases run sequentially in a shared DB,
/// so auto-increment IDs depend on execution order.
fn null_auto_increment_ids(value: &mut Value) {
    match value {
        Value::Object(map) => {
            for (key, val) in map.iter_mut() {
                if AUTO_INCREMENT_ID_KEYS.contains(&key.as_str()) && val.is_number() {
                    *val = Value::Null;
                } else {
                    null_auto_increment_ids(val);
                }
            }
        }
        Value::Array(arr) => {
            for item in arr.iter_mut() {
                null_auto_increment_ids(item);
            }
        }
        _ => {}
    }
}

/// For tooling/directory-like resources with "clusters" â†’ "tools" arrays,
/// filter the actual response to only include tools whose names appear in
/// the expected output. This handles tools added after fixture generation.
fn align_cluster_tools(actual: &mut Value, expected: &Value) {
    let Some(expected_clusters) = expected.get("clusters").and_then(|c| c.as_array()) else {
        return;
    };
    let Some(actual_clusters) = actual.get_mut("clusters").and_then(|c| c.as_array_mut()) else {
        return;
    };

    // Collect all tool names from expected
    let mut expected_tool_names: std::collections::HashSet<String> =
        std::collections::HashSet::new();
    for cluster in expected_clusters {
        if let Some(tools) = cluster.get("tools").and_then(|t| t.as_array()) {
            for tool in tools {
                if let Some(name) = tool.get("name").and_then(|n| n.as_str()) {
                    expected_tool_names.insert(name.to_string());
                }
            }
        }
    }

    if expected_tool_names.is_empty() {
        return;
    }

    // Filter actual clusters: remove tools not in expected, remove empty clusters
    for cluster in actual_clusters.iter_mut() {
        if let Some(tools) = cluster.get_mut("tools").and_then(|t| t.as_array_mut()) {
            tools.retain(|tool| {
                tool.get("name")
                    .and_then(|n| n.as_str())
                    .is_some_and(|name| expected_tool_names.contains(name))
            });
        }
    }
    actual_clusters.retain(|c| {
        c.get("tools")
            .and_then(|t| t.as_array())
            .is_some_and(|tools| !tools.is_empty())
    });
}

/// For tooling/metrics-like responses, filter to only tools in expected.
fn align_metrics_tools(actual: &mut Value, expected: &Value) {
    let Some(expected_tools) = expected.get("tools").and_then(|t| t.as_array()) else {
        return;
    };
    let Some(actual_tools) = actual.get_mut("tools").and_then(|t| t.as_array_mut()) else {
        return;
    };

    let expected_names: std::collections::HashSet<String> = expected_tools
        .iter()
        .filter_map(|t| t.get("name").and_then(|n| n.as_str()).map(String::from))
        .collect();

    if expected_names.is_empty() {
        return;
    }

    actual_tools.retain(|tool| {
        tool.get("name")
            .and_then(|n| n.as_str())
            .is_some_and(|name| expected_names.contains(name))
    });
}

fn normalize_pair(mut actual: Value, mut expected: Value, norm: &Normalize) -> (Value, Value) {
    // Always null out auto-increment IDs since they're non-deterministic
    null_auto_increment_ids(&mut actual);
    null_auto_increment_ids(&mut expected);

    // Align tool lists (handle tools added after fixture generation)
    align_cluster_tools(&mut actual, &expected);
    align_metrics_tools(&mut actual, &expected);

    for ptr in &norm.ignore_json_pointers {
        if let Some(v) = actual.pointer_mut(ptr) {
            *v = Value::Null;
        }
        if let Some(v) = expected.pointer_mut(ptr) {
            *v = Value::Null;
        }
    }

    for (ptr, replacement) in &norm.replace {
        if let Some(v) = actual.pointer_mut(ptr) {
            *v = replacement.clone();
        }
        if let Some(v) = expected.pointer_mut(ptr) {
            *v = replacement.clone();
        }
    }

    (actual, expected)
}

fn decode_json_from_tool_content(content: &[Content]) -> Result<Value, String> {
    if content.len() != 1 {
        return Err(format!(
            "expected exactly 1 content item, got {}",
            content.len()
        ));
    }

    match &content[0] {
        Content::Text { text } => match serde_json::from_str(text) {
            Ok(v) => Ok(v),
            Err(_) => Ok(Value::String(text.clone())),
        },
        Content::Resource { resource } => {
            let text = resource
                .text
                .as_deref()
                .ok_or_else(|| "tool returned Resource content without text".to_string())?;
            match serde_json::from_str(text) {
                Ok(v) => Ok(v),
                Err(_) => Ok(Value::String(text.to_string())),
            }
        }
        Content::Image { mime_type, .. } => Err(format!(
            "tool returned Image content (mime_type={mime_type}); JSON decode not supported yet"
        )),
    }
}

fn decode_json_from_resource_contents(
    uri: &str,
    contents: &[fastmcp::ResourceContent],
) -> Result<Value, String> {
    if contents.len() != 1 {
        return Err(format!(
            "expected exactly 1 resource content item for {uri}, got {}",
            contents.len()
        ));
    }
    let item = &contents[0];
    let text = item
        .text
        .as_deref()
        .ok_or_else(|| format!("resource {uri} returned no text"))?;
    match serde_json::from_str(text) {
        Ok(v) => Ok(v),
        Err(_) => Ok(Value::String(text.to_string())),
    }
}

fn assert_expected_error(got: &str, expect: &ExpectedError) {
    if let Some(substr) = &expect.message_contains {
        assert!(
            got.contains(substr),
            "expected error message to contain {substr:?}, got {got:?}"
        );
    }
}

#[derive(Debug, Deserialize)]
struct ToolFilterFixtures {
    version: String,
    generated_at: String,
    cases: Vec<ToolFilterCase>,
}

#[derive(Debug, Deserialize)]
struct ToolFilterCase {
    name: String,
    #[serde(default)]
    env: BTreeMap<String, String>,
    expected_tools: Vec<String>,
}

struct ToolFilterEnvGuard {
    previous: Vec<(String, Option<String>)>,
}

impl ToolFilterEnvGuard {
    fn apply(case_env: &BTreeMap<String, String>) -> Self {
        let keys = [
            "TOOLS_FILTER_ENABLED",
            "TOOLS_FILTER_PROFILE",
            "TOOLS_FILTER_MODE",
            "TOOLS_FILTER_CLUSTERS",
            "TOOLS_FILTER_TOOLS",
        ];

        let mut previous = Vec::new();
        for key in keys {
            let old = std::env::var(key).ok();
            previous.push((key.to_string(), old));
            if let Some(value) = case_env.get(key) {
                unsafe {
                    std::env::set_var(key, value);
                }
            } else {
                unsafe {
                    std::env::remove_var(key);
                }
            }
        }

        Self { previous }
    }
}

impl Drop for ToolFilterEnvGuard {
    fn drop(&mut self) {
        for (key, value) in self.previous.drain(..) {
            match value {
                Some(v) => unsafe {
                    std::env::set_var(&key, v);
                },
                None => unsafe {
                    std::env::remove_var(&key);
                },
            }
        }
    }
}

struct EnvVarGuard {
    previous: Vec<(String, Option<String>)>,
}

impl EnvVarGuard {
    fn set(vars: &[(&str, &str)]) -> Self {
        let mut previous = Vec::new();
        for (key, value) in vars {
            let old = std::env::var(*key).ok();
            previous.push(((*key).to_string(), old));
            unsafe {
                std::env::set_var(key, value);
            }
        }
        Self { previous }
    }
}

impl Drop for EnvVarGuard {
    fn drop(&mut self) {
        for (key, value) in self.previous.drain(..) {
            match value {
                Some(v) => unsafe {
                    std::env::set_var(&key, v);
                },
                None => unsafe {
                    std::env::remove_var(&key);
                },
            }
        }
    }
}

fn load_tool_filter_fixtures() -> ToolFilterFixtures {
    let path = "tests/conformance/fixtures/tool_filter/cases.json";
    let raw = std::fs::read_to_string(path).expect("tool filter fixtures missing");
    let fixtures: ToolFilterFixtures =
        serde_json::from_str(&raw).expect("tool filter fixtures invalid JSON");
    assert!(
        !fixtures.version.trim().is_empty(),
        "tool filter fixtures version must be non-empty"
    );
    assert!(
        !fixtures.generated_at.trim().is_empty(),
        "tool filter fixtures generated_at must be non-empty"
    );
    fixtures
}

fn extract_tool_names_from_directory(value: &Value) -> Vec<String> {
    let mut names = Vec::new();
    let Some(clusters) = value.get("clusters").and_then(|v| v.as_array()) else {
        return names;
    };
    for cluster in clusters {
        let Some(tools) = cluster.get("tools").and_then(|v| v.as_array()) else {
            continue;
        };
        for tool in tools {
            if let Some(name) = tool.get("name").and_then(|v| v.as_str()) {
                names.push(name.to_string());
            }
        }
    }
    names
}

fn args_from_case(case: &Case) -> Option<Value> {
    match &case.input {
        Value::Null => None,
        Value::Object(map) if map.is_empty() => None,
        other => Some(other.clone()),
    }
}

struct FixtureEnv {
    tmp: tempfile::TempDir,
    _env_guard: EnvVarGuard,
    fixtures: Fixtures,
    router: fastmcp::Router,
}

/// Set up env vars, run all tool fixtures, and return the environment for further assertions.
fn setup_fixture_env() -> FixtureEnv {
    let tmp = tempfile::TempDir::new().expect("failed to create tempdir");
    let db_path = tmp.path().join("db.sqlite3");
    let db_url = format!("sqlite://{}", db_path.display());
    let storage_root = tmp.path().join("archive");
    let storage_root_str = storage_root
        .to_str()
        .expect("storage_root must be valid UTF-8");
    // Ensure fixtures run deterministically regardless of developer shell env.
    // Also explicitly disable tool filtering (otherwise tools may not be registered).
    let env_guard = EnvVarGuard::set(&[
        ("DATABASE_URL", &db_url),
        ("WORKTREES_ENABLED", "1"),
        ("STORAGE_ROOT", storage_root_str),
        ("TOOLS_FILTER_ENABLED", "0"),
        ("TOOLS_FILTER_PROFILE", "full"),
        ("TOOLS_FILTER_MODE", "include"),
        ("TOOLS_FILTER_CLUSTERS", ""),
        ("TOOLS_FILTER_TOOLS", ""),
        ("MCP_AGENT_MAIL_OUTPUT_FORMAT", ""),
        ("TOON_DEFAULT_FORMAT", ""),
        ("TOON_BIN", ""),
        ("TOON_TRU_BIN", ""),
        ("TOON_STATS", "0"),
        ("AGENT_NAME_ENFORCEMENT_MODE", "coerce"),
    ]);

    for repo_name in &["repo_install", "repo_uninstall"] {
        let repo_dir = std::path::Path::new("/tmp/agent-mail-fixtures").join(repo_name);
        std::fs::create_dir_all(&repo_dir).expect("create fixture repo dir");
        if !repo_dir.join(".git").exists() {
            std::process::Command::new("git")
                .args(["init", "--quiet"])
                .current_dir(&repo_dir)
                .status()
                .expect("git init");
        }
    }

    let fixtures = Fixtures::load_default().expect("failed to load fixtures");
    let config = mcp_agent_mail_core::Config::from_env();
    let router = mcp_agent_mail_server::build_server(&config).into_router();

    FixtureEnv {
        tmp,
        _env_guard: env_guard,
        fixtures,
        router,
    }
}

/// Parse frontmatter from a message markdown file.
/// Returns the JSON value from the `---json ... ---` block.
fn parse_frontmatter(content: &str) -> Option<Value> {
    let content = content.trim();
    if !content.starts_with("---json") {
        return None;
    }
    let after_start = &content["---json".len()..];
    let end_idx = after_start.find("\n---")?;
    let json_str = &after_start[..end_idx];
    serde_json::from_str(json_str.trim()).ok()
}

#[test]
fn load_and_validate_fixture_schema() {
    let fixtures = Fixtures::load_default().expect("failed to load fixtures");
    assert!(
        fixtures.tools.contains_key("health_check"),
        "fixtures should include at least health_check"
    );
    assert!(
        fixtures
            .resources
            .contains_key("resource://config/environment"),
        "fixtures should include resource://config/environment"
    );
}

#[test]
fn run_fixtures_against_rust_server_router() {
    let _lock = env_lock().lock().unwrap_or_else(|e| e.into_inner());
    let env = setup_fixture_env();
    let storage_root = env.tmp.path().join("archive");
    let fixtures = &env.fixtures;
    let router = &env.router;

    let cx = Cx::for_testing();
    let budget = Budget::INFINITE;
    let mut req_id: u64 = 1;

    for (tool_name, tool_fixture) in &fixtures.tools {
        for case in &tool_fixture.cases {
            let params = CallToolParams {
                name: tool_name.clone(),
                arguments: args_from_case(case),
                meta: None,
            };

            let result = router.handle_tools_call(
                &cx,
                req_id,
                params,
                &budget,
                SessionState::new(),
                None,
                None,
            );
            req_id += 1;

            match (&case.expect.ok, &case.expect.err) {
                (Some(expected_ok), None) => {
                    let call_result = result.unwrap_or_else(|e| {
                        panic!(
                            "tool {tool_name} case {}: unexpected router error: {e}",
                            case.name
                        )
                    });
                    if call_result.is_error {
                        // Print error content for debugging
                        let err_text = call_result
                            .content
                            .first()
                            .and_then(|c| match c {
                                Content::Text { text } => Some(text.clone()),
                                _ => None,
                            })
                            .unwrap_or_default();
                        panic!(
                            "tool {tool_name} case {}: expected ok, got error: {err_text}",
                            case.name
                        );
                    }

                    let actual = decode_json_from_tool_content(&call_result.content)
                        .unwrap_or_else(|e| panic!("tool {tool_name} case {}: {e}", case.name));
                    let (actual, expected) =
                        normalize_pair(actual, expected_ok.clone(), &case.normalize);
                    assert_eq!(
                        actual, expected,
                        "tool {tool_name} case {}: output mismatch",
                        case.name
                    );
                }
                (None, Some(expected_err)) => match result {
                    Ok(call_result) => {
                        assert!(
                            call_result.is_error,
                            "tool {tool_name} case {}: expected error, got ok",
                            case.name
                        );
                        let got = match &call_result.content.first() {
                            Some(Content::Text { text }) => text.as_str(),
                            _ => "<non-text error>",
                        };
                        assert_expected_error(got, expected_err);
                    }
                    Err(e) => {
                        assert_expected_error(&e.message, expected_err);
                    }
                },
                _ => panic!(
                    "tool {tool_name} case {}: invalid fixture expectation (must contain exactly one of ok/err)",
                    case.name
                ),
            }
        }
    }

    for (uri, resource_fixture) in &fixtures.resources {
        for case in &resource_fixture.cases {
            let params = ReadResourceParams {
                uri: uri.clone(),
                meta: None,
            };
            let result = router.handle_resources_read(
                &cx,
                req_id,
                &params,
                &budget,
                SessionState::new(),
                None,
                None,
            );
            req_id += 1;

            match (&case.expect.ok, &case.expect.err) {
                (Some(expected_ok), None) => {
                    let read_result = result.unwrap_or_else(|e| {
                        panic!(
                            "resource {uri} case {}: unexpected router error: {e}",
                            case.name
                        )
                    });
                    let actual = decode_json_from_resource_contents(uri, &read_result.contents)
                        .unwrap_or_else(|e| panic!("resource {uri} case {}: {e}", case.name));
                    let (actual, expected) =
                        normalize_pair(actual, expected_ok.clone(), &case.normalize);
                    assert_eq!(
                        actual, expected,
                        "resource {uri} case {}: output mismatch",
                        case.name
                    );
                }
                (None, Some(expected_err)) => match result {
                    Ok(read_result) => {
                        let got = read_result
                            .contents
                            .first()
                            .and_then(|c| c.text.as_deref())
                            .unwrap_or("<non-text error>");
                        assert_expected_error(got, expected_err);
                    }
                    Err(e) => {
                        assert_expected_error(&e.message, expected_err);
                    }
                },
                _ => panic!(
                    "resource {uri} case {}: invalid fixture expectation (must contain exactly one of ok/err)",
                    case.name
                ),
            }
        }
    }

    // -----------------------------------------------------------------------
    // Archive artifact assertions (run in same test to avoid env var races)
    // -----------------------------------------------------------------------
    let files = collect_archive_files(&storage_root);

    // --- .gitattributes ---
    assert!(
        storage_root.join(".gitattributes").exists(),
        "expected .gitattributes at archive root, found {} files: {:?}",
        files.len(),
        files
    );

    // --- Agent profiles ---
    let expected_profiles = [
        "projects/abs-path-backend/agents/BlueLake/profile.json",
        "projects/abs-path-backend/agents/GreenCastle/profile.json",
        "projects/abs-path-backend/agents/OrangeFox/profile.json",
    ];
    for profile_rel in &expected_profiles {
        assert!(
            files.iter().any(|f| f == profile_rel),
            "expected agent profile at {profile_rel}"
        );
        let content = std::fs::read_to_string(storage_root.join(profile_rel))
            .unwrap_or_else(|e| panic!("failed to read {profile_rel}: {e}"));
        let parsed: Value = serde_json::from_str(&content)
            .unwrap_or_else(|e| panic!("failed to parse JSON in {profile_rel}: {e}"));
        assert!(parsed.get("name").and_then(Value::as_str).is_some());
        assert!(parsed.get("program").and_then(Value::as_str).is_some());
        assert!(parsed.get("model").and_then(Value::as_str).is_some());
    }

    // --- Canonical message files ---
    let message_files: Vec<&String> = files
        .iter()
        .filter(|f| {
            f.starts_with("projects/")
                && f.contains("/messages/")
                && f.ends_with(".md")
                && !f.contains("/threads/")
        })
        .collect();
    assert!(
        message_files.len() >= 2,
        "expected at least 2 canonical message files, found {}: {:?}",
        message_files.len(),
        message_files
    );

    for msg_rel in &message_files {
        let content = std::fs::read_to_string(storage_root.join(msg_rel))
            .unwrap_or_else(|e| panic!("failed to read {msg_rel}: {e}"));
        let fm = parse_frontmatter(&content)
            .unwrap_or_else(|| panic!("message {msg_rel} has no valid ---json frontmatter"));
        assert!(fm.get("from").and_then(Value::as_str).is_some());
        assert!(fm.get("subject").and_then(Value::as_str).is_some());
        assert!(fm.get("to").and_then(Value::as_array).is_some());
        assert!(fm.get("id").is_some());
    }

    // --- Inbox/outbox copies ---
    let inbox_files: Vec<&String> = files
        .iter()
        .filter(|f| f.contains("/inbox/") && f.ends_with(".md"))
        .collect();
    let outbox_files: Vec<&String> = files
        .iter()
        .filter(|f| f.contains("/outbox/") && f.ends_with(".md"))
        .collect();
    assert!(!inbox_files.is_empty(), "expected at least one inbox copy");
    assert!(
        !outbox_files.is_empty(),
        "expected at least one outbox copy"
    );

    // --- File reservation artifacts ---
    let reservation_files: Vec<&String> = files
        .iter()
        .filter(|f| f.contains("/file_reservations/") && f.ends_with(".json"))
        .collect();
    assert!(
        !reservation_files.is_empty(),
        "expected at least one file reservation JSON artifact"
    );

    // --- Notification signal assertions (tool flow) ---
    let notif_tmp = tempfile::TempDir::new().expect("failed to create notifications tempdir");
    let notif_db_path = notif_tmp.path().join("db.sqlite3");
    let notif_db_url = format!("sqlite://{}", notif_db_path.display());
    let notif_storage_root = notif_tmp.path().join("archive");
    let notif_signals_dir = notif_tmp.path().join("signals");
    let _env_guard = EnvVarGuard::set(&[
        ("DATABASE_URL", notif_db_url.as_str()),
        (
            "STORAGE_ROOT",
            notif_storage_root
                .to_str()
                .expect("storage_root must be valid UTF-8"),
        ),
        ("NOTIFICATIONS_ENABLED", "1"),
        ("NOTIFICATIONS_DEBOUNCE_MS", "0"),
        ("NOTIFICATIONS_INCLUDE_METADATA", "1"),
        (
            "NOTIFICATIONS_SIGNALS_DIR",
            notif_signals_dir
                .to_str()
                .expect("signals_dir must be valid UTF-8"),
        ),
    ]);

    let config = mcp_agent_mail_core::Config::from_env();
    let router = mcp_agent_mail_server::build_server(&config).into_router();

    let project_dir = notif_tmp.path().join("project");
    std::fs::create_dir_all(&project_dir).expect("create notification project dir");
    let project_key = project_dir.to_string_lossy().to_string();
    let project_slug = mcp_agent_mail_core::compute_project_slug(&project_key);

    let ensure_params = CallToolParams {
        name: "ensure_project".to_string(),
        arguments: Some(serde_json::json!({ "human_key": project_key.clone() })),
        meta: None,
    };
    let ensure_result = router
        .handle_tools_call(
            &cx,
            req_id,
            ensure_params,
            &budget,
            SessionState::new(),
            None,
            None,
        )
        .unwrap_or_else(|e| panic!("ensure_project failed: {e}"));
    req_id += 1;
    assert!(!ensure_result.is_error, "ensure_project returned error");

    for name in ["BoldCastle", "CalmRiver", "DeepMeadow", "IronPeak"] {
        let register_params = CallToolParams {
            name: "register_agent".to_string(),
            arguments: Some(serde_json::json!({
                "project_key": project_key.clone(),
                "program": "codex-cli",
                "model": "gpt-5",
                "name": name,
            })),
            meta: None,
        };
        let register_result = router
            .handle_tools_call(
                &cx,
                req_id,
                register_params,
                &budget,
                SessionState::new(),
                None,
                None,
            )
            .unwrap_or_else(|e| panic!("register_agent failed for {name}: {e}"));
        req_id += 1;
        assert!(
            !register_result.is_error,
            "register_agent returned error for {name}: {:?}",
            register_result.content
        );
    }

    let send_params = CallToolParams {
        name: "send_message".to_string(),
        arguments: Some(serde_json::json!({
            "project_key": project_key.clone(),
            "sender_name": "BoldCastle",
            "to": ["CalmRiver"],
            "cc": ["DeepMeadow"],
            "bcc": ["IronPeak"],
            "subject": "Signal test",
            "body_md": "Hello from notifications test.",
            "importance": "high",
        })),
        meta: None,
    };
    let send_result = router
        .handle_tools_call(
            &cx,
            req_id,
            send_params,
            &budget,
            SessionState::new(),
            None,
            None,
        )
        .unwrap_or_else(|e| panic!("send_message failed: {e}"));
    req_id += 1;
    assert!(
        !send_result.is_error,
        "send_message returned error: {:?}",
        send_result.content
    );

    let send_json = decode_json_from_tool_content(&send_result.content)
        .expect("failed to decode send_message response");
    let message_id = send_json
        .pointer("/deliveries/0/payload/id")
        .and_then(Value::as_i64)
        .expect("send_message response missing deliveries[0].payload.id");

    let signal_root = notif_signals_dir
        .join("projects")
        .join(&project_slug)
        .join("agents");
    let to_signal = signal_root.join("CalmRiver.signal");
    let cc_signal = signal_root.join("DeepMeadow.signal");
    let bcc_signal = signal_root.join("IronPeak.signal");

    // Debug: check signal directory structure
    eprintln!("signal_root: {}", signal_root.display());
    eprintln!("signal_root exists: {}", signal_root.exists());
    eprintln!("notif_signals_dir: {}", notif_signals_dir.display());
    eprintln!(
        "notif_signals_dir exists: {}",
        notif_signals_dir.exists()
    );
    eprintln!("to_signal path: {}", to_signal.display());
    eprintln!("project_slug: {project_slug}");
    eprintln!("send_json: {send_json}");
    // List files in signals dir recursively
    fn list_dir_recursive(path: &std::path::Path, indent: usize) {
        if let Ok(entries) = std::fs::read_dir(path) {
            for entry in entries {
                if let Ok(entry) = entry {
                    let p = entry.path();
                    eprintln!(
                        "{}{}",
                        " ".repeat(indent),
                        p.file_name().unwrap_or_default().to_string_lossy()
                    );
                    if p.is_dir() {
                        list_dir_recursive(&p, indent + 2);
                    }
                }
            }
        }
    }
    if notif_signals_dir.exists() {
        list_dir_recursive(&notif_signals_dir, 2);
    }

    assert!(to_signal.exists(), "expected CalmRiver signal file");
    assert!(cc_signal.exists(), "expected DeepMeadow signal file");
    assert!(!bcc_signal.exists(), "did not expect IronPeak signal file");

    let to_payload: Value = serde_json::from_str(
        &std::fs::read_to_string(&to_signal).expect("failed to read CalmRiver signal"),
    )
    .expect("failed to parse CalmRiver signal JSON");
    assert_eq!(to_payload["project"], project_slug);
    assert_eq!(to_payload["agent"], "CalmRiver");
    assert_eq!(to_payload["message"]["id"], message_id);
    assert_eq!(to_payload["message"]["from"], "BoldCastle");
    assert_eq!(to_payload["message"]["subject"], "Signal test");
    assert_eq!(to_payload["message"]["importance"], "high");

    let fetch_params = CallToolParams {
        name: "fetch_inbox".to_string(),
        arguments: Some(serde_json::json!({
            "project_key": project_key.clone(),
            "agent_name": "CalmRiver",
        })),
        meta: None,
    };
    let fetch_result = router
        .handle_tools_call(
            &cx,
            req_id,
            fetch_params,
            &budget,
            SessionState::new(),
            None,
            None,
        )
        .unwrap_or_else(|e| panic!("fetch_inbox failed: {e}"));
    assert!(!fetch_result.is_error, "fetch_inbox returned error");

    assert!(
        !to_signal.exists(),
        "expected CalmRiver signal to be cleared after fetch_inbox"
    );
    assert!(cc_signal.exists(), "expected DeepMeadow signal to remain");
}

#[test]
fn tool_filter_profiles_match_fixtures() {
    let _lock = env_lock().lock().unwrap_or_else(|e| e.into_inner());
    let fixtures = load_tool_filter_fixtures();

    for case in fixtures.cases {
        let _env_guard = ToolFilterEnvGuard::apply(&case.env);
        let config = mcp_agent_mail_core::Config::from_env();
        let router = mcp_agent_mail_server::build_server(&config).into_router();

        let cx = Cx::for_testing();
        let budget = Budget::INFINITE;

        // tools/list
        let tools_result = router
            .handle_tools_list(&cx, ListToolsParams::default(), None)
            .expect("tools/list failed");
        let mut actual_tools: Vec<String> =
            tools_result.tools.into_iter().map(|t| t.name).collect();
        actual_tools.sort();

        let mut expected_tools = case.expected_tools.clone();
        expected_tools.sort();

        assert_eq!(
            actual_tools, expected_tools,
            "tools/list mismatch for case {}",
            case.name
        );

        // tooling directory
        let params = ReadResourceParams {
            uri: "resource://tooling/directory".to_string(),
            meta: None,
        };
        let result = router
            .handle_resources_read(&cx, 1, &params, &budget, SessionState::new(), None, None)
            .expect("tooling directory read failed");
        let dir_json = decode_json_from_resource_contents(&params.uri, &result.contents)
            .expect("tooling directory JSON decode failed");
        let mut directory_tools = extract_tool_names_from_directory(&dir_json);
        directory_tools.sort();

        assert_eq!(
            directory_tools, expected_tools,
            "tooling/directory mismatch for case {}",
            case.name
        );
    }
}

// ---------------------------------------------------------------------------
// Archive artifact conformance tests
// ---------------------------------------------------------------------------

/// Collect all files under a directory (excluding .git), returning paths relative to root.
fn collect_archive_files(root: &std::path::Path) -> Vec<String> {
    let mut files = Vec::new();
    collect_files_recursive(root, root, &mut files);
    files.sort();
    files
}

fn collect_files_recursive(base: &std::path::Path, dir: &std::path::Path, out: &mut Vec<String>) {
    let Ok(entries) = std::fs::read_dir(dir) else {
        return;
    };
    for entry in entries {
        let Ok(entry) = entry else { continue };
        let path = entry.path();
        let name = entry.file_name().to_string_lossy().to_string();
        if name == ".git" {
            continue;
        }
        if path.is_dir() {
            collect_files_recursive(base, &path, out);
        } else if let Ok(rel) = path.strip_prefix(base) {
            out.push(rel.to_string_lossy().to_string());
        }
    }
}

// Archive artifact conformance assertions are now embedded at the end of
// `run_fixtures_against_rust_server_router` to avoid parallel env var races.
